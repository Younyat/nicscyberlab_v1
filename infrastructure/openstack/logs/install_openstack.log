[2025-12-09 21:24:06] Iniciando comprobación de permisos
[2025-12-09 21:24:06] ERROR: Este script no debe ejecutarse como root.
[2025-12-09 21:28:07] Iniciando comprobación de permisos
[2025-12-09 21:28:07] Usuario ejecutor: nics (UID=1000)
[2025-12-09 21:28:07] Grupos: nics adm cdrom sudo dip plugdev users lpadmin
[2025-12-09 21:28:07] Permisos sudo verificados correctamente
[2025-12-09 21:28:07] Instalando dependencias del sistema
[2025-12-09 21:29:04] Dependencias del sistema instaladas correctamente
[2025-12-09 21:29:07] Configurando repositorio de Docker
[2025-12-09 21:29:30] Docker instalado. Habilitando servicio y agregando usuario al grupo docker
[2025-12-09 21:29:32] Creando entorno virtual en /home/nics/openstack_venv
[2025-12-09 21:29:44] Entorno virtual activado: /home/nics/openstack_venv/bin/python
[2025-12-09 21:29:44] Instalando dependencias Python para Kolla-Ansible desde /home/nics/Desktop/nicscyberlab_v1/infrastructure/openstack/configs/requirements-kolla.txt
[2025-12-09 21:31:08] Dependencias Python y Kolla-Ansible instaladas correctamente
[2025-12-09 21:31:08] Configurando Kolla en /etc/kolla
[2025-12-09 21:31:08] Generando passwords de Kolla
[2025-12-09 21:31:12] Detectando interfaz principal y subnet para VIP
[2025-12-09 21:31:13] Interfaz principal: ens34
[2025-12-09 21:31:13] IP principal:       192.168.0.195
[2025-12-09 21:31:13] VIP seleccionada:   192.168.0.12
[2025-12-09 21:31:13] Generando /etc/kolla/globals.yml desde plantilla
[2025-12-09 21:31:13] Archivo globals.yml configurado correctamente
[2025-12-09 21:31:13] === Iniciando configuración + despliegue de OpenStack con Kolla-Ansible ===
[2025-12-09 21:31:13] Activando entorno virtual: /home/nics/openstack_venv
[2025-12-09 21:31:13] globals.yml y passwords.yml ya existen. No se sobrescriben.
[2025-12-09 21:31:13] Verificando passwords...
[2025-12-09 21:31:13] passwords.yml ya contiene contraseñas válidas
[2025-12-09 21:31:13] Detectando interfaz principal y generando VIP
[2025-12-09 21:31:14] Interfaz principal detectada: ens34
[2025-12-09 21:31:14] IP principal:                192.168.0.195
[2025-12-09 21:31:14] VIP seleccionado:            192.168.0.200
[2025-12-09 21:31:14] Generando archivo globals.yml final
[2025-12-09 21:31:14] globals.yml configurado correctamente
[2025-12-09 21:31:14] Creando inventario all-in-one
[2025-12-09 21:31:14] Instalando dependencias Galaxy
Your branch is up to date with 'origin/master'.
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Installing 'openstack.kolla:1.0.0' to '/home/nics/.ansible/collections/ansible_collections/openstack/kolla'
Created collection for openstack.kolla:1.0.0 at /home/nics/.ansible/collections/ansible_collections/openstack/kolla
openstack.kolla:1.0.0 was installed successfully
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-posix-2.1.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/ansible-posix-2.1.0-rmivvegp
Installing 'ansible.posix:2.1.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/posix'
ansible.posix:2.1.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-utils-6.0.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/ansible-utils-6.0.0-11ndycy5
Installing 'ansible.utils:6.0.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/utils'
ansible.utils:6.0.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-netcommon-8.2.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/ansible-netcommon-8.2.0-nrulafww
Installing 'ansible.netcommon:8.2.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/netcommon'
ansible.netcommon:8.2.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/containers-podman-1.18.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/containers-podman-1.18.0-42ebl870
Installing 'containers.podman:1.18.0' to '/home/nics/.ansible/collections/ansible_collections/containers/podman'
containers.podman:1.18.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-crypto-3.0.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/community-crypto-3.0.5-5k2jjb7u
Installing 'community.crypto:3.0.5' to '/home/nics/.ansible/collections/ansible_collections/community/crypto'
community.crypto:3.0.5 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-docker-4.8.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/community-docker-4.8.5-40ajqvig
Installing 'community.docker:4.8.5' to '/home/nics/.ansible/collections/ansible_collections/community/docker'
community.docker:4.8.5 was installed successfully
'community.library_inventory_filtering_v1:1.1.1' is already installed, skipping.
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-general-11.4.2.tar.gz to /home/nics/.ansible/tmp/ansible-local-19801bitsylje/tmp587sjm60/community-general-11.4.2-2qej25p0
Installing 'community.general:11.4.2' to '/home/nics/.ansible/collections/ansible_collections/community/general'
community.general:11.4.2 was installed successfully
[2025-12-09 21:31:58] Ejecutando bootstrap-servers

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Apply role baremetal] ****************************************************

TASK [openstack.kolla.etc_hosts : Include etc-hosts.yml] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/etc_hosts/tasks/etc-hosts.yml for localhost

TASK [openstack.kolla.etc_hosts : Ensure localhost in /etc/hosts] **************
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Ensure hostname does not point to 127.0.1.1 in /etc/hosts] ***
changed: [localhost]

TASK [openstack.kolla.etc_hosts : Generate /etc/hosts for all of the nodes] ****
changed: [localhost]

TASK [openstack.kolla.etc_hosts : Check whether /etc/cloud/cloud.cfg exists] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Disable cloud-init manage_etc_hosts] *********
changed: [localhost]

TASK [openstack.kolla.baremetal : Ensure unprivileged users can use ping] ******
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set firewall default policy] *****************
ok: [localhost]

TASK [openstack.kolla.baremetal : Check if firewalld is installed] *************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Disable firewalld] ***************************
skipping: [localhost] => (item=firewalld) 
skipping: [localhost]

TASK [openstack.kolla.packages : Install packages] *****************************
ok: [localhost]

TASK [openstack.kolla.packages : Remove packages] ******************************
ok: [localhost]

TASK [openstack.kolla.docker : Install/Uninstall] ******************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/install.yml for localhost

TASK [openstack.kolla.docker : Enable Docker repository] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/repo-Debian.yml for localhost

TASK [openstack.kolla.docker : Install CA certificates and gnupg packages] *****
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt sources list directory exists] *******
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt keyrings directory exists] ***********
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt gpg key] *********************
changed: [localhost]

TASK [openstack.kolla.docker : Install docker apt pin] *************************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure old docker repository absent] ************
changed: [localhost]

TASK [openstack.kolla.docker : Enable docker apt repository] *******************
changed: [localhost]

TASK [openstack.kolla.docker : Update the apt cache] ***************************
changed: [localhost]

TASK [openstack.kolla.docker : Check which containers are running] *************
ok: [localhost]

TASK [openstack.kolla.docker : Check if docker systemd unit exists] ************
ok: [localhost]

TASK [openstack.kolla.docker : Mask the docker systemd unit on Debian/Ubuntu] ***
changed: [localhost]

TASK [openstack.kolla.docker : Install packages] *******************************
ok: [localhost]

TASK [openstack.kolla.docker : Start docker] ***********************************
skipping: [localhost]

TASK [openstack.kolla.docker : Wait for Docker to start] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure containers are running after Docker upgrade] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure docker config directory exists] **********
ok: [localhost]

TASK [openstack.kolla.docker : Write docker config] ****************************
changed: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

RUNNING HANDLER [openstack.kolla.docker : Restart docker] **********************
changed: [localhost]

TASK [openstack.kolla.docker : Get Docker API version] *************************
ok: [localhost]

TASK [openstack.kolla.docker : Parse Docker system info] ***********************
ok: [localhost]

TASK [openstack.kolla.docker : Determine if Docker uses containerd image store] ***
ok: [localhost]

TASK [openstack.kolla.docker : Copying over containerd config] *****************
changed: [localhost]

TASK [openstack.kolla.docker : Remove old docker options file] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Ensure docker service directory exists] *********
skipping: [localhost]

TASK [openstack.kolla.docker : Configure docker service] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the path for CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

RUNNING HANDLER [openstack.kolla.docker : Restart containerd] ******************
changed: [localhost]

TASK [openstack.kolla.docker : Start and enable docker] ************************
ok: [localhost]

TASK [openstack.kolla.docker : Configure containerd for Zun] *******************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Ensure groups are present] ******************
skipping: [localhost] => (item=docker) 
skipping: [localhost] => (item=sudo) 
skipping: [localhost] => (item=kolla) 
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Create kolla user] **************************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Add public key to kolla user authorized keys] ***
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Grant kolla user passwordless sudo] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Get Python] *********************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if Python environment is externally managed] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Set docker_sdk_python_externally_managed fact] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Install/Uninstall] **************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker_sdk/tasks/install.yml for localhost

TASK [openstack.kolla.docker_sdk : Ensure apt sources list directory exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Ensure apt keyrings directory exists] *******
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install osbpo apt gpg key] ******************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Enable osbpo apt repository] ****************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packages] ***************************
changed: [localhost]

TASK [openstack.kolla.docker_sdk : Check if virtualenv is a directory] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Check if packaging is already installed] ****
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packaging into virtualenv] **********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install latest pip and packaging in the virtualenv] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install docker SDK for python using pip] ****
skipping: [localhost]

TASK [openstack.kolla.baremetal : Ensure node_config_directory directory exists] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Include tasks from remove-profile.yml] ***
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/apparmor_libvirt/tasks/remove-profile.yml for localhost

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor disable profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Remove apparmor profile for libvirt] ***
skipping: [localhost]

TASK [openstack.kolla.baremetal : Change state of selinux] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set https proxy for git] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set http proxy for git] **********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Copying over kolla.target] *******************
changed: [localhost]

TASK [openstack.kolla.baremetal : Configure ceph for zun] **********************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=44   changed=14   unreachable=0    failed=0    skipped=30   rescued=0    ignored=0   

[2025-12-09 21:32:44] Ejecutando prechecks

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************

TASK [prechecks : Checking loadbalancer group] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/host_os_checks.yml for localhost

TASK [prechecks : Checking host OS distribution] *******************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking host OS release or version] *************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking if CentOS is Stream] ********************************
skipping: [localhost]

TASK [prechecks : Fail if not running on CentOS Stream] ************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/localtime exist] *********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/localtime is absent] ****************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/timezone exist] **********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/timezone is absent] *****************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Checking if system uses systemd] *****************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking Docker version] *************************************
ok: [localhost]

TASK [prechecks : Checking empty passwords in passwords.yml. Run kolla-genpwd if this task fails] ***
ok: [localhost]

TASK [prechecks : Check if nscd is running] ************************************
ok: [localhost]

TASK [prechecks : Fail if nscd is running] *************************************
skipping: [localhost]

TASK [prechecks : Validate that internal and external vip address are different when TLS is enabled only on either the internal and external network] ***
skipping: [localhost]

TASK [prechecks : Validate that enable_ceph is disabled] ***********************
skipping: [localhost]

TASK [prechecks : Validate that enable_redis is disabled] **********************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking docker SDK version] *********************************
ok: [localhost]

TASK [prechecks : Checking dbus-python package] ********************************
fatal: [localhost]: FAILED! => {"changed": false, "cmd": ["/home/nics/openstack_venv/bin/python3.12", "-c", "import dbus"], "delta": "0:00:00.023520", "end": "2025-12-09 21:32:51.930621", "failed_when_result": true, "msg": "non-zero return code", "rc": 1, "start": "2025-12-09 21:32:51.907101", "stderr": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'dbus'", "stderr_lines": ["Traceback (most recent call last):", "  File \"<string>\", line 1, in <module>", "ModuleNotFoundError: No module named 'dbus'"], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
localhost                  : ok=16   changed=0    unreachable=0    failed=1    skipped=9    rescued=0    ignored=0   

[2025-12-10 12:36:53] Iniciando comprobación de permisos
[2025-12-10 12:36:53] Usuario ejecutor: nics (UID=1000)
[2025-12-10 12:36:53] Grupos: nics adm cdrom sudo dip plugdev users lpadmin
[2025-12-10 12:36:53] Permisos sudo verificados correctamente
[2025-12-10 12:36:53] Instalando dependencias base requeridas por Kolla-Ansible (según Quick-Start)
[2025-12-10 12:37:54] Dependencias del sistema instaladas correctamente
[2025-12-10 12:37:54] Configurando repositorio oficial de Docker (limpieza previa + instalación limpia)
[2025-12-10 12:37:54] Descargando clave GPG oficial de Docker
[2025-12-10 12:37:54] Registrando el repositorio estable de Docker para noble (amd64)
[2025-12-10 12:37:54] Instalando Docker Engine y runtime soportado por Kolla
[2025-12-10 12:38:18] Habilitando servicio docker y añadiendo usuario actual al grupo docker
[2025-12-10 12:38:20] Usuario añadido al grupo docker (es necesario un nuevo login para aplicar el cambio)
[2025-12-10 12:38:20] Instalación de Docker completada
[2025-12-10 12:38:20] Creando entorno virtual en /home/nics/openstack_venv
[2025-12-10 12:38:32] Entorno virtual activado: /home/nics/openstack_venv/bin/python
[2025-12-10 12:38:32] Instalando dependencias Python para Kolla-Ansible desde /home/nics/Desktop/nicscyberlab_v1/infrastructure/openstack/configs/requirements-kolla.txt
[2025-12-10 12:41:19] Iniciando comprobación de permisos
[2025-12-10 12:41:19] Usuario ejecutor: nics (UID=1000)
[2025-12-10 12:41:19] Grupos: nics adm cdrom sudo dip plugdev users lpadmin
[2025-12-10 12:41:19] Permisos sudo verificados correctamente
[2025-12-10 12:41:19] Instalando dependencias base requeridas por Kolla-Ansible (según Quick-Start)
[2025-12-10 12:41:23] Dependencias del sistema instaladas correctamente
[2025-12-10 12:41:23] Configurando repositorio oficial de Docker (limpieza previa + instalación limpia)
[2025-12-10 12:41:23] Descargando clave GPG oficial de Docker
[2025-12-10 12:41:24] Registrando el repositorio estable de Docker para noble (amd64)
[2025-12-10 12:41:24] Instalando Docker Engine y runtime soportado por Kolla
[2025-12-10 12:41:28] Habilitando servicio docker y añadiendo usuario actual al grupo docker
[2025-12-10 12:41:32] El usuario nics ya pertenece al grupo docker
[2025-12-10 12:41:32] Instalación de Docker completada
[2025-12-10 12:41:32] Creando entorno virtual en /home/nics/openstack_venv
[2025-12-10 12:41:38] Entorno virtual activado: /home/nics/openstack_venv/bin/python
[2025-12-10 12:41:38] Instalando dependencias Python para Kolla-Ansible desde /home/nics/Desktop/nicscyberlab_v1/infrastructure/openstack/configs/requirements-kolla.txt
[2025-12-10 12:43:18] Dependencias Python y Kolla-Ansible instaladas correctamente
[2025-12-10 12:43:18] Configurando red virtual para OpenStack (veth + uplinkbridge)
[2025-12-10 12:43:18] Interfaz externa detectada: ens34
[2025-12-10 12:43:18] Interfaz veth0/veth1 creada
[2025-12-10 12:43:18] Bridge uplinkbridge creado
[2025-12-10 12:43:18] IP 10.0.2.1/24 asignada a uplinkbridge
[2025-12-10 12:43:18] Regla NAT añadida para 10.0.2.0/24 sobre ens34
[2025-12-10 12:43:18] Regla FORWARD añadida para 10.0.2.0/24
[2025-12-10 12:43:18] Red uplinkbridge + veth configurada correctamente
[2025-12-10 12:43:18] Configurando Kolla-Ansible en /etc/kolla
[2025-12-10 12:43:18] Asegurando inventario all-in-one en /etc/kolla/ansible/inventory/all-in-one
[2025-12-10 12:43:18] passwords.yml ya contiene contraseñas generadas
[2025-12-10 12:43:19] Interfaz management: ens34
[2025-12-10 12:43:19] Interfaz externa:    veth1
[2025-12-10 12:43:19] VIP seleccionada:    192.168.0.200
[2025-12-10 12:43:19] Archivo globals.yml generado a partir de la plantilla oficial
[2025-12-10 12:43:19] === Iniciando despliegue de OpenStack con Kolla-Ansible ===
[2025-12-10 12:43:19] Activando entorno virtual: /home/nics/openstack_venv
[2025-12-10 12:43:19] Instalando dependencias Galaxy (kolla-ansible install-deps)
Your branch is up to date with 'origin/master'.
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Installing 'openstack.kolla:1.0.0' to '/home/nics/.ansible/collections/ansible_collections/openstack/kolla'
Created collection for openstack.kolla:1.0.0 at /home/nics/.ansible/collections/ansible_collections/openstack/kolla
openstack.kolla:1.0.0 was installed successfully
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-posix-2.1.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/ansible-posix-2.1.0-155cq946
Installing 'ansible.posix:2.1.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/posix'
ansible.posix:2.1.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-utils-6.0.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/ansible-utils-6.0.0-p7jm8pcr
Installing 'ansible.utils:6.0.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/utils'
ansible.utils:6.0.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-netcommon-8.2.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/ansible-netcommon-8.2.0-wk305l4d
Installing 'ansible.netcommon:8.2.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/netcommon'
ansible.netcommon:8.2.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/containers-podman-1.18.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/containers-podman-1.18.0-y6nhatd1
Installing 'containers.podman:1.18.0' to '/home/nics/.ansible/collections/ansible_collections/containers/podman'
containers.podman:1.18.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-crypto-3.0.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/community-crypto-3.0.5-jiddpzvt
Installing 'community.crypto:3.0.5' to '/home/nics/.ansible/collections/ansible_collections/community/crypto'
community.crypto:3.0.5 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-docker-4.8.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/community-docker-4.8.5-2yur78c9
Installing 'community.docker:4.8.5' to '/home/nics/.ansible/collections/ansible_collections/community/docker'
community.docker:4.8.5 was installed successfully
'community.library_inventory_filtering_v1:1.1.1' is already installed, skipping.
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-general-11.4.2.tar.gz to /home/nics/.ansible/tmp/ansible-local-39581a4_mh5zn/tmpkuocxbq7/community-general-11.4.2-eglk9q__
Installing 'community.general:11.4.2' to '/home/nics/.ansible/collections/ansible_collections/community/general'
community.general:11.4.2 was installed successfully
[2025-12-10 12:44:08] Ejecutando bootstrap-servers

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Apply role baremetal] ****************************************************

TASK [openstack.kolla.etc_hosts : Include etc-hosts.yml] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/etc_hosts/tasks/etc-hosts.yml for localhost

TASK [openstack.kolla.etc_hosts : Ensure localhost in /etc/hosts] **************
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Ensure hostname does not point to 127.0.1.1 in /etc/hosts] ***
changed: [localhost]

TASK [openstack.kolla.etc_hosts : Generate /etc/hosts for all of the nodes] ****
changed: [localhost]

TASK [openstack.kolla.etc_hosts : Check whether /etc/cloud/cloud.cfg exists] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Disable cloud-init manage_etc_hosts] *********
changed: [localhost]

TASK [openstack.kolla.baremetal : Ensure unprivileged users can use ping] ******
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set firewall default policy] *****************
ok: [localhost]

TASK [openstack.kolla.baremetal : Check if firewalld is installed] *************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Disable firewalld] ***************************
skipping: [localhost] => (item=firewalld) 
skipping: [localhost]

TASK [openstack.kolla.packages : Install packages] *****************************
ok: [localhost]

TASK [openstack.kolla.packages : Remove packages] ******************************
ok: [localhost]

TASK [openstack.kolla.docker : Install/Uninstall] ******************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/install.yml for localhost

TASK [openstack.kolla.docker : Enable Docker repository] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/repo-Debian.yml for localhost

TASK [openstack.kolla.docker : Install CA certificates and gnupg packages] *****
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt sources list directory exists] *******
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt keyrings directory exists] ***********
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt gpg key] *********************
changed: [localhost]

TASK [openstack.kolla.docker : Install docker apt pin] *************************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure old docker repository absent] ************
changed: [localhost]

TASK [openstack.kolla.docker : Enable docker apt repository] *******************
changed: [localhost]

TASK [openstack.kolla.docker : Update the apt cache] ***************************
changed: [localhost]

TASK [openstack.kolla.docker : Check which containers are running] *************
ok: [localhost]

TASK [openstack.kolla.docker : Check if docker systemd unit exists] ************
ok: [localhost]

TASK [openstack.kolla.docker : Mask the docker systemd unit on Debian/Ubuntu] ***
changed: [localhost]

TASK [openstack.kolla.docker : Install packages] *******************************
ok: [localhost]

TASK [openstack.kolla.docker : Start docker] ***********************************
skipping: [localhost]

TASK [openstack.kolla.docker : Wait for Docker to start] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure containers are running after Docker upgrade] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure docker config directory exists] **********
ok: [localhost]

TASK [openstack.kolla.docker : Write docker config] ****************************
changed: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

RUNNING HANDLER [openstack.kolla.docker : Restart docker] **********************
changed: [localhost]

TASK [openstack.kolla.docker : Get Docker API version] *************************
ok: [localhost]

TASK [openstack.kolla.docker : Parse Docker system info] ***********************
ok: [localhost]

TASK [openstack.kolla.docker : Determine if Docker uses containerd image store] ***
ok: [localhost]

TASK [openstack.kolla.docker : Copying over containerd config] *****************
changed: [localhost]

TASK [openstack.kolla.docker : Remove old docker options file] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Ensure docker service directory exists] *********
skipping: [localhost]

TASK [openstack.kolla.docker : Configure docker service] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the path for CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

RUNNING HANDLER [openstack.kolla.docker : Restart containerd] ******************
changed: [localhost]

TASK [openstack.kolla.docker : Start and enable docker] ************************
ok: [localhost]

TASK [openstack.kolla.docker : Configure containerd for Zun] *******************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Ensure groups are present] ******************
skipping: [localhost] => (item=docker) 
skipping: [localhost] => (item=sudo) 
skipping: [localhost] => (item=kolla) 
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Create kolla user] **************************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Add public key to kolla user authorized keys] ***
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Grant kolla user passwordless sudo] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Get Python] *********************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if Python environment is externally managed] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Set docker_sdk_python_externally_managed fact] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Install/Uninstall] **************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker_sdk/tasks/install.yml for localhost

TASK [openstack.kolla.docker_sdk : Ensure apt sources list directory exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Ensure apt keyrings directory exists] *******
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install osbpo apt gpg key] ******************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Enable osbpo apt repository] ****************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packages] ***************************
changed: [localhost]

TASK [openstack.kolla.docker_sdk : Check if virtualenv is a directory] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Check if packaging is already installed] ****
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packaging into virtualenv] **********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install latest pip and packaging in the virtualenv] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install docker SDK for python using pip] ****
skipping: [localhost]

TASK [openstack.kolla.baremetal : Ensure node_config_directory directory exists] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Include tasks from remove-profile.yml] ***
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/apparmor_libvirt/tasks/remove-profile.yml for localhost

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor disable profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Remove apparmor profile for libvirt] ***
skipping: [localhost]

TASK [openstack.kolla.baremetal : Change state of selinux] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set https proxy for git] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set http proxy for git] **********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Copying over kolla.target] *******************
changed: [localhost]

TASK [openstack.kolla.baremetal : Configure ceph for zun] **********************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=44   changed=14   unreachable=0    failed=0    skipped=30   rescued=0    ignored=0   

[2025-12-10 12:44:49] Ejecutando prechecks

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************

TASK [prechecks : Checking loadbalancer group] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/host_os_checks.yml for localhost

TASK [prechecks : Checking host OS distribution] *******************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking host OS release or version] *************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking if CentOS is Stream] ********************************
skipping: [localhost]

TASK [prechecks : Fail if not running on CentOS Stream] ************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/localtime exist] *********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/localtime is absent] ****************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/timezone exist] **********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/timezone is absent] *****************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Checking if system uses systemd] *****************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking Docker version] *************************************
ok: [localhost]

TASK [prechecks : Checking empty passwords in passwords.yml. Run kolla-genpwd if this task fails] ***
fatal: [localhost]: FAILED! => {"changed": false, "cmd": ["grep", "^[^#].*:\\s*$", "/etc/kolla/passwords.yml"], "delta": "0:00:00.006702", "end": "2025-12-10 12:44:55.397044", "failed_when_result": true, "msg": "", "rc": 0, "start": "2025-12-10 12:44:55.390342", "stderr": "", "stderr_lines": [], "stdout": "rbd_secret_uuid:\ncinder_rbd_secret_uuid:\ndatabase_password:\nmariadb_backup_database_password:\nmariadb_monitor_password:\ndocker_registry_password:\nhnas_nfs_password:\ninfoblox_admin_password:\naodh_database_password:\naodh_keystone_password:\nbarbican_database_password:\nbarbican_keystone_password:\nbarbican_p11_password:\nbarbican_crypto_key:\nblazar_database_password:\nblazar_keystone_password:\nkeystone_admin_password:\nkeystone_database_password:\ngrafana_database_password:\ngrafana_admin_password:\nglance_database_password:\nglance_keystone_password:\ngnocchi_database_password:\ngnocchi_keystone_password:\nkuryr_keystone_password:\nnova_database_password:\nnova_api_database_password:\nnova_keystone_password:\nplacement_keystone_password:\nplacement_database_password:\nneutron_database_password:\nneutron_keystone_password:\nmetadata_secret:\ncinder_database_password:\ncinder_keystone_password:\ncloudkitty_database_password:\ncloudkitty_keystone_password:\ncyborg_database_password:\ncyborg_keystone_password:\ndesignate_database_password:\ndesignate_keystone_password:\ndesignate_pool_id:\ndesignate_rndc_key:\nheat_database_password:\nheat_keystone_password:\nheat_domain_admin_password:\nironic_database_password:\nironic_keystone_password:\nmagnum_database_password:\nmagnum_keystone_password:\nmistral_database_password:\nmistral_keystone_password:\ntrove_database_password:\ntrove_keystone_password:\nceilometer_database_password:\nceilometer_keystone_password:\nwatcher_database_password:\nwatcher_keystone_password:\nhorizon_secret_key:\nhorizon_database_password:\ntelemetry_secret_key:\nmanila_database_password:\nmanila_keystone_password:\noctavia_database_password:\noctavia_persistence_database_password:\noctavia_keystone_password:\noctavia_ca_password:\noctavia_client_ca_password:\ntacker_database_password:\ntacker_keystone_password:\nzun_database_password:\nzun_keystone_password:\nmasakari_database_password:\nmasakari_keystone_password:\nmemcache_secret_key:\nskyline_secret_key:\nskyline_database_password:\nskyline_keystone_password:\nosprofiler_secret:\nnova_ssh_key:\n  private_key:\n  public_key:\nkolla_ssh_key:\n  private_key:\n  public_key:\nkeystone_ssh_key:\n  private_key:\n  public_key:\nbifrost_ssh_key:\n  private_key:\n  public_key:\noctavia_amp_ssh_key:\n  private_key:\n  public_key:\nneutron_ssh_key:\n  private_key:\n  public_key:\nhaproxy_ssh_key:\n  private_key:\n  public_key:\ngnocchi_project_id:\ngnocchi_resource_id:\ngnocchi_user_id:\nrabbitmq_password:\nrabbitmq_monitoring_password:\nrabbitmq_cluster_cookie:\nhaproxy_password:\nkeepalived_password:\netcd_cluster_token:\nvalkey_master_password:\nredis_master_password:\nprometheus_mysql_exporter_database_password:\nprometheus_alertmanager_password:\nprometheus_password:\nprometheus_grafana_password:\nprometheus_haproxy_password:\nprometheus_skyline_password:\nprometheus_bcrypt_salt:\nkeystone_federation_openid_crypto_password:\nceph_rgw_keystone_password:\nlibvirt_sasl_password:\nproxysql_admin_password:\nproxysql_stats_password:\nopensearch_dashboards_password:", "stdout_lines": ["rbd_secret_uuid:", "cinder_rbd_secret_uuid:", "database_password:", "mariadb_backup_database_password:", "mariadb_monitor_password:", "docker_registry_password:", "hnas_nfs_password:", "infoblox_admin_password:", "aodh_database_password:", "aodh_keystone_password:", "barbican_database_password:", "barbican_keystone_password:", "barbican_p11_password:", "barbican_crypto_key:", "blazar_database_password:", "blazar_keystone_password:", "keystone_admin_password:", "keystone_database_password:", "grafana_database_password:", "grafana_admin_password:", "glance_database_password:", "glance_keystone_password:", "gnocchi_database_password:", "gnocchi_keystone_password:", "kuryr_keystone_password:", "nova_database_password:", "nova_api_database_password:", "nova_keystone_password:", "placement_keystone_password:", "placement_database_password:", "neutron_database_password:", "neutron_keystone_password:", "metadata_secret:", "cinder_database_password:", "cinder_keystone_password:", "cloudkitty_database_password:", "cloudkitty_keystone_password:", "cyborg_database_password:", "cyborg_keystone_password:", "designate_database_password:", "designate_keystone_password:", "designate_pool_id:", "designate_rndc_key:", "heat_database_password:", "heat_keystone_password:", "heat_domain_admin_password:", "ironic_database_password:", "ironic_keystone_password:", "magnum_database_password:", "magnum_keystone_password:", "mistral_database_password:", "mistral_keystone_password:", "trove_database_password:", "trove_keystone_password:", "ceilometer_database_password:", "ceilometer_keystone_password:", "watcher_database_password:", "watcher_keystone_password:", "horizon_secret_key:", "horizon_database_password:", "telemetry_secret_key:", "manila_database_password:", "manila_keystone_password:", "octavia_database_password:", "octavia_persistence_database_password:", "octavia_keystone_password:", "octavia_ca_password:", "octavia_client_ca_password:", "tacker_database_password:", "tacker_keystone_password:", "zun_database_password:", "zun_keystone_password:", "masakari_database_password:", "masakari_keystone_password:", "memcache_secret_key:", "skyline_secret_key:", "skyline_database_password:", "skyline_keystone_password:", "osprofiler_secret:", "nova_ssh_key:", "  private_key:", "  public_key:", "kolla_ssh_key:", "  private_key:", "  public_key:", "keystone_ssh_key:", "  private_key:", "  public_key:", "bifrost_ssh_key:", "  private_key:", "  public_key:", "octavia_amp_ssh_key:", "  private_key:", "  public_key:", "neutron_ssh_key:", "  private_key:", "  public_key:", "haproxy_ssh_key:", "  private_key:", "  public_key:", "gnocchi_project_id:", "gnocchi_resource_id:", "gnocchi_user_id:", "rabbitmq_password:", "rabbitmq_monitoring_password:", "rabbitmq_cluster_cookie:", "haproxy_password:", "keepalived_password:", "etcd_cluster_token:", "valkey_master_password:", "redis_master_password:", "prometheus_mysql_exporter_database_password:", "prometheus_alertmanager_password:", "prometheus_password:", "prometheus_grafana_password:", "prometheus_haproxy_password:", "prometheus_skyline_password:", "prometheus_bcrypt_salt:", "keystone_federation_openid_crypto_password:", "ceph_rgw_keystone_password:", "libvirt_sasl_password:", "proxysql_admin_password:", "proxysql_stats_password:", "opensearch_dashboards_password:"]}

PLAY RECAP *********************************************************************
localhost                  : ok=12   changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   

[2025-12-10 12:49:45] Iniciando comprobación de permisos
[2025-12-10 12:49:45] Usuario ejecutor: nics (UID=1000)
[2025-12-10 12:49:45] Grupos: nics adm cdrom sudo dip plugdev users lpadmin
[2025-12-10 12:49:45] Permisos sudo verificados correctamente
[2025-12-10 12:49:45] Instalando dependencias base requeridas por Kolla-Ansible (según Quick-Start)
[2025-12-10 12:49:49] Dependencias del sistema instaladas correctamente
[2025-12-10 12:49:49] Configurando repositorio oficial de Docker (limpieza previa + instalación limpia)
[2025-12-10 12:49:49] Descargando clave GPG oficial de Docker
[2025-12-10 12:49:49] Registrando el repositorio estable de Docker para noble (amd64)
[2025-12-10 12:49:49] Instalando Docker Engine y runtime soportado por Kolla
[2025-12-10 12:49:53] Habilitando servicio docker y añadiendo usuario actual al grupo docker
[2025-12-10 12:49:55] El usuario nics ya pertenece al grupo docker
[2025-12-10 12:49:55] Instalación de Docker completada
[2025-12-10 12:49:55] Creando entorno virtual en /home/nics/openstack_venv
[2025-12-10 12:50:04] Entorno virtual activado: /home/nics/openstack_venv/bin/python
[2025-12-10 12:50:04] Instalando dependencias Python para Kolla-Ansible desde /home/nics/Desktop/nicscyberlab_v1/infrastructure/openstack/configs/requirements-kolla.txt
[2025-12-10 12:50:23] Dependencias Python y Kolla-Ansible instaladas correctamente
[2025-12-10 12:50:23] Configurando red virtual para OpenStack (veth + uplinkbridge)
[2025-12-10 12:50:23] Interfaz externa detectada: ens34
[2025-12-10 12:50:23] veth0/veth1 ya existen, no se recrean
[2025-12-10 12:50:23] Bridge uplinkbridge ya existe
[2025-12-10 12:50:23] IP 10.0.2.1/24 ya estaba asignada a uplinkbridge
[2025-12-10 12:50:23] Regla NAT añadida para 10.0.2.0/24 sobre ens34
[2025-12-10 12:50:23] Regla FORWARD añadida para 10.0.2.0/24
[2025-12-10 12:50:23] Red uplinkbridge + veth configurada correctamente
[2025-12-10 12:50:23] Configurando Kolla-Ansible en /etc/kolla
[2025-12-10 12:50:24] Asegurando inventario all-in-one en /etc/kolla/ansible/inventory/all-in-one
[2025-12-10 12:50:24] Inventario existente detectado; no se sobrescribe
[2025-12-10 12:50:24] Ejecutando kolla-genpwd para garantizar contraseñas completas
[2025-12-10 12:50:30] Interfaz management: ens34
[2025-12-10 12:50:30] Interfaz externa:    veth1
[2025-12-10 12:50:30] VIP seleccionada:    192.168.0.200
[2025-12-10 12:50:30] Archivo globals.yml generado a partir de la plantilla oficial
[2025-12-10 12:50:31] === Iniciando despliegue de OpenStack con Kolla-Ansible ===
[2025-12-10 12:50:31] Activando entorno virtual: /home/nics/openstack_venv
[2025-12-10 12:50:31] Instalando dependencias Galaxy (kolla-ansible install-deps)
Your branch is up to date with 'origin/master'.
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Installing 'openstack.kolla:1.0.0' to '/home/nics/.ansible/collections/ansible_collections/openstack/kolla'
Created collection for openstack.kolla:1.0.0 at /home/nics/.ansible/collections/ansible_collections/openstack/kolla
openstack.kolla:1.0.0 was installed successfully
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-posix-2.1.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/ansible-posix-2.1.0-qti1llkd
Installing 'ansible.posix:2.1.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/posix'
ansible.posix:2.1.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-utils-6.0.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/ansible-utils-6.0.0-annsp974
Installing 'ansible.utils:6.0.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/utils'
ansible.utils:6.0.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-netcommon-8.2.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/ansible-netcommon-8.2.0-g80redpd
Installing 'ansible.netcommon:8.2.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/netcommon'
ansible.netcommon:8.2.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/containers-podman-1.18.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/containers-podman-1.18.0-ki_2nxgy
Installing 'containers.podman:1.18.0' to '/home/nics/.ansible/collections/ansible_collections/containers/podman'
containers.podman:1.18.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-crypto-3.0.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/community-crypto-3.0.5-clo8nqak
Installing 'community.crypto:3.0.5' to '/home/nics/.ansible/collections/ansible_collections/community/crypto'
community.crypto:3.0.5 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-docker-4.8.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/community-docker-4.8.5-s3x63gf_
Installing 'community.docker:4.8.5' to '/home/nics/.ansible/collections/ansible_collections/community/docker'
community.docker:4.8.5 was installed successfully
'community.library_inventory_filtering_v1:1.1.1' is already installed, skipping.
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-general-11.4.2.tar.gz to /home/nics/.ansible/tmp/ansible-local-45057s0j1wcvk/tmpjtzgiza4/community-general-11.4.2-dvsd_70o
Installing 'community.general:11.4.2' to '/home/nics/.ansible/collections/ansible_collections/community/general'
community.general:11.4.2 was installed successfully
[2025-12-10 12:51:06] Ejecutando bootstrap-servers

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Apply role baremetal] ****************************************************

TASK [openstack.kolla.etc_hosts : Include etc-hosts.yml] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/etc_hosts/tasks/etc-hosts.yml for localhost

TASK [openstack.kolla.etc_hosts : Ensure localhost in /etc/hosts] **************
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Ensure hostname does not point to 127.0.1.1 in /etc/hosts] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Generate /etc/hosts for all of the nodes] ****
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Check whether /etc/cloud/cloud.cfg exists] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Disable cloud-init manage_etc_hosts] *********
ok: [localhost]

TASK [openstack.kolla.baremetal : Ensure unprivileged users can use ping] ******
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set firewall default policy] *****************
ok: [localhost]

TASK [openstack.kolla.baremetal : Check if firewalld is installed] *************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Disable firewalld] ***************************
skipping: [localhost] => (item=firewalld) 
skipping: [localhost]

TASK [openstack.kolla.packages : Install packages] *****************************
ok: [localhost]

TASK [openstack.kolla.packages : Remove packages] ******************************
ok: [localhost]

TASK [openstack.kolla.docker : Install/Uninstall] ******************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/install.yml for localhost

TASK [openstack.kolla.docker : Enable Docker repository] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/repo-Debian.yml for localhost

TASK [openstack.kolla.docker : Install CA certificates and gnupg packages] *****
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt sources list directory exists] *******
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt keyrings directory exists] ***********
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt gpg key] *********************
changed: [localhost]

TASK [openstack.kolla.docker : Install docker apt pin] *************************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure old docker repository absent] ************
changed: [localhost]

TASK [openstack.kolla.docker : Enable docker apt repository] *******************
changed: [localhost]

TASK [openstack.kolla.docker : Update the apt cache] ***************************
changed: [localhost]

TASK [openstack.kolla.docker : Check which containers are running] *************
ok: [localhost]

TASK [openstack.kolla.docker : Check if docker systemd unit exists] ************
ok: [localhost]

TASK [openstack.kolla.docker : Mask the docker systemd unit on Debian/Ubuntu] ***
changed: [localhost]

TASK [openstack.kolla.docker : Install packages] *******************************
ok: [localhost]

TASK [openstack.kolla.docker : Start docker] ***********************************
skipping: [localhost]

TASK [openstack.kolla.docker : Wait for Docker to start] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure containers are running after Docker upgrade] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure docker config directory exists] **********
ok: [localhost]

TASK [openstack.kolla.docker : Write docker config] ****************************
ok: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Get Docker API version] *************************
ok: [localhost]

TASK [openstack.kolla.docker : Parse Docker system info] ***********************
ok: [localhost]

TASK [openstack.kolla.docker : Determine if Docker uses containerd image store] ***
ok: [localhost]

TASK [openstack.kolla.docker : Copying over containerd config] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Remove old docker options file] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Ensure docker service directory exists] *********
skipping: [localhost]

TASK [openstack.kolla.docker : Configure docker service] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the path for CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Start and enable docker] ************************
changed: [localhost]

TASK [openstack.kolla.docker : Configure containerd for Zun] *******************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Ensure groups are present] ******************
skipping: [localhost] => (item=docker) 
skipping: [localhost] => (item=sudo) 
skipping: [localhost] => (item=kolla) 
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Create kolla user] **************************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Add public key to kolla user authorized keys] ***
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Grant kolla user passwordless sudo] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Get Python] *********************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if Python environment is externally managed] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Set docker_sdk_python_externally_managed fact] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Install/Uninstall] **************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker_sdk/tasks/install.yml for localhost

TASK [openstack.kolla.docker_sdk : Ensure apt sources list directory exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Ensure apt keyrings directory exists] *******
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install osbpo apt gpg key] ******************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Enable osbpo apt repository] ****************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packages] ***************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if virtualenv is a directory] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Check if packaging is already installed] ****
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packaging into virtualenv] **********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install latest pip and packaging in the virtualenv] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install docker SDK for python using pip] ****
skipping: [localhost]

TASK [openstack.kolla.baremetal : Ensure node_config_directory directory exists] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Include tasks from remove-profile.yml] ***
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/apparmor_libvirt/tasks/remove-profile.yml for localhost

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor disable profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Remove apparmor profile for libvirt] ***
skipping: [localhost]

TASK [openstack.kolla.baremetal : Change state of selinux] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set https proxy for git] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set http proxy for git] **********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Copying over kolla.target] *******************
ok: [localhost]

TASK [openstack.kolla.baremetal : Configure ceph for zun] **********************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=42   changed=6    unreachable=0    failed=0    skipped=30   rescued=0    ignored=0   

[2025-12-10 12:51:39] Ejecutando prechecks

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************

TASK [prechecks : Checking loadbalancer group] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/host_os_checks.yml for localhost

TASK [prechecks : Checking host OS distribution] *******************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking host OS release or version] *************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking if CentOS is Stream] ********************************
skipping: [localhost]

TASK [prechecks : Fail if not running on CentOS Stream] ************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/localtime exist] *********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/localtime is absent] ****************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/timezone exist] **********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/timezone is absent] *****************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Checking if system uses systemd] *****************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking Docker version] *************************************
ok: [localhost]

TASK [prechecks : Checking empty passwords in passwords.yml. Run kolla-genpwd if this task fails] ***
ok: [localhost]

TASK [prechecks : Check if nscd is running] ************************************
ok: [localhost]

TASK [prechecks : Fail if nscd is running] *************************************
skipping: [localhost]

TASK [prechecks : Validate that internal and external vip address are different when TLS is enabled only on either the internal and external network] ***
skipping: [localhost]

TASK [prechecks : Validate that enable_ceph is disabled] ***********************
skipping: [localhost]

TASK [prechecks : Validate that enable_redis is disabled] **********************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking docker SDK version] *********************************
ok: [localhost]

TASK [prechecks : Checking dbus-python package] ********************************
ok: [localhost]

TASK [prechecks : Checking Ansible version] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Check if config_owner_user existed] **************************
ok: [localhost]

TASK [prechecks : Check if config_owner_group existed] *************************
ok: [localhost]

TASK [prechecks : Check if ansible user can do passwordless sudo] **************
ok: [localhost]

TASK [prechecks : Check if external mariadb hosts are reachable from the load balancer] ***
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [prechecks : Check if external database address is reachable from all hosts] ***
skipping: [localhost]

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/precheck.yml for localhost

TASK [service-precheck : common | Validate inventory groups] *******************
skipping: [localhost] => (item=kolla-toolbox) 
skipping: [localhost]

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/precheck.yml for localhost

TASK [service-precheck : cron | Validate inventory groups] *********************
skipping: [localhost] => (item=cron) 
skipping: [localhost]

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/precheck.yml for localhost

TASK [service-precheck : fluentd | Validate inventory groups] ******************
skipping: [localhost] => (item=fluentd) 
skipping: [localhost]

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/precheck.yml for localhost

TASK [service-precheck : loadbalancer | Validate inventory groups] *************
skipping: [localhost] => (item=haproxy) 
skipping: [localhost] => (item=proxysql) 
skipping: [localhost] => (item=keepalived) 
skipping: [localhost] => (item=haproxy-ssh) 
skipping: [localhost]

TASK [loadbalancer : Get container facts] **************************************
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running keepalived] *******
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running HAProxy] **********
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running ProxySQL] *********
ok: [localhost]

TASK [loadbalancer : Set facts about whether we can run HAProxy and keepalived VIP prechecks] ***
ok: [localhost]

TASK [loadbalancer : Checking if external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking if internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is present] *****
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is active] ******
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address and kolla_external_vip_address are not pingable from any node] ***
ok: [localhost] => (item=192.168.0.200)
ok: [localhost] => (item=192.168.0.200)

TASK [loadbalancer : Checking free port for HAProxy stats] *********************
ok: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (api interface)] ***
ok: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (vip interface)] ***
ok: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (api interface)] ****
ok: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (vip interface)] ****
ok: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (api interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (vip interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address is in the same network as api_interface on all nodes] ***
ok: [localhost]

TASK [loadbalancer : Getting haproxy stat] *************************************
skipping: [localhost]

TASK [loadbalancer : Setting haproxy stat fact] ********************************
ok: [localhost]

TASK [loadbalancer : Checking free port for Aodh API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Barbican API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Blazar API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Ceph RadosGW HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cinder API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cloudkitty API HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cyborg API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Designate API HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Glance API HAProxy] ****************
ok: [localhost]

TASK [loadbalancer : Checking free port for Gnocchi API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Grafana server HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Heat API HAProxy] ******************
ok: [localhost]

TASK [loadbalancer : Checking free port for Heat API CFN HAProxy] **************
ok: [localhost]

TASK [loadbalancer : Checking free port for Horizon HAProxy] *******************
ok: [localhost]

TASK [loadbalancer : Checking free port for Ironic API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Keystone Internal HAProxy] *********
ok: [localhost]

TASK [loadbalancer : Checking free port for Keystone Public HAProxy] ***********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Magnum API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Manila API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for MariaDB HAProxy/ProxySQL] **********
ok: [localhost]

TASK [loadbalancer : Checking free port for Masakari API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Mistral API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Neutron Server HAProxy] ************
ok: [localhost]

TASK [loadbalancer : Checking free port for Nova API HAProxy] ******************
ok: [localhost]

TASK [loadbalancer : Checking free port for Nova Metadata HAProxy] *************
ok: [localhost]

TASK [loadbalancer : Checking free port for Nova NoVNC HAProxy] ****************
ok: [localhost]

TASK [loadbalancer : Checking free port for Nova Serial Proxy HAProxy] *********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Spice HTML5 HAProxy] **********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Placement API HAProxy] ********
ok: [localhost]

TASK [loadbalancer : Checking free port for Octavia API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch Dashboards HAProxy] *****
skipping: [localhost]

TASK [loadbalancer : Checking free port for RabbitMQ Management HAProxy] *******
ok: [localhost]

TASK [loadbalancer : Checking free port for Tacker Server HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Trove API HAProxy] *****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Watcher API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Zun API HAProxy] *******************
skipping: [localhost]

TASK [loadbalancer : Check if firewalld is running] ****************************
skipping: [localhost]

TASK [loadbalancer : Fail if firewalld is not running] *************************
skipping: [localhost]

TASK [include_role : aodh] *****************************************************
skipping: [localhost]

TASK [include_role : barbican] *************************************************
skipping: [localhost]

TASK [include_role : blazar] ***************************************************
skipping: [localhost]

TASK [include_role : ceph-rgw] *************************************************
skipping: [localhost]

TASK [include_role : cinder] ***************************************************
skipping: [localhost]

TASK [include_role : cloudkitty] ***********************************************
skipping: [localhost]

TASK [include_role : cyborg] ***************************************************
skipping: [localhost]

TASK [include_role : designate] ************************************************
skipping: [localhost]

TASK [include_role : etcd] *****************************************************
skipping: [localhost]

TASK [include_role : glance] ***************************************************
skipping: [localhost]

TASK [include_role : gnocchi] **************************************************
skipping: [localhost]

TASK [include_role : grafana] **************************************************
skipping: [localhost]

TASK [include_role : heat] *****************************************************
skipping: [localhost]

TASK [include_role : horizon] **************************************************
skipping: [localhost]

TASK [include_role : influxdb] *************************************************
skipping: [localhost]

TASK [include_role : ironic] ***************************************************
skipping: [localhost]

TASK [include_role : keystone] *************************************************
skipping: [localhost]

TASK [include_role : letsencrypt] **********************************************
skipping: [localhost]

TASK [include_role : magnum] ***************************************************
skipping: [localhost]

TASK [include_role : manila] ***************************************************
skipping: [localhost]

TASK [include_role : mariadb] **************************************************
skipping: [localhost]

TASK [include_role : masakari] *************************************************
skipping: [localhost]

TASK [include_role : memcached] ************************************************
skipping: [localhost]

TASK [include_role : mistral] **************************************************
skipping: [localhost]

TASK [include_role : neutron] **************************************************
skipping: [localhost]

TASK [include_role : placement] ************************************************
skipping: [localhost]

TASK [include_role : nova] *****************************************************
skipping: [localhost]

TASK [include_role : nova-cell] ************************************************
skipping: [localhost]

TASK [include_role : octavia] **************************************************
skipping: [localhost]

TASK [include_role : opensearch] ***********************************************
skipping: [localhost]

TASK [include_role : prometheus] ***********************************************
skipping: [localhost]

TASK [include_role : rabbitmq] *************************************************
skipping: [localhost]

TASK [include_role : skyline] **************************************************
skipping: [localhost]

TASK [include_role : tacker] ***************************************************
skipping: [localhost]

TASK [include_role : trove] ****************************************************
skipping: [localhost]

TASK [include_role : watcher] **************************************************
skipping: [localhost]

TASK [include_role : zun] ******************************************************
skipping: [localhost]

TASK [include_role : loadbalancer] *********************************************
skipping: [localhost]

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
ok: [localhost] => (item=localhost)

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/precheck.yml for localhost

TASK [service-precheck : mariadb | Validate inventory groups] ******************
skipping: [localhost] => (item=mariadb) 
skipping: [localhost]

TASK [mariadb : Get container facts] *******************************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB] ********************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB WSREP] **************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB IST] ****************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB SST] ****************************
ok: [localhost]

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************
skipping: no hosts matched

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
skipping: [localhost]

TASK [Include mariadb post-upgrade.yml] ****************************************
skipping: [localhost]

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/precheck.yml for localhost

TASK [service-precheck : memcached | Validate inventory groups] ****************
skipping: [localhost] => (item=memcached) 
skipping: [localhost]

TASK [memcached : Get container facts] *****************************************
ok: [localhost]

TASK [memcached : Checking free port for Memcached] ****************************
ok: [localhost]

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/precheck.yml for localhost

TASK [service-precheck : rabbitmq | Validate inventory groups] *****************
skipping: [localhost] => (item=rabbitmq) 
skipping: [localhost]

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ] ******************************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Management] *******************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Cluster] **********************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ EPMD] *************************
ok: [localhost]

TASK [rabbitmq : Check if all rabbit hostnames are resolvable] *****************
ok: [localhost] => (item=localhost)

TASK [rabbitmq : Check if each rabbit hostname resolves uniquely to the proper IP address] ***
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 12:52:29.298466', 'end': '2025-12-10 12:52:29.305447', 'delta': '0:00:00.006981', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   STREAM nics-VMware20-1']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 12:52:29.298466', 'end': '2025-12-10 12:52:29.305447', 'delta': '0:00:00.006981', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   DGRAM  ']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 12:52:29.298466', 'end': '2025-12-10 12:52:29.305447', 'delta': '0:00:00.006981', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   RAW    ']) 
skipping: [localhost]

TASK [rabbitmq : Check if TLS certificate exists for RabbitMQ] *****************
skipping: [localhost]

TASK [rabbitmq : Check if TLS key exists for RabbitMQ] *************************
skipping: [localhost]

TASK [rabbitmq : List RabbitMQ queues] *****************************************
skipping: [localhost]

TASK [rabbitmq : Check if RabbitMQ quorum queues need to be configured] ********
skipping: [localhost]

TASK [rabbitmq : Check if RabbitMQ quorum queues for transient queues need to be configured] ***
skipping: [localhost]

TASK [rabbitmq : Check if RabbitMQ streams need to be configured] **************
skipping: [localhost]

PLAY [Restart rabbitmq services] ***********************************************
skipping: no hosts matched

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
skipping: [localhost]

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/precheck.yml for localhost

TASK [service-precheck : keystone | Validate inventory groups] *****************
skipping: [localhost] => (item=keystone) 
skipping: [localhost] => (item=keystone-fernet) 
skipping: [localhost] => (item=keystone-httpd) 
skipping: [localhost] => (item=keystone-ssh) 
skipping: [localhost]

TASK [keystone : Get container facts] ******************************************
ok: [localhost]

TASK [keystone : Checking free port for Keystone Public] ***********************
ok: [localhost]

TASK [keystone : Checking free port for Keystone SSH] **************************
ok: [localhost]

TASK [keystone : Checking fernet_token_expiry] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/precheck.yml for localhost

TASK [service-precheck : glance | Validate inventory groups] *******************
skipping: [localhost] => (item=glance-api) 
skipping: [localhost] => (item=glance-tls-proxy) 
skipping: [localhost]

TASK [glance : Get container facts] ********************************************
ok: [localhost]

TASK [glance : Checking free port for Glance API] ******************************
ok: [localhost]

TASK [glance : Check if S3 configurations are defined] *************************
skipping: [localhost] => (item=glance_backend_s3_url) 
skipping: [localhost] => (item=glance_backend_s3_bucket) 
skipping: [localhost] => (item=glance_backend_s3_access_key) 
skipping: [localhost] => (item=glance_backend_s3_secret_key) 
skipping: [localhost]

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/precheck.yml for localhost

TASK [service-precheck : placement | Validate inventory groups] ****************
skipping: [localhost] => (item=placement-api) 
skipping: [localhost]

TASK [placement : Get container facts] *****************************************
ok: [localhost]

TASK [placement : Checking free port for Placement API] ************************
ok: [localhost]

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/precheck.yml for localhost

TASK [service-precheck : openvswitch | Validate inventory groups] **************
skipping: [localhost] => (item=openvswitch-db-server) 
skipping: [localhost] => (item=openvswitch-vswitchd) 
skipping: [localhost]

TASK [openvswitch : Get container facts] ***************************************
ok: [localhost]

TASK [openvswitch : Checking free port for OVSDB] ******************************
ok: [localhost]

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-api) 
skipping: [localhost] => (item=nova-metadata) 
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-super-conductor) 
skipping: [localhost]

TASK [nova : Get container facts] **********************************************
ok: [localhost]

TASK [nova : Checking free port for Nova API] **********************************
ok: [localhost]

TASK [nova : Checking free port for Nova Metadata] *****************************
ok: [localhost]

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-libvirt) 
skipping: [localhost] => (item=nova-ssh) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost]

TASK [nova-cell : Get container facts] *****************************************
ok: [localhost]

TASK [nova-cell : Checking available compute nodes in inventory] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova NoVNC Proxy] *********************
ok: [localhost]

TASK [nova-cell : Checking free port for Nova Serial Proxy] ********************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Spice HTML5 Proxy] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (API interface)] *************
ok: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (migration interface)] *******
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Libvirt] *************************
ok: [localhost]

TASK [nova-cell : Checking that host libvirt is not running] *******************
ok: [localhost]

TASK [nova-cell : Checking that nova_libvirt container is not running] *********
skipping: [localhost]

PLAY [Refresh nova scheduler cell cache] ***************************************

TASK [nova : Refresh cell cache in nova scheduler] *****************************
skipping: [localhost]

PLAY [Reload global Nova super conductor services] *****************************

TASK [nova : Reload nova super conductor services to remove RPC version pin] ***
skipping: [localhost]

PLAY [Reload Nova cell services] ***********************************************

TASK [nova-cell : Reload nova cell services to remove RPC version cap] *********
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost]

PLAY [Reload global Nova API services] *****************************************

TASK [nova : Reload nova API services to remove RPC version pin] ***************
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-api) 
skipping: [localhost]

PLAY [Run Nova API online data migrations] *************************************

TASK [nova : Run Nova API online database migrations] **************************
skipping: [localhost]

PLAY [Run Nova cell online data migrations] ************************************

TASK [nova-cell : Run Nova cell online database migrations] ********************
skipping: [localhost]

PLAY [Apply role neutron] ******************************************************

TASK [neutron : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/neutron/tasks/precheck.yml for localhost

TASK [service-precheck : neutron | Validate inventory groups] ******************
skipping: [localhost] => (item=neutron-server) 
skipping: [localhost] => (item=neutron-rpc-server) 
skipping: [localhost] => (item=neutron-periodic-worker) 
skipping: [localhost] => (item=neutron-ovn-maintenance-worker) 
skipping: [localhost] => (item=neutron-openvswitch-agent) 
skipping: [localhost] => (item=neutron-dhcp-agent) 
skipping: [localhost] => (item=neutron-l3-agent) 
skipping: [localhost] => (item=neutron-sriov-agent) 
skipping: [localhost] => (item=neutron-mlnx-agent) 
skipping: [localhost] => (item=neutron-eswitchd) 
skipping: [localhost] => (item=neutron-metadata-agent) 
skipping: [localhost] => (item=neutron-ovn-metadata-agent) 
skipping: [localhost] => (item=neutron-bgp-dragent) 
skipping: [localhost] => (item=neutron-infoblox-ipam-agent) 
skipping: [localhost] => (item=neutron-metering-agent) 
skipping: [localhost] => (item=ironic-neutron-agent) 
skipping: [localhost] => (item=neutron-ovn-agent) 
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Checking free port for Neutron Server] *************************
ok: [localhost]

TASK [neutron : Checking number of network agents] *****************************
skipping: [localhost]

TASK [neutron : Checking tenant network types] *********************************
ok: [localhost] => (item=vxlan) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": "vxlan",
    "msg": "All assertions passed"
}

TASK [neutron : Checking whether Ironic enabled] *******************************
skipping: [localhost]

TASK [neutron : Checking if neutron's dns domain has proper value] *************
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Get container volume facts] ************************************
ok: [localhost]

TASK [neutron : Check for ML2/OVN presence] ************************************
skipping: [localhost]

TASK [neutron : Check for ML2/OVS presence] ************************************
skipping: [localhost]

PLAY [Apply role kuryr] ********************************************************
skipping: no hosts matched

PLAY [Apply role hacluster] ****************************************************
skipping: no hosts matched

PLAY [Apply role heat] *********************************************************

TASK [heat : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/heat/tasks/precheck.yml for localhost

TASK [service-precheck : heat | Validate inventory groups] *********************
skipping: [localhost] => (item=heat-api) 
skipping: [localhost] => (item=heat-api-cfn) 
skipping: [localhost] => (item=heat-engine) 
skipping: [localhost]

TASK [heat : Get container facts] **********************************************
ok: [localhost]

TASK [heat : Checking free port for Heat API] **********************************
ok: [localhost]

TASK [heat : Checking free port for Heat API CFN] ******************************
ok: [localhost]

PLAY [Apply role horizon] ******************************************************

TASK [horizon : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/horizon/tasks/precheck.yml for localhost

TASK [service-precheck : horizon | Validate inventory groups] ******************
skipping: [localhost] => (item=horizon) 
skipping: [localhost]

TASK [horizon : Get container facts] *******************************************
ok: [localhost]

TASK [horizon : Checking free port for Horizon] ********************************
ok: [localhost]

PLAY [Apply role magnum] *******************************************************
skipping: no hosts matched

PLAY [Apply role mistral] ******************************************************
skipping: no hosts matched

PLAY [Apply role manila] *******************************************************
skipping: no hosts matched

PLAY [Apply role gnocchi] ******************************************************
skipping: no hosts matched

PLAY [Apply role ceilometer] ***************************************************
skipping: no hosts matched

PLAY [Apply role aodh] *********************************************************
skipping: no hosts matched

PLAY [Apply role barbican] *****************************************************
skipping: no hosts matched

PLAY [Apply role cyborg] *******************************************************
skipping: no hosts matched

PLAY [Apply role designate] ****************************************************
skipping: no hosts matched

PLAY [Apply role trove] ********************************************************
skipping: no hosts matched

PLAY [Apply role watcher] ******************************************************
skipping: no hosts matched

PLAY [Apply role grafana] ******************************************************
skipping: no hosts matched

PLAY [Apply role cloudkitty] ***************************************************
skipping: no hosts matched

PLAY [Apply role tacker] *******************************************************
skipping: no hosts matched

PLAY [Apply role octavia] ******************************************************
skipping: no hosts matched

PLAY [Apply role zun] **********************************************************
skipping: no hosts matched

PLAY [Apply role blazar] *******************************************************
skipping: no hosts matched

PLAY [Apply role masakari] *****************************************************
skipping: no hosts matched

PLAY [Apply role skyline] ******************************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
localhost                  : ok=104  changed=0    unreachable=0    failed=0    skipped=132  rescued=0    ignored=0   

[2025-12-10 12:52:53] Ejecutando deploy

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************
skipping: no hosts matched

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/deploy.yml for localhost

TASK [common : Ensuring config directories exist] ******************************
changed: [localhost] => (item=[{'service_name': 'kolla-toolbox'}, 'kolla-toolbox'])

TASK [common : include_tasks] **************************************************
skipping: [localhost]

TASK [common : Copying over config.json files for services] ********************
changed: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [common : Ensure RabbitMQ Erlang cookie exists] ***************************
changed: [localhost]

TASK [common : Ensuring config directories have correct owner and permission] ***
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [common : Copy rabbitmq-env.conf to kolla toolbox] ************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/rabbitmq-env.conf.j2)

TASK [common : Copy rabbitmq erl_inetrc to kolla toolbox] **********************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/erl_inetrc.j2)

TASK [service-check-containers : common | Check containers] ********************
changed: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : common | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [common : Creating log volume] ********************************************
changed: [localhost]

TASK [common : Link kolla_logs volume to /var/log/kolla] ***********************
changed: [localhost]

TASK [common : Flush handlers] *************************************************

RUNNING HANDLER [common : Restart kolla-toolbox container] *********************
changed: [localhost]

RUNNING HANDLER [common : Initializing toolbox container using normal user] ****
ok: [localhost]

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/deploy.yml for localhost

TASK [cron : Ensuring config directories exist] ********************************
changed: [localhost]

TASK [cron : include_tasks] ****************************************************
skipping: [localhost]

TASK [cron : Copying over config.json files for services] **********************
changed: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [cron : Copying over cron logrotate config file] **************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/templates/cron-logrotate-global.conf.j2)

TASK [cron : Ensuring config directories have correct owner and permission] ****
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : cron | Check containers] **********************
changed: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : cron | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [cron : Flush handlers] ***************************************************

RUNNING HANDLER [cron : Restart cron container] ********************************
changed: [localhost]

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/deploy.yml for localhost

TASK [fluentd : Ensuring config directories exist] *****************************
changed: [localhost]

TASK [fluentd : include_tasks] *************************************************
skipping: [localhost]

TASK [fluentd : Ensure /var/log/journal exists on EL systems] ******************
skipping: [localhost]

TASK [fluentd : Copying over config.json files for services] *******************
changed: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [fluentd : Find custom fluentd input config files] ************************
ok: [localhost]

TASK [fluentd : Find custom fluentd filter config files] ***********************
ok: [localhost]

TASK [fluentd : Find custom fluentd format config files] ***********************
ok: [localhost]

TASK [fluentd : Find custom fluentd output config files] ***********************
ok: [localhost]

TASK [fluentd : Copying over fluentd.conf] *************************************
changed: [localhost]

TASK [fluentd : Ensuring config directories have correct owner and permission] ***
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [service-check-containers : fluentd | Check containers] *******************
changed: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [service-check-containers : fluentd | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [fluentd : Flush handlers] ************************************************

RUNNING HANDLER [fluentd : Restart fluentd container] **************************
changed: [localhost]

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/deploy.yml for localhost

TASK [loadbalancer : Check IPv6 support] ***************************************
ok: [localhost]

TASK [Setting sysctl values] ***************************************************
included: sysctl for localhost

TASK [sysctl : Check IPv6 support] *********************************************
ok: [localhost]

TASK [sysctl : Setting sysctl values] ******************************************
changed: [localhost] => (item={'name': 'net.ipv6.ip_nonlocal_bind', 'value': 1})
changed: [localhost] => (item={'name': 'net.ipv4.ip_nonlocal_bind', 'value': 1})
ok: [localhost] => (item={'name': 'net.ipv4.tcp_retries2', 'value': 'KOLLA_UNSET'})
changed: [localhost] => (item={'name': 'net.unix.max_dgram_qlen', 'value': 128})

TASK [module-load : Load modules] **********************************************
changed: [localhost] => (item=ip_vs)

TASK [module-load : Persist modules via modules-load.d] ************************
changed: [localhost] => (item=ip_vs)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=ip_vs) 
skipping: [localhost]

TASK [loadbalancer : Ensuring config directories exist] ************************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [loadbalancer : Ensuring haproxy service config subdir exists] ************
changed: [localhost]

TASK [loadbalancer : Ensuring proxysql service config subdirectories exist] ****
changed: [localhost] => (item=users)
changed: [localhost] => (item=rules)

TASK [loadbalancer : Ensuring keepalived checks subdir exists] *****************
changed: [localhost]

TASK [loadbalancer : Remove mariadb.cfg if proxysql enabled] *******************
ok: [localhost]

TASK [loadbalancer : Removing checks for services which are disabled] **********
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__e4fb5cd1d39faee2233ac1552fc9b914d896b11d', '__omit_place_holder__e4fb5cd1d39faee2233ac1552fc9b914d896b11d'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [loadbalancer : Copying checks for services which are enabled] ************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__e4fb5cd1d39faee2233ac1552fc9b914d896b11d', '__omit_place_holder__e4fb5cd1d39faee2233ac1552fc9b914d896b11d'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}}) 

TASK [loadbalancer : Copying over config.json files for services] **************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [loadbalancer : Copying over haproxy.cfg] *********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_main.cfg.j2)

TASK [loadbalancer : Copying over proxysql config] *****************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql.yaml.j2)

TASK [loadbalancer : Copying over haproxy single external frontend config] *****
skipping: [localhost]

TASK [loadbalancer : Copying over custom haproxy services configuration] *******
skipping: [localhost]

TASK [loadbalancer : Copying over keepalived.conf] *****************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/keepalived/keepalived.conf.j2)

TASK [loadbalancer : include_tasks] ********************************************
skipping: [localhost]

TASK [loadbalancer : Copying over haproxy start script] ************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_run.sh.j2)

TASK [loadbalancer : Copying over proxysql start script] ***********************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql_run.sh.j2)

TASK [loadbalancer : Copying files for haproxy-ssh] ****************************
skipping: [localhost] => (item={'src': 'haproxy-ssh/sshd_config.j2', 'dest': 'sshd_config'}) 
skipping: [localhost] => (item={'src': 'haproxy-ssh/id_rsa.pub', 'dest': 'id_rsa.pub'}) 
skipping: [localhost]

TASK [service-check-containers : loadbalancer | Check containers] **************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [include_role : aodh] *****************************************************
skipping: [localhost]

TASK [include_role : barbican] *************************************************
skipping: [localhost]

TASK [include_role : blazar] ***************************************************
skipping: [localhost]

TASK [include_role : ceph-rgw] *************************************************
skipping: [localhost]

TASK [include_role : cinder] ***************************************************
skipping: [localhost]

TASK [include_role : cloudkitty] ***********************************************
skipping: [localhost]

TASK [include_role : cyborg] ***************************************************
skipping: [localhost]

TASK [include_role : designate] ************************************************
skipping: [localhost]

TASK [include_role : etcd] *****************************************************
skipping: [localhost]

TASK [include_role : glance] ***************************************************
included: glance for localhost

TASK [haproxy-config : Copying over glance haproxy config] *********************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}}) 

TASK [haproxy-config : Add configuration for glance when using single external frontend] ***
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for glance] ************************
skipping: [localhost] => (item={'key': 'glance_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost] => (item={'key': 'glance_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over glance ProxySQL users config] *************
changed: [localhost]

TASK [proxysql-config : Copying over glance ProxySQL rules config] *************
changed: [localhost]

TASK [include_role : gnocchi] **************************************************
skipping: [localhost]

TASK [include_role : grafana] **************************************************
skipping: [localhost]

TASK [include_role : heat] *****************************************************
included: heat for localhost

TASK [haproxy-config : Copying over heat haproxy config] ***********************
changed: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for heat when using single external frontend] ***
skipping: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for heat] **************************
skipping: [localhost] => (item={'key': 'heat_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_cfn', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_cfn_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over heat ProxySQL users config] ***************
changed: [localhost]

TASK [proxysql-config : Copying over heat ProxySQL rules config] ***************
changed: [localhost]

TASK [include_role : horizon] **************************************************
included: horizon for localhost

TASK [haproxy-config : Copying over horizon haproxy config] ********************
changed: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}})

TASK [haproxy-config : Add configuration for horizon when using single external frontend] ***
skipping: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for horizon] ***********************
skipping: [localhost] => (item={'key': 'horizon', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'horizon_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}}) 
skipping: [localhost] => (item={'key': 'horizon_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'horizon_external_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}}) 
skipping: [localhost] => (item={'key': 'acme_client', 'value': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over horizon ProxySQL users config] ************
changed: [localhost]

TASK [proxysql-config : Copying over horizon ProxySQL rules config] ************
changed: [localhost]

TASK [include_role : influxdb] *************************************************
skipping: [localhost]

TASK [include_role : ironic] ***************************************************
skipping: [localhost]

TASK [include_role : keystone] *************************************************
included: keystone for localhost

TASK [haproxy-config : Copying over keystone haproxy config] *******************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for keystone when using single external frontend] ***
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for keystone] **********************
skipping: [localhost] => (item={'key': 'keystone_internal', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}) 
skipping: [localhost] => (item={'key': 'keystone_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over keystone ProxySQL users config] ***********
changed: [localhost]

TASK [proxysql-config : Copying over keystone ProxySQL rules config] ***********
changed: [localhost]

TASK [include_role : letsencrypt] **********************************************
skipping: [localhost]

TASK [include_role : magnum] ***************************************************
skipping: [localhost]

TASK [include_role : manila] ***************************************************
skipping: [localhost]

TASK [include_role : mariadb] **************************************************
included: mariadb for localhost

TASK [mariadb : Ensure mysql monitor user exist] *******************************
ok: [localhost] => (item=localhost)

TASK [haproxy-config : Copying over mariadb haproxy config] ********************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for mariadb when using single external frontend] ***
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for mariadb] ***********************
skipping: [localhost] => (item={'key': 'mariadb_external_lb', 'value': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over mariadb ProxySQL users config] ************
changed: [localhost]

TASK [proxysql-config : Copying over mariadb ProxySQL rules config] ************
skipping: [localhost]

TASK [include_role : masakari] *************************************************
skipping: [localhost]

TASK [include_role : memcached] ************************************************
included: memcached for localhost

TASK [haproxy-config : Copying over memcached haproxy config] ******************
changed: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})

TASK [haproxy-config : Add configuration for memcached when using single external frontend] ***
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for memcached] *********************
skipping: [localhost] => (item={'key': 'memcached', 'value': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over memcached ProxySQL users config] **********
skipping: [localhost]

TASK [proxysql-config : Copying over memcached ProxySQL rules config] **********
skipping: [localhost]

TASK [include_role : mistral] **************************************************
skipping: [localhost]

TASK [include_role : neutron] **************************************************
included: neutron for localhost

TASK [haproxy-config : Copying over neutron haproxy config] ********************
changed: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}})
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}}) 
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for neutron when using single external frontend] ***
skipping: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}}) 
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}}) 
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for neutron] ***********************
skipping: [localhost] => (item={'key': 'neutron_server', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'neutron_server_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over neutron ProxySQL users config] ************
changed: [localhost]

TASK [proxysql-config : Copying over neutron ProxySQL rules config] ************
changed: [localhost]

TASK [include_role : placement] ************************************************
included: placement for localhost

TASK [haproxy-config : Copying over placement haproxy config] ******************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [haproxy-config : Add configuration for placement when using single external frontend] ***
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for placement] *********************
skipping: [localhost] => (item={'key': 'placement_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}) 
skipping: [localhost] => (item={'key': 'placement_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over placement ProxySQL users config] **********
changed: [localhost]

TASK [proxysql-config : Copying over placement ProxySQL rules config] **********
changed: [localhost]

TASK [include_role : nova] *****************************************************
included: nova for localhost

TASK [haproxy-config : Copying over nova haproxy config] ***********************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for nova when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova] **************************
skipping: [localhost] => (item={'key': 'nova_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_metadata', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_metadata_external', 'value': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over nova ProxySQL users config] ***************
changed: [localhost]

TASK [proxysql-config : Copying over nova ProxySQL rules config] ***************
changed: [localhost]

TASK [include_role : nova-cell] ************************************************
included: nova-cell for localhost

TASK [nova-cell : Configure loadbalancer for nova-novncproxy] ******************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-novncproxy)

TASK [haproxy-config : Copying over nova-cell:nova-novncproxy haproxy config] ***
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}})

TASK [haproxy-config : Add configuration for nova-cell:nova-novncproxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-novncproxy] *****
skipping: [localhost] => (item={'key': 'nova_novncproxy', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}) 
skipping: [localhost] => (item={'key': 'nova_novncproxy_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
changed: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
changed: [localhost]

TASK [nova-cell : Configure loadbalancer for nova-spicehtml5proxy] *************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-spicehtml5proxy)

TASK [haproxy-config : Copying over nova-cell:nova-spicehtml5proxy haproxy config] ***
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for nova-cell:nova-spicehtml5proxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-spicehtml5proxy] ***
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
ok: [localhost]

TASK [nova-cell : Configure loadbalancer for nova-serialproxy] *****************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-serialproxy)

TASK [haproxy-config : Copying over nova-cell:nova-serialproxy haproxy config] ***
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for nova-cell:nova-serialproxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-serialproxy] ****
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
ok: [localhost]

TASK [include_role : octavia] **************************************************
skipping: [localhost]

TASK [include_role : opensearch] ***********************************************
skipping: [localhost]

TASK [include_role : prometheus] ***********************************************
skipping: [localhost]

TASK [include_role : rabbitmq] *************************************************
included: rabbitmq for localhost

TASK [haproxy-config : Copying over rabbitmq haproxy config] *******************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [haproxy-config : Add configuration for rabbitmq when using single external frontend] ***
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for rabbitmq] **********************
skipping: [localhost] => (item={'key': 'rabbitmq_management', 'value': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over rabbitmq ProxySQL users config] ***********
skipping: [localhost]

TASK [proxysql-config : Copying over rabbitmq ProxySQL rules config] ***********
skipping: [localhost]

TASK [include_role : skyline] **************************************************
skipping: [localhost]

TASK [include_role : tacker] ***************************************************
skipping: [localhost]

TASK [include_role : trove] ****************************************************
skipping: [localhost]

TASK [include_role : watcher] **************************************************
skipping: [localhost]

TASK [include_role : zun] ******************************************************
skipping: [localhost]

TASK [include_role : loadbalancer] *********************************************
included: loadbalancer for localhost

TASK [service-check-containers : loadbalancer | Check containers] **************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Check IP addresses on the API interface] *******
ok: [localhost]

RUNNING HANDLER [loadbalancer : Group HA nodes by status] **********************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup keepalived container] **************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup haproxy container] *****************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup proxysql container] ****************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Start backup haproxy container] ****************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Wait for backup haproxy to start] **************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Start backup proxysql container] ***************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Wait for backup proxysql to start] *************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Start backup keepalived container] *************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Stop master haproxy container] *****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Stop master proxysql container] ****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Stop master keepalived container] **************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master haproxy container] ****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master proxysql container] ***************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master keepalived container] *************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Wait for haproxy to listen on VIP] *************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Wait for proxysql to listen on VIP] ************
ok: [localhost]

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
ok: [localhost] => (item=localhost)

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/deploy.yml for localhost

TASK [mariadb : Ensuring config directories exist] *****************************
changed: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [mariadb : Ensuring database backup config directory exists] **************
skipping: [localhost]

TASK [mariadb : Copying over my.cnf for mariabackup] ***************************
skipping: [localhost]

TASK [mariadb : Copying over config.json files for services] *******************
changed: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [mariadb : Copying over config.json files for mariabackup] ****************
skipping: [localhost]

TASK [mariadb : Copying over galera.cnf] ***************************************
changed: [localhost]

TASK [mariadb : Copying over healthcheck.cnf] **********************************
changed: [localhost]

TASK [mariadb : include_tasks] *************************************************
skipping: [localhost]

TASK [service-check-containers : mariadb | Check containers] *******************
changed: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [service-check-containers : mariadb | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Checking for mariadb cluster] **********************************
skipping: [localhost]

TASK [mariadb : Cleaning up temp file on localhost] ****************************
skipping: [localhost]

TASK [mariadb : Stop MariaDB containers] ***************************************
skipping: [localhost]

TASK [mariadb : Run MariaDB wsrep recovery] ************************************
skipping: [localhost]

TASK [mariadb : Copying MariaDB log file to /tmp] ******************************
skipping: [localhost]

TASK [mariadb : Get MariaDB wsrep recovery seqno] ******************************
skipping: [localhost]

TASK [mariadb : Removing MariaDB log file from /tmp] ***************************
skipping: [localhost]

TASK [mariadb : Registering MariaDB seqno variable] ****************************
skipping: [localhost]

TASK [mariadb : Comparing seqno value on all mariadb hosts] ********************
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [mariadb : Writing hostname of host with the largest seqno to temp file] ***
skipping: [localhost]

TASK [mariadb : Registering mariadb_recover_inventory_name from temp file] *****
skipping: [localhost]

TASK [mariadb : Store bootstrap and master hostnames into facts] ***************
skipping: [localhost]

TASK [mariadb : Set grastate.dat file from MariaDB container in bootstrap host] ***
skipping: [localhost]

TASK [mariadb : Refresh galera.cnf to set first MariaDB container as primary] ***
skipping: [localhost]

TASK [mariadb : Starting first MariaDB container] ******************************
skipping: [localhost]

TASK [mariadb : Wait for first MariaDB container] ******************************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB to become operational] ************************
skipping: [localhost]

TASK [mariadb : Restart slave MariaDB container(s)] ****************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Wait for slave MariaDB] ****************************************
skipping: [localhost]

TASK [mariadb : Unset pc.bootstrap for primary MariaDB galera.cnf for next restart] ***
skipping: [localhost]

TASK [mariadb : Restart master MariaDB container(s)] ***************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Wait for MariaDB] **********************************************
skipping: [localhost]

TASK [service-check : mariadb | Get container facts] ***************************
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
skipping: [localhost]

TASK [mariadb : Create MariaDB volume] *****************************************
changed: [localhost]

TASK [mariadb : Divide hosts by their MariaDB volume availability] *************
ok: [localhost]

TASK [mariadb : Establish whether the cluster has already existed] *************
ok: [localhost]

TASK [mariadb : Check MariaDB service port liveness] ***************************
fatal: [localhost]: FAILED! => {"changed": false, "elapsed": 10, "msg": "Timeout when waiting for search string MariaDB in 192.168.0.195:3306"}
...ignoring

TASK [mariadb : Divide hosts by their MariaDB service port liveness] ***********
ok: [localhost]

TASK [mariadb : Fail on existing but stopped cluster] **************************
skipping: [localhost]

TASK [mariadb : Check MariaDB service WSREP sync status] ***********************
skipping: [localhost]

TASK [mariadb : Extract MariaDB service WSREP sync status] *********************
skipping: [localhost]

TASK [mariadb : Divide hosts by their MariaDB service WSREP sync status] *******
ok: [localhost]

TASK [mariadb : Fail when MariaDB services are not synced across the whole cluster] ***
skipping: [localhost]

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/bootstrap_cluster.yml for localhost

TASK [mariadb : Running MariaDB bootstrap container] ***************************
changed: [localhost]

TASK [mariadb : Store bootstrap host name into facts] **************************
ok: [localhost]

TASK [mariadb : include_tasks] *************************************************
skipping: [localhost]

RUNNING HANDLER [mariadb : Starting first MariaDB container] *******************
changed: [localhost]

RUNNING HANDLER [mariadb : Wait for first MariaDB service port liveness] *******
FAILED - RETRYING: [localhost]: Wait for first MariaDB service port liveness (10 retries left).
ok: [localhost]

RUNNING HANDLER [mariadb : Wait for first MariaDB service to sync WSREP] *******
ok: [localhost]

RUNNING HANDLER [mariadb : Ensure MariaDB is running normally on bootstrap host] ***
changed: [localhost]

RUNNING HANDLER [mariadb : Restart MariaDB on existing cluster members] ********
skipping: [localhost]

RUNNING HANDLER [mariadb : Start MariaDB on new nodes] *************************
skipping: [localhost]

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************

TASK [mariadb : Restart MariaDB container] *************************************
changed: [localhost]

TASK [mariadb : Wait for MariaDB service port liveness] ************************
ok: [localhost]

TASK [mariadb : Wait for MariaDB service to sync WSREP] ************************
ok: [localhost]

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
included: mariadb for localhost

TASK [mariadb : Creating shard root mysql user] ********************************
changed: [localhost]

TASK [mariadb : Creating mysql monitor user] ***********************************
changed: [localhost]

TASK [mariadb : Creating database backup user and setting permissions] *********
skipping: [localhost]

TASK [mariadb : Granting permissions on Mariabackup database to backup user] ***
skipping: [localhost]

TASK [service-check : mariadb | Get container facts] ***************************
ok: [localhost]

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
ok: [localhost]

TASK [Include mariadb post-upgrade.yml] ****************************************
skipping: [localhost]

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/deploy.yml for localhost

TASK [memcached : Ensuring config directories exist] ***************************
changed: [localhost] => (item=memcached)

TASK [memcached : Copying over config.json files for services] *****************
changed: [localhost] => (item=memcached)

TASK [service-check-containers : memcached | Check containers] *****************
changed: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})

TASK [service-check-containers : memcached | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) 
skipping: [localhost]

RUNNING HANDLER [memcached : Restart memcached container] **********************
changed: [localhost]

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/deploy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : Get current RabbitMQ version] *********************************
skipping: [localhost]

TASK [rabbitmq : Get new RabbitMQ version] *************************************
skipping: [localhost]

TASK [rabbitmq : Check if running RabbitMQ is at most one version behind] ******
skipping: [localhost]

TASK [rabbitmq : Catch when RabbitMQ is being downgraded] **********************
skipping: [localhost]

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : List RabbitMQ policies] ***************************************
skipping: [localhost]

TASK [rabbitmq : Remove ha-all policy from RabbitMQ] ***************************
skipping: [localhost]

TASK [rabbitmq : Ensuring config directories exist] ****************************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [rabbitmq : Copying over config.json files for services] ******************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [rabbitmq : Copying over rabbitmq-env.conf] *******************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2)

TASK [rabbitmq : Copying over rabbitmq.conf] ***********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq.conf.j2)

TASK [rabbitmq : Copying over erl_inetrc] **************************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/erl_inetrc.j2)

TASK [rabbitmq : Copying over advanced.config] *********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/advanced.config.j2)

TASK [rabbitmq : Copying over definitions.json] ********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/definitions.json.j2)

TASK [rabbitmq : Copying over enabled_plugins] *********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/enabled_plugins.j2)

TASK [rabbitmq : include_tasks] ************************************************
skipping: [localhost]

TASK [service-check-containers : rabbitmq | Check containers] ******************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [service-check-containers : rabbitmq | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) 
skipping: [localhost]

TASK [rabbitmq : Creating rabbitmq volume] *************************************
changed: [localhost]

TASK [rabbitmq : Running RabbitMQ bootstrap container] *************************
changed: [localhost]

RUNNING HANDLER [rabbitmq : Restart rabbitmq container] ************************
changed: [localhost]

PLAY [Restart rabbitmq services] ***********************************************

TASK [rabbitmq : Get info on RabbitMQ container] *******************************
ok: [localhost]

TASK [rabbitmq : Put RabbitMQ node into maintenance mode if in cluster] ********
skipping: [localhost]

TASK [rabbitmq : Stop the RabbitMQ application if not in cluster] **************
skipping: [localhost]

TASK [rabbitmq : Restart rabbitmq container] ***********************************
changed: [localhost]

TASK [rabbitmq : Waiting for rabbitmq to start] ********************************
ok: [localhost]

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
included: rabbitmq for localhost

TASK [rabbitmq : Enable all stable feature flags] ******************************
ok: [localhost]

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml for localhost

TASK [keystone : Ensuring config directories exist] ****************************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [keystone : Check if policies shall be overwritten] ***********************
skipping: [localhost]

TASK [keystone : Set keystone policy file] *************************************
skipping: [localhost]

TASK [keystone : Check if Keystone domain-specific config is supplied] *********
ok: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Copying over config.json files for services] ******************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [keystone : Copying over keystone.conf] ***********************************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 

TASK [keystone : Copying keystone-startup script for keystone] *****************
changed: [localhost]

TASK [keystone : Create Keystone domain-specific config directory] *************
skipping: [localhost]

TASK [keystone : Get file list in custom domains folder] ***********************
skipping: [localhost]

TASK [keystone : Copying Keystone Domain specific settings] ********************
skipping: [localhost]

TASK [keystone : Copying over existing policy file] ****************************
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Copying over wsgi-keystone.conf] ******************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/wsgi-keystone.conf.j2) 
skipping: [localhost]

TASK [Configure uWSGI for Keystone] ********************************************
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over keystone uWSGI config] ***************
changed: [localhost]

TASK [keystone : Copying over httpd-keystone.conf] *****************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/httpd-keystone.conf.j2) 
skipping: [localhost]

TASK [keystone : Checking whether keystone-paste.ini file exists] **************
ok: [localhost]

TASK [keystone : Copying over keystone-paste.ini] ******************************
skipping: [localhost]

TASK [keystone : Generate the required cron jobs for the node] *****************
ok: [localhost]

TASK [keystone : Set fact with the generated cron jobs for building the crontab later] ***
ok: [localhost]

TASK [keystone : Copying files for keystone-fernet] ****************************
changed: [localhost] => (item={'src': 'crontab.j2', 'dest': 'crontab'})
changed: [localhost] => (item={'src': 'fernet-rotate.sh.j2', 'dest': 'fernet-rotate.sh'})
changed: [localhost] => (item={'src': 'fernet-node-sync.sh.j2', 'dest': 'fernet-node-sync.sh'})
changed: [localhost] => (item={'src': 'fernet-push.sh.j2', 'dest': 'fernet-push.sh'})
changed: [localhost] => (item={'src': 'fernet-healthcheck.sh.j2', 'dest': 'fernet-healthcheck.sh'})
changed: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'})
changed: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'})

TASK [keystone : Copying files for keystone-ssh] *******************************
changed: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'})
changed: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'})

TASK [service-check-containers : keystone | Check containers] ******************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [service-check-containers : keystone | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Creating keystone database] ***********************************
changed: [localhost]

TASK [keystone : Creating Keystone database user and setting permissions] ******
changed: [localhost]

TASK [keystone : Checking for any running keystone_fernet containers] **********
ok: [localhost]

TASK [keystone : Group nodes where keystone_fernet is running] *****************
ok: [localhost]

TASK [keystone : Fail if any hosts need bootstrapping and not all hosts targeted] ***
skipping: [localhost]

TASK [keystone : Running Keystone bootstrap container] *************************
changed: [localhost]

TASK [keystone : Running Keystone fernet bootstrap container] ******************
changed: [localhost]

TASK [keystone : Flush handlers] ***********************************************

RUNNING HANDLER [keystone : Restart keystone-ssh container] ********************
changed: [localhost]

RUNNING HANDLER [keystone : Restart keystone-fernet container] *****************
changed: [localhost]

RUNNING HANDLER [keystone : Restart keystone container] ************************
changed: [localhost]

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/distribute_fernet.yml for localhost

TASK [keystone : Waiting for Keystone SSH port to be UP] ***********************
ok: [localhost]

TASK [keystone : Run key distribution] *****************************************
changed: [localhost]

TASK [keystone : Creating admin project, user, role, service, and endpoint] ****
changed: [localhost] => (item=RegionOne)

TASK [service-ks-register : keystone | Creating/deleting services] *************
changed: [localhost] => (item=keystone (identity))

TASK [service-ks-register : keystone | Creating/deleting endpoints] ************
ok: [localhost] => (item=keystone -> http://192.168.0.200:5000 -> internal)
ok: [localhost] => (item=keystone -> http://192.168.0.200:5000 -> public)

TASK [service-ks-register : keystone | Creating projects] **********************
skipping: [localhost]

TASK [service-ks-register : keystone | Creating/deleting users] ****************
skipping: [localhost]

TASK [service-ks-register : keystone | Creating roles] *************************
skipping: [localhost]

TASK [service-ks-register : keystone | Granting/revoking user roles] ***********
skipping: [localhost]

TASK [keystone : Creating default user role] ***********************************
ok: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/deploy.yml for localhost

TASK [service-ks-register : glance | Creating/deleting services] ***************
changed: [localhost] => (item=glance (image))

TASK [service-ks-register : glance | Creating/deleting endpoints] **************
changed: [localhost] => (item=glance -> http://192.168.0.200:9292 -> internal)
changed: [localhost] => (item=glance -> http://192.168.0.200:9292 -> public)

TASK [service-ks-register : glance | Creating projects] ************************
changed: [localhost] => (item=service)

TASK [service-ks-register : glance | Creating/deleting users] ******************
changed: [localhost] => (item=glance -> service)

TASK [service-ks-register : glance | Creating roles] ***************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : glance | Granting/revoking user roles] *************
changed: [localhost] => (item=glance -> service -> admin)

TASK [glance : Ensuring config directories exist] ******************************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Check if policies shall be overwritten] *************************
skipping: [localhost]

TASK [glance : Set glance policy file] *****************************************
skipping: [localhost]

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Creating TLS backend PEM File] **********************************
skipping: [localhost]

TASK [glance : Copying over config.json files for services] ********************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [glance : Copying over glance-api.conf] ***********************************
changed: [localhost]

TASK [glance : Copying over glance-cache.conf for glance_api] ******************
skipping: [localhost]

TASK [glance : Copying over glance-image-import.conf] **************************
skipping: [localhost]

TASK [glance : Copying over property-protections-rules.conf] *******************
skipping: [localhost]

TASK [glance : Copying over existing policy file] ******************************
skipping: [localhost]

TASK [glance : Copying over glance-haproxy-tls.cfg] ****************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/templates/glance-tls-proxy.cfg.j2) 
skipping: [localhost]

TASK [service-check-containers : glance | Check containers] ********************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [service-check-containers : glance | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.200'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Creating Glance database] ***************************************
changed: [localhost]

TASK [glance : Creating Glance database user and setting permissions] **********
changed: [localhost]

TASK [glance : Enable log_bin_trust_function_creators function] ****************
changed: [localhost]

TASK [glance : Running Glance bootstrap container] *****************************
changed: [localhost]

TASK [glance : Disable log_bin_trust_function_creators function] ***************
changed: [localhost]

TASK [glance : Flush handlers] *************************************************

RUNNING HANDLER [glance : Restart glance-api container] ************************
changed: [localhost]

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/deploy.yml for localhost

TASK [service-ks-register : placement | Creating/deleting services] ************
changed: [localhost] => (item=placement (placement))

TASK [service-ks-register : placement | Creating/deleting endpoints] ***********
changed: [localhost] => (item=placement -> http://192.168.0.200:8780 -> internal)
changed: [localhost] => (item=placement -> http://192.168.0.200:8780 -> public)

TASK [service-ks-register : placement | Creating projects] *********************
ok: [localhost] => (item=service)

TASK [service-ks-register : placement | Creating/deleting users] ***************
changed: [localhost] => (item=placement -> service)

TASK [service-ks-register : placement | Creating roles] ************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : placement | Granting/revoking user roles] **********
changed: [localhost] => (item=placement -> service -> admin)

TASK [placement : include_tasks] ***********************************************
skipping: [localhost]

TASK [placement : Ensuring config directories exist] ***************************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Check if policies shall be overwritten] **********************
skipping: [localhost]

TASK [placement : Set placement policy file] ***********************************
skipping: [localhost]

TASK [placement : include_tasks] ***********************************************
skipping: [localhost]

TASK [placement : Copying over config.json files for services] *****************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Copying over placement.conf] *********************************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Copying over placement-api wsgi configuration] ***************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/templates/placement-api-wsgi.conf.j2) 
skipping: [localhost]

TASK [Configure uWSGI for Placement] *******************************************
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over placement-api uWSGI config] **********
changed: [localhost]

TASK [placement : Copying over migrate-db.rc.j2 configuration] *****************
changed: [localhost]

TASK [placement : Copying over existing policy file] ***************************
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [service-check-containers : placement | Check containers] *****************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [service-check-containers : placement | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [placement : Creating placement databases] ********************************
changed: [localhost]

TASK [placement : Creating placement databases user and setting permissions] ***
changed: [localhost]

TASK [placement : Running placement bootstrap container] ***********************
changed: [localhost]

TASK [placement : Flush handlers] **********************************************

RUNNING HANDLER [placement : Restart placement-api container] ******************
changed: [localhost]

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/deploy.yml for localhost

TASK [module-load : Load modules] **********************************************
changed: [localhost] => (item=openvswitch)

TASK [module-load : Persist modules via modules-load.d] ************************
changed: [localhost] => (item=openvswitch)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=openvswitch) 
skipping: [localhost]

TASK [openvswitch : Create /run/openvswitch directory on host] *****************
skipping: [localhost]

TASK [openvswitch : Ensuring config directories exist] *************************
changed: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [openvswitch : Copying over config.json files for services] ***************
changed: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [openvswitch : Copying over ovs-vsctl wrapper] ****************************
skipping: [localhost]

TASK [service-check-containers : openvswitch | Check containers] ***************
changed: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [service-check-containers : openvswitch | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [openvswitch : Flush Handlers] ********************************************

RUNNING HANDLER [openvswitch : Restart openvswitch-db-server container] ********
changed: [localhost]

RUNNING HANDLER [openvswitch : Waiting for openvswitch_db service to be ready] ***
ok: [localhost]

RUNNING HANDLER [openvswitch : Restart openvswitch-vswitchd container] *********
changed: [localhost]

TASK [openvswitch : Set system-id, hostname and hw-offload] ********************
changed: [localhost] => (item={'col': 'external_ids', 'name': 'system-id', 'value': 'nics-VMware20-1'})
changed: [localhost] => (item={'col': 'external_ids', 'name': 'hostname', 'value': 'nics-VMware20-1'})
ok: [localhost] => (item={'col': 'other_config', 'name': 'hw-offload', 'value': True, 'state': 'absent'})

TASK [openvswitch : Ensuring OVS bridge is properly setup] *********************
changed: [localhost] => (item=br-ex)

TASK [openvswitch : Ensuring OVS ports are properly setup] *********************
changed: [localhost] => (item=['br-ex', 'veth1'])

RUNNING HANDLER [openvswitch : Restart openvswitch-vswitchd container] *********
changed: [localhost]

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
included: nova for localhost

TASK [nova : Creating Nova databases] ******************************************
changed: [localhost] => (item=nova_cell0)
changed: [localhost] => (item=nova_api)

TASK [nova : Creating Nova databases user and setting permissions] *************
changed: [localhost] => (item=None)
changed: [localhost] => (item=None)
changed: [localhost]

TASK [nova : Ensuring config directories exist] ********************************
changed: [localhost]

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [nova : Copying over config.json files for nova-api-bootstrap] ************
changed: [localhost]

TASK [nova : Copying over nova.conf for nova-api-bootstrap] ********************
changed: [localhost]

TASK [nova : include_tasks] ****************************************************
skipping: [localhost]

TASK [nova : Running Nova API bootstrap container] *****************************
ok: [localhost]

TASK [nova : Create cell0 mappings] ********************************************
changed: [localhost]

TASK [nova-cell : Get a list of existing cells] ********************************
ok: [localhost]

TASK [nova-cell : Extract current cell settings from list] *********************
ok: [localhost]

TASK [nova : Update cell0 mappings] ********************************************
skipping: [localhost]

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap_service.yml for localhost

TASK [nova : Running Nova API bootstrap container] *****************************
ok: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
included: nova-cell for localhost

TASK [nova-cell : Creating Nova cell database] *********************************
changed: [localhost]

TASK [nova-cell : Creating Nova cell database user and setting permissions] ****
changed: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
skipping: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
ok: [localhost] => (item=None)
ok: [localhost -> {{ service_rabbitmq_delegate_host }}]

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
skipping: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
skipping: [localhost] => (item=None) 
skipping: [localhost]

TASK [nova-cell : Ensuring config directories exist] ***************************
changed: [localhost]

TASK [nova-cell : Copying over config.json files for nova-cell-bootstrap] ******
changed: [localhost]

TASK [nova-cell : Copying over nova.conf for nova-cell-bootstrap] **************
changed: [localhost]

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [nova-cell : Running Nova cell bootstrap container] ***********************
ok: [localhost]

TASK [nova-cell : Get a list of existing cells] ********************************
ok: [localhost]

TASK [nova-cell : Extract current cell settings from list] *********************
ok: [localhost]

TASK [nova-cell : Create cell] *************************************************
changed: [localhost]

TASK [nova-cell : Update cell] *************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/deploy.yml for localhost

TASK [service-ks-register : nova | Creating/deleting services] *****************
skipping: [localhost] => (item=nova_legacy (compute_legacy)) 
changed: [localhost] => (item=nova (compute))

TASK [service-ks-register : nova | Creating/deleting endpoints] ****************
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.200:8774/v2/%(tenant_id)s -> internal) 
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.200:8774/v2/%(tenant_id)s -> public) 
changed: [localhost] => (item=nova -> http://192.168.0.200:8774/v2.1 -> internal)
changed: [localhost] => (item=nova -> http://192.168.0.200:8774/v2.1 -> public)

TASK [service-ks-register : nova | Creating projects] **************************
ok: [localhost] => (item=service)

TASK [service-ks-register : nova | Creating/deleting users] ********************
changed: [localhost] => (item=nova -> service)

TASK [service-ks-register : nova | Creating roles] *****************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : nova | Granting/revoking user roles] ***************
changed: [localhost] => (item=nova -> service -> admin)
changed: [localhost] => (item=nova -> service -> service)

TASK [nova : Ensuring config directories exist] ********************************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Check if policies shall be overwritten] ***************************
skipping: [localhost]

TASK [nova : Set nova policy file] *********************************************
skipping: [localhost]

TASK [nova : Check for vendordata file] ****************************************
ok: [localhost]

TASK [nova : Set vendordata file path] *****************************************
skipping: [localhost]

TASK [nova : include_tasks] ****************************************************
skipping: [localhost]

TASK [nova : Copying over config.json files for services] **********************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Copying over nova.conf] *******************************************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Copying over existing policy file] ********************************
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova : Copying over nova-api-wsgi.conf] **********************************
skipping: [localhost]

TASK [nova : Copying over nova-metadata-wsgi.conf] *****************************
skipping: [localhost]

TASK [nova : Copying over vendordata file for nova services] *******************
skipping: [localhost] => (item=nova-metadata) 
skipping: [localhost] => (item=nova-api) 
skipping: [localhost]

TASK [Configure uWSGI for Nova] ************************************************
included: service-uwsgi-config for localhost => (item={'name': 'nova-api', 'port': '8774'})
included: service-uwsgi-config for localhost => (item={'name': 'nova-metadata', 'port': '8775'})

TASK [service-uwsgi-config : Copying over nova-api uWSGI config] ***************
changed: [localhost]

TASK [service-uwsgi-config : Copying over nova-metadata uWSGI config] **********
changed: [localhost]

TASK [service-check-containers : nova | Check containers] **********************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [service-check-containers : nova | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.200', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova : Flush handlers] ***************************************************

RUNNING HANDLER [nova : Restart nova-scheduler container] **********************
changed: [localhost]

RUNNING HANDLER [nova : Restart nova-api container] ****************************
changed: [localhost]

RUNNING HANDLER [nova : Restart nova-metadata container] ***********************
changed: [localhost]

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml for localhost

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Get new Libvirt version] *************************************
changed: [localhost]

TASK [nova-cell : Cache new Libvirt version] ***********************************
ok: [localhost]

TASK [Get nova_libvirt image info] *********************************************
included: service-image-info for localhost

TASK [service-image-info : community.docker.docker_image_info] *****************
ok: [localhost]

TASK [service-image-info : set_fact] *******************************************
ok: [localhost]

TASK [service-image-info : containers.podman.podman_image_info] ****************
skipping: [localhost]

TASK [service-image-info : set_fact] *******************************************
skipping: [localhost]

TASK [nova-cell : Get container facts] *****************************************
ok: [localhost] => (item=localhost)

TASK [nova-cell : Get current Libvirt version] *********************************
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [nova-cell : Check that the new Libvirt version is >= current] ************
skipping: [localhost] => (item={'result': False, 'changed': False, 'containers': {}, 'invocation': {'module_args': {'action': 'get_containers', 'container_engine': 'docker', 'name': ['nova_libvirt'], 'api_version': 'auto', 'args': {'get_all_containers': False}}}, 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}) 
skipping: [localhost]

TASK [Load and persist br_netfilter module] ************************************
included: module-load for localhost

TASK [module-load : Load modules] **********************************************
changed: [localhost] => (item=br_netfilter)

TASK [module-load : Persist modules via modules-load.d] ************************
changed: [localhost] => (item=br_netfilter)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=br_netfilter) 
skipping: [localhost]

TASK [nova-cell : Enable bridge-nf-call sysctl variables] **********************
changed: [localhost] => (item=net.bridge.bridge-nf-call-iptables)
changed: [localhost] => (item=net.bridge.bridge-nf-call-ip6tables)

TASK [nova-cell : Install udev kolla kvm rules] ********************************
skipping: [localhost]

TASK [nova-cell : Mask qemu-kvm service] ***************************************
skipping: [localhost]

TASK [nova-cell : Ensuring config directories exist] ***************************
changed: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Check if policies shall be overwritten] **********************
skipping: [localhost]

TASK [nova-cell : Set nova policy file] ****************************************
skipping: [localhost]

TASK [nova-cell : Check for vendordata file] ***********************************
ok: [localhost]

TASK [nova-cell : Set vendordata file path] ************************************
skipping: [localhost]

TASK [nova-cell : Copying over config.json files for services] *****************
changed: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : Copying over nova.conf] **************************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : Copying over Nova compute provider config] *******************
skipping: [localhost]

TASK [nova-cell : Copying over libvirt configuration] **************************
changed: [localhost] => (item={'src': 'qemu.conf.j2', 'dest': 'qemu.conf'})
changed: [localhost] => (item={'src': 'libvirtd.conf.j2', 'dest': 'libvirtd.conf'})

TASK [nova-cell : Copying over libvirt TLS keys] *******************************
skipping: [localhost]

TASK [nova-cell : Copying over libvirt SASL configuration] *********************
changed: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-compute'})
changed: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-libvirt'})
changed: [localhost] => (item={'src': 'sasl.conf.j2', 'dest': 'sasl.conf', 'service': 'nova-libvirt'})

TASK [nova-cell : Copying files for nova-ssh] **********************************
changed: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'})
changed: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'})
changed: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'})
changed: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'})

TASK [nova-cell : Copying 'release' file for nova_compute] *********************
skipping: [localhost]

TASK [nova-cell : Generating 'hostnqn' file for nova_compute] ******************
changed: [localhost]

TASK [nova-cell : Copying over existing policy file] ***************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova-cell : Copying over vendordata file to containers] ******************
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost]

TASK [service-check-containers : nova_cell | Check containers] *****************
changed: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [service-check-containers : nova_cell | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Flush handlers] **********************************************

RUNNING HANDLER [nova-cell : Restart nova-conductor container] *****************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-novncproxy container] ****************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-ssh container] ***********************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-libvirt container] *******************
changed: [localhost]

RUNNING HANDLER [nova-cell : Checking libvirt container is ready] **************
ok: [localhost]

RUNNING HANDLER [nova-cell : Create libvirt SASL user] *************************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-compute container] *******************
changed: [localhost]

RUNNING HANDLER [nova-cell : Wait for nova-compute services to update service versions] ***
skipping: [localhost]

TASK [nova-cell : Waiting for nova-compute services to register themselves] ****
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (20 retries left).
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (19 retries left).
ok: [localhost]

TASK [nova-cell : Fail if nova-compute service failed to register] *************
skipping: [localhost]

TASK [nova-cell : Include discover_computes.yml] *******************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/discover_computes.yml for localhost

TASK [nova-cell : Get a list of existing cells] ********************************
ok: [localhost]

TASK [nova-cell : Extract current cell settings from list] *********************
ok: [localhost]

TASK [nova-cell : Fail if cell settings not found] *****************************
skipping: [localhost]

TASK [nova-cell : Discover nova hosts] *****************************************
ok: [localhost]

PLAY [Refresh nova scheduler cell cache] ***************************************

TASK [nova : Refresh cell cache in nova scheduler] *****************************
fatal: [localhost]: FAILED! => {"changed": true, "cmd": "kill -HUP `docker inspect -f '{{ .State.Pid }}' nova_scheduler`", "delta": "0:00:00.031197", "end": "2025-12-10 13:08:00.782307", "msg": "non-zero return code", "rc": 1, "start": "2025-12-10 13:08:00.751110", "stderr": "/bin/sh: 1: kill: Permission denied", "stderr_lines": ["/bin/sh: 1: kill: Permission denied"], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
localhost                  : ok=333  changed=209  unreachable=0    failed=1    skipped=224  rescued=0    ignored=1   

[2025-12-10 13:16:26] Configurando Kolla-Ansible en /etc/kolla
[2025-12-10 13:16:26] Asegurando inventario all-in-one en /etc/kolla/ansible/inventory/all-in-one
[2025-12-10 13:16:26] Inventario existente detectado; no se sobrescribe
[2025-12-10 13:16:26] Ejecutando kolla-genpwd para garantizar contraseñas completas
[2025-12-10 13:16:28] Interfaz management: ens34
[2025-12-10 13:16:28] Interfaz externa:    veth1
[2025-12-10 13:16:28] VIP seleccionada:    192.168.0.201
[2025-12-10 13:16:28] Archivo globals.yml generado a partir de la plantilla oficial
[2025-12-10 13:16:28] === Iniciando despliegue de OpenStack con Kolla-Ansible ===
[2025-12-10 13:16:28] Activando entorno virtual: /home/nics/openstack_venv
[2025-12-10 13:16:28] Instalando dependencias Galaxy (kolla-ansible install-deps)
Your branch is up to date with 'origin/master'.
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Installing 'openstack.kolla:1.0.0' to '/home/nics/.ansible/collections/ansible_collections/openstack/kolla'
Created collection for openstack.kolla:1.0.0 at /home/nics/.ansible/collections/ansible_collections/openstack/kolla
openstack.kolla:1.0.0 was installed successfully
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-posix-2.1.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/ansible-posix-2.1.0-6idyxdpj
Installing 'ansible.posix:2.1.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/posix'
ansible.posix:2.1.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-utils-6.0.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/ansible-utils-6.0.0-61i4ez8d
Installing 'ansible.utils:6.0.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/utils'
ansible.utils:6.0.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-netcommon-8.2.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/ansible-netcommon-8.2.0-12ay_9s6
Installing 'ansible.netcommon:8.2.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/netcommon'
ansible.netcommon:8.2.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/containers-podman-1.18.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/containers-podman-1.18.0-0lutgui8
Installing 'containers.podman:1.18.0' to '/home/nics/.ansible/collections/ansible_collections/containers/podman'
containers.podman:1.18.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-crypto-3.0.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/community-crypto-3.0.5-5ni875kn
Installing 'community.crypto:3.0.5' to '/home/nics/.ansible/collections/ansible_collections/community/crypto'
community.crypto:3.0.5 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-docker-4.8.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/community-docker-4.8.5-g5csmm4g
Installing 'community.docker:4.8.5' to '/home/nics/.ansible/collections/ansible_collections/community/docker'
community.docker:4.8.5 was installed successfully
'community.library_inventory_filtering_v1:1.1.1' is already installed, skipping.
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-general-11.4.2.tar.gz to /home/nics/.ansible/tmp/ansible-local-114379250l3n6x/tmp_45e6hc8/community-general-11.4.2-3afvxdgm
Installing 'community.general:11.4.2' to '/home/nics/.ansible/collections/ansible_collections/community/general'
community.general:11.4.2 was installed successfully
[2025-12-10 13:16:59] Ejecutando bootstrap-servers

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Apply role baremetal] ****************************************************

TASK [openstack.kolla.etc_hosts : Include etc-hosts.yml] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/etc_hosts/tasks/etc-hosts.yml for localhost

TASK [openstack.kolla.etc_hosts : Ensure localhost in /etc/hosts] **************
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Ensure hostname does not point to 127.0.1.1 in /etc/hosts] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Generate /etc/hosts for all of the nodes] ****
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Check whether /etc/cloud/cloud.cfg exists] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Disable cloud-init manage_etc_hosts] *********
ok: [localhost]

TASK [openstack.kolla.baremetal : Ensure unprivileged users can use ping] ******
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set firewall default policy] *****************
ok: [localhost]

TASK [openstack.kolla.baremetal : Check if firewalld is installed] *************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Disable firewalld] ***************************
skipping: [localhost] => (item=firewalld) 
skipping: [localhost]

TASK [openstack.kolla.packages : Install packages] *****************************
ok: [localhost]

TASK [openstack.kolla.packages : Remove packages] ******************************
ok: [localhost]

TASK [openstack.kolla.docker : Install/Uninstall] ******************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/install.yml for localhost

TASK [openstack.kolla.docker : Enable Docker repository] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/repo-Debian.yml for localhost

TASK [openstack.kolla.docker : Install CA certificates and gnupg packages] *****
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt sources list directory exists] *******
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt keyrings directory exists] ***********
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt gpg key] *********************
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt pin] *************************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure old docker repository absent] ************
ok: [localhost]

TASK [openstack.kolla.docker : Enable docker apt repository] *******************
ok: [localhost]

TASK [openstack.kolla.docker : Update the apt cache] ***************************
changed: [localhost]

TASK [openstack.kolla.docker : Check which containers are running] *************
ok: [localhost]

TASK [openstack.kolla.docker : Check if docker systemd unit exists] ************
ok: [localhost]

TASK [openstack.kolla.docker : Mask the docker systemd unit on Debian/Ubuntu] ***
changed: [localhost]

TASK [openstack.kolla.docker : Install packages] *******************************
ok: [localhost]

TASK [openstack.kolla.docker : Start docker] ***********************************
skipping: [localhost]

TASK [openstack.kolla.docker : Wait for Docker to start] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure containers are running after Docker upgrade] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure docker config directory exists] **********
ok: [localhost]

TASK [openstack.kolla.docker : Write docker config] ****************************
ok: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Get Docker API version] *************************
ok: [localhost]

TASK [openstack.kolla.docker : Parse Docker system info] ***********************
ok: [localhost]

TASK [openstack.kolla.docker : Determine if Docker uses containerd image store] ***
ok: [localhost]

TASK [openstack.kolla.docker : Copying over containerd config] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Remove old docker options file] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Ensure docker service directory exists] *********
skipping: [localhost]

TASK [openstack.kolla.docker : Configure docker service] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the path for CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Start and enable docker] ************************
changed: [localhost]

TASK [openstack.kolla.docker : Configure containerd for Zun] *******************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Ensure groups are present] ******************
skipping: [localhost] => (item=docker) 
skipping: [localhost] => (item=sudo) 
skipping: [localhost] => (item=kolla) 
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Create kolla user] **************************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Add public key to kolla user authorized keys] ***
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Grant kolla user passwordless sudo] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Get Python] *********************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if Python environment is externally managed] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Set docker_sdk_python_externally_managed fact] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Install/Uninstall] **************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker_sdk/tasks/install.yml for localhost

TASK [openstack.kolla.docker_sdk : Ensure apt sources list directory exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Ensure apt keyrings directory exists] *******
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install osbpo apt gpg key] ******************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Enable osbpo apt repository] ****************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packages] ***************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if virtualenv is a directory] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Check if packaging is already installed] ****
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packaging into virtualenv] **********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install latest pip and packaging in the virtualenv] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install docker SDK for python using pip] ****
skipping: [localhost]

TASK [openstack.kolla.baremetal : Ensure node_config_directory directory exists] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Include tasks from remove-profile.yml] ***
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/apparmor_libvirt/tasks/remove-profile.yml for localhost

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor disable profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Remove apparmor profile for libvirt] ***
skipping: [localhost]

TASK [openstack.kolla.baremetal : Change state of selinux] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set https proxy for git] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set http proxy for git] **********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Copying over kolla.target] *******************
ok: [localhost]

TASK [openstack.kolla.baremetal : Configure ceph for zun] **********************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=42   changed=3    unreachable=0    failed=0    skipped=30   rescued=0    ignored=0   

[2025-12-10 13:17:38] Ejecutando prechecks

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************

TASK [prechecks : Checking loadbalancer group] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/host_os_checks.yml for localhost

TASK [prechecks : Checking host OS distribution] *******************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking host OS release or version] *************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking if CentOS is Stream] ********************************
skipping: [localhost]

TASK [prechecks : Fail if not running on CentOS Stream] ************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/localtime exist] *********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/localtime is absent] ****************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/timezone exist] **********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/timezone is absent] *****************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Checking if system uses systemd] *****************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking Docker version] *************************************
ok: [localhost]

TASK [prechecks : Checking empty passwords in passwords.yml. Run kolla-genpwd if this task fails] ***
ok: [localhost]

TASK [prechecks : Check if nscd is running] ************************************
ok: [localhost]

TASK [prechecks : Fail if nscd is running] *************************************
skipping: [localhost]

TASK [prechecks : Validate that internal and external vip address are different when TLS is enabled only on either the internal and external network] ***
skipping: [localhost]

TASK [prechecks : Validate that enable_ceph is disabled] ***********************
skipping: [localhost]

TASK [prechecks : Validate that enable_redis is disabled] **********************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking docker SDK version] *********************************
ok: [localhost]

TASK [prechecks : Checking dbus-python package] ********************************
ok: [localhost]

TASK [prechecks : Checking Ansible version] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Check if config_owner_user existed] **************************
ok: [localhost]

TASK [prechecks : Check if config_owner_group existed] *************************
ok: [localhost]

TASK [prechecks : Check if ansible user can do passwordless sudo] **************
ok: [localhost]

TASK [prechecks : Check if external mariadb hosts are reachable from the load balancer] ***
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [prechecks : Check if external database address is reachable from all hosts] ***
skipping: [localhost]

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/precheck.yml for localhost

TASK [service-precheck : common | Validate inventory groups] *******************
skipping: [localhost] => (item=kolla-toolbox) 
skipping: [localhost]

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/precheck.yml for localhost

TASK [service-precheck : cron | Validate inventory groups] *********************
skipping: [localhost] => (item=cron) 
skipping: [localhost]

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/precheck.yml for localhost

TASK [service-precheck : fluentd | Validate inventory groups] ******************
skipping: [localhost] => (item=fluentd) 
skipping: [localhost]

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/precheck.yml for localhost

TASK [service-precheck : loadbalancer | Validate inventory groups] *************
skipping: [localhost] => (item=haproxy) 
skipping: [localhost] => (item=proxysql) 
skipping: [localhost] => (item=keepalived) 
skipping: [localhost] => (item=haproxy-ssh) 
skipping: [localhost]

TASK [loadbalancer : Get container facts] **************************************
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running keepalived] *******
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running HAProxy] **********
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running ProxySQL] *********
ok: [localhost]

TASK [loadbalancer : Set facts about whether we can run HAProxy and keepalived VIP prechecks] ***
ok: [localhost]

TASK [loadbalancer : Checking if external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking if internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is present] *****
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is active] ******
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address and kolla_external_vip_address are not pingable from any node] ***
skipping: [localhost] => (item=192.168.0.201) 
skipping: [localhost] => (item=192.168.0.201) 
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy stats] *********************
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (api interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (vip interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (api interface)] ****
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (vip interface)] ****
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (api interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (vip interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address is in the same network as api_interface on all nodes] ***
skipping: [localhost]

TASK [loadbalancer : Getting haproxy stat] *************************************
ok: [localhost]

TASK [loadbalancer : Setting haproxy stat fact] ********************************
ok: [localhost]

TASK [loadbalancer : Checking free port for Aodh API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Barbican API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Blazar API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Ceph RadosGW HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cinder API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cloudkitty API HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cyborg API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Designate API HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Glance API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Gnocchi API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Grafana server HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Heat API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Heat API CFN HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Horizon HAProxy] *******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Ironic API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Keystone Internal HAProxy] *********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Keystone Public HAProxy] ***********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Magnum API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Manila API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for MariaDB HAProxy/ProxySQL] **********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Masakari API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Mistral API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Neutron Server HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Metadata HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova NoVNC HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Serial Proxy HAProxy] *********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Spice HTML5 HAProxy] **********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Placement API HAProxy] ********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Octavia API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch Dashboards HAProxy] *****
skipping: [localhost]

TASK [loadbalancer : Checking free port for RabbitMQ Management HAProxy] *******
skipping: [localhost]

TASK [loadbalancer : Checking free port for Tacker Server HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Trove API HAProxy] *****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Watcher API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Zun API HAProxy] *******************
skipping: [localhost]

TASK [loadbalancer : Check if firewalld is running] ****************************
skipping: [localhost]

TASK [loadbalancer : Fail if firewalld is not running] *************************
skipping: [localhost]

TASK [include_role : aodh] *****************************************************
skipping: [localhost]

TASK [include_role : barbican] *************************************************
skipping: [localhost]

TASK [include_role : blazar] ***************************************************
skipping: [localhost]

TASK [include_role : ceph-rgw] *************************************************
skipping: [localhost]

TASK [include_role : cinder] ***************************************************
skipping: [localhost]

TASK [include_role : cloudkitty] ***********************************************
skipping: [localhost]

TASK [include_role : cyborg] ***************************************************
skipping: [localhost]

TASK [include_role : designate] ************************************************
skipping: [localhost]

TASK [include_role : etcd] *****************************************************
skipping: [localhost]

TASK [include_role : glance] ***************************************************
skipping: [localhost]

TASK [include_role : gnocchi] **************************************************
skipping: [localhost]

TASK [include_role : grafana] **************************************************
skipping: [localhost]

TASK [include_role : heat] *****************************************************
skipping: [localhost]

TASK [include_role : horizon] **************************************************
skipping: [localhost]

TASK [include_role : influxdb] *************************************************
skipping: [localhost]

TASK [include_role : ironic] ***************************************************
skipping: [localhost]

TASK [include_role : keystone] *************************************************
skipping: [localhost]

TASK [include_role : letsencrypt] **********************************************
skipping: [localhost]

TASK [include_role : magnum] ***************************************************
skipping: [localhost]

TASK [include_role : manila] ***************************************************
skipping: [localhost]

TASK [include_role : mariadb] **************************************************
skipping: [localhost]

TASK [include_role : masakari] *************************************************
skipping: [localhost]

TASK [include_role : memcached] ************************************************
skipping: [localhost]

TASK [include_role : mistral] **************************************************
skipping: [localhost]

TASK [include_role : neutron] **************************************************
skipping: [localhost]

TASK [include_role : placement] ************************************************
skipping: [localhost]

TASK [include_role : nova] *****************************************************
skipping: [localhost]

TASK [include_role : nova-cell] ************************************************
skipping: [localhost]

TASK [include_role : octavia] **************************************************
skipping: [localhost]

TASK [include_role : opensearch] ***********************************************
skipping: [localhost]

TASK [include_role : prometheus] ***********************************************
skipping: [localhost]

TASK [include_role : rabbitmq] *************************************************
skipping: [localhost]

TASK [include_role : skyline] **************************************************
skipping: [localhost]

TASK [include_role : tacker] ***************************************************
skipping: [localhost]

TASK [include_role : trove] ****************************************************
skipping: [localhost]

TASK [include_role : watcher] **************************************************
skipping: [localhost]

TASK [include_role : zun] ******************************************************
skipping: [localhost]

TASK [include_role : loadbalancer] *********************************************
skipping: [localhost]

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
ok: [localhost] => (item=localhost)

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/precheck.yml for localhost

TASK [service-precheck : mariadb | Validate inventory groups] ******************
skipping: [localhost] => (item=mariadb) 
skipping: [localhost]

TASK [mariadb : Get container facts] *******************************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB] ********************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB WSREP] **************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB IST] ****************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB SST] ****************************
skipping: [localhost]

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************
skipping: no hosts matched

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
skipping: [localhost]

TASK [Include mariadb post-upgrade.yml] ****************************************
skipping: [localhost]

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/precheck.yml for localhost

TASK [service-precheck : memcached | Validate inventory groups] ****************
skipping: [localhost] => (item=memcached) 
skipping: [localhost]

TASK [memcached : Get container facts] *****************************************
ok: [localhost]

TASK [memcached : Checking free port for Memcached] ****************************
skipping: [localhost]

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/precheck.yml for localhost

TASK [service-precheck : rabbitmq | Validate inventory groups] *****************
skipping: [localhost] => (item=rabbitmq) 
skipping: [localhost]

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ] ******************************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Management] *******************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Cluster] **********************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ EPMD] *************************
skipping: [localhost]

TASK [rabbitmq : Check if all rabbit hostnames are resolvable] *****************
ok: [localhost] => (item=localhost)

TASK [rabbitmq : Check if each rabbit hostname resolves uniquely to the proper IP address] ***
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 13:18:03.521980', 'end': '2025-12-10 13:18:03.529878', 'delta': '0:00:00.007898', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   STREAM nics-VMware20-1']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 13:18:03.521980', 'end': '2025-12-10 13:18:03.529878', 'delta': '0:00:00.007898', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   DGRAM  ']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 13:18:03.521980', 'end': '2025-12-10 13:18:03.529878', 'delta': '0:00:00.007898', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   RAW    ']) 
skipping: [localhost]

TASK [rabbitmq : Check if TLS certificate exists for RabbitMQ] *****************
skipping: [localhost]

TASK [rabbitmq : Check if TLS key exists for RabbitMQ] *************************
skipping: [localhost]

TASK [rabbitmq : List RabbitMQ queues] *****************************************
ok: [localhost]

TASK [rabbitmq : Check if RabbitMQ quorum queues need to be configured] ********
ok: [localhost] => (item=conductor.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=compute_fanout) 
skipping: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) 
skipping: [localhost] => (item=scheduler_fanout) 
ok: [localhost] => (item=conductor) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=scheduler.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=conductor_fanout) 
ok: [localhost] => (item=compute) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=compute.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=scheduler) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}

TASK [rabbitmq : Check if RabbitMQ quorum queues for transient queues need to be configured] ***
skipping: [localhost] => (item=conductor.nics-VMware20-1) 
skipping: [localhost] => (item=compute_fanout) 
ok: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "reply_nics-VMware20-1:nova-compute:1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=scheduler_fanout) 
skipping: [localhost] => (item=conductor) 
skipping: [localhost] => (item=scheduler.nics-VMware20-1) 
skipping: [localhost] => (item=conductor_fanout) 
skipping: [localhost] => (item=compute) 
skipping: [localhost] => (item=compute.nics-VMware20-1) 
skipping: [localhost] => (item=scheduler) 

TASK [rabbitmq : Check if RabbitMQ streams need to be configured] **************
skipping: [localhost] => (item=conductor.nics-VMware20-1) 
ok: [localhost] => (item=compute_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) 
ok: [localhost] => (item=scheduler_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=conductor) 
skipping: [localhost] => (item=scheduler.nics-VMware20-1) 
ok: [localhost] => (item=conductor_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=compute) 
skipping: [localhost] => (item=compute.nics-VMware20-1) 
skipping: [localhost] => (item=scheduler) 

PLAY [Restart rabbitmq services] ***********************************************
skipping: no hosts matched

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
skipping: [localhost]

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/precheck.yml for localhost

TASK [service-precheck : keystone | Validate inventory groups] *****************
skipping: [localhost] => (item=keystone) 
skipping: [localhost] => (item=keystone-fernet) 
skipping: [localhost] => (item=keystone-httpd) 
skipping: [localhost] => (item=keystone-ssh) 
skipping: [localhost]

TASK [keystone : Get container facts] ******************************************
ok: [localhost]

TASK [keystone : Checking free port for Keystone Public] ***********************
skipping: [localhost]

TASK [keystone : Checking free port for Keystone SSH] **************************
skipping: [localhost]

TASK [keystone : Checking fernet_token_expiry] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/precheck.yml for localhost

TASK [service-precheck : glance | Validate inventory groups] *******************
skipping: [localhost] => (item=glance-api) 
skipping: [localhost] => (item=glance-tls-proxy) 
skipping: [localhost]

TASK [glance : Get container facts] ********************************************
ok: [localhost]

TASK [glance : Checking free port for Glance API] ******************************
skipping: [localhost]

TASK [glance : Check if S3 configurations are defined] *************************
skipping: [localhost] => (item=glance_backend_s3_url) 
skipping: [localhost] => (item=glance_backend_s3_bucket) 
skipping: [localhost] => (item=glance_backend_s3_access_key) 
skipping: [localhost] => (item=glance_backend_s3_secret_key) 
skipping: [localhost]

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/precheck.yml for localhost

TASK [service-precheck : placement | Validate inventory groups] ****************
skipping: [localhost] => (item=placement-api) 
skipping: [localhost]

TASK [placement : Get container facts] *****************************************
ok: [localhost]

TASK [placement : Checking free port for Placement API] ************************
skipping: [localhost]

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/precheck.yml for localhost

TASK [service-precheck : openvswitch | Validate inventory groups] **************
skipping: [localhost] => (item=openvswitch-db-server) 
skipping: [localhost] => (item=openvswitch-vswitchd) 
skipping: [localhost]

TASK [openvswitch : Get container facts] ***************************************
ok: [localhost]

TASK [openvswitch : Checking free port for OVSDB] ******************************
skipping: [localhost]

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-api) 
skipping: [localhost] => (item=nova-metadata) 
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-super-conductor) 
skipping: [localhost]

TASK [nova : Get container facts] **********************************************
ok: [localhost]

TASK [nova : Checking free port for Nova API] **********************************
skipping: [localhost]

TASK [nova : Checking free port for Nova Metadata] *****************************
skipping: [localhost]

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-libvirt) 
skipping: [localhost] => (item=nova-ssh) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost]

TASK [nova-cell : Get container facts] *****************************************
ok: [localhost]

TASK [nova-cell : Checking available compute nodes in inventory] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova NoVNC Proxy] *********************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Serial Proxy] ********************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Spice HTML5 Proxy] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (API interface)] *************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (migration interface)] *******
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Libvirt] *************************
skipping: [localhost]

TASK [nova-cell : Checking that host libvirt is not running] *******************
skipping: [localhost]

TASK [nova-cell : Checking that nova_libvirt container is not running] *********
skipping: [localhost]

PLAY [Refresh nova scheduler cell cache] ***************************************

TASK [nova : Refresh cell cache in nova scheduler] *****************************
skipping: [localhost]

PLAY [Reload global Nova super conductor services] *****************************

TASK [nova : Reload nova super conductor services to remove RPC version pin] ***
skipping: [localhost]

PLAY [Reload Nova cell services] ***********************************************

TASK [nova-cell : Reload nova cell services to remove RPC version cap] *********
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost]

PLAY [Reload global Nova API services] *****************************************

TASK [nova : Reload nova API services to remove RPC version pin] ***************
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-api) 
skipping: [localhost]

PLAY [Run Nova API online data migrations] *************************************

TASK [nova : Run Nova API online database migrations] **************************
skipping: [localhost]

PLAY [Run Nova cell online data migrations] ************************************

TASK [nova-cell : Run Nova cell online database migrations] ********************
skipping: [localhost]

PLAY [Apply role neutron] ******************************************************

TASK [neutron : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/neutron/tasks/precheck.yml for localhost

TASK [service-precheck : neutron | Validate inventory groups] ******************
skipping: [localhost] => (item=neutron-server) 
skipping: [localhost] => (item=neutron-rpc-server) 
skipping: [localhost] => (item=neutron-periodic-worker) 
skipping: [localhost] => (item=neutron-ovn-maintenance-worker) 
skipping: [localhost] => (item=neutron-openvswitch-agent) 
skipping: [localhost] => (item=neutron-dhcp-agent) 
skipping: [localhost] => (item=neutron-l3-agent) 
skipping: [localhost] => (item=neutron-sriov-agent) 
skipping: [localhost] => (item=neutron-mlnx-agent) 
skipping: [localhost] => (item=neutron-eswitchd) 
skipping: [localhost] => (item=neutron-metadata-agent) 
skipping: [localhost] => (item=neutron-ovn-metadata-agent) 
skipping: [localhost] => (item=neutron-bgp-dragent) 
skipping: [localhost] => (item=neutron-infoblox-ipam-agent) 
skipping: [localhost] => (item=neutron-metering-agent) 
skipping: [localhost] => (item=ironic-neutron-agent) 
skipping: [localhost] => (item=neutron-ovn-agent) 
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Checking free port for Neutron Server] *************************
ok: [localhost]

TASK [neutron : Checking number of network agents] *****************************
skipping: [localhost]

TASK [neutron : Checking tenant network types] *********************************
ok: [localhost] => (item=vxlan) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": "vxlan",
    "msg": "All assertions passed"
}

TASK [neutron : Checking whether Ironic enabled] *******************************
skipping: [localhost]

TASK [neutron : Checking if neutron's dns domain has proper value] *************
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Get container volume facts] ************************************
ok: [localhost]

TASK [neutron : Check for ML2/OVN presence] ************************************
skipping: [localhost]

TASK [neutron : Check for ML2/OVS presence] ************************************
skipping: [localhost]

PLAY [Apply role kuryr] ********************************************************
skipping: no hosts matched

PLAY [Apply role hacluster] ****************************************************
skipping: no hosts matched

PLAY [Apply role heat] *********************************************************

TASK [heat : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/heat/tasks/precheck.yml for localhost

TASK [service-precheck : heat | Validate inventory groups] *********************
skipping: [localhost] => (item=heat-api) 
skipping: [localhost] => (item=heat-api-cfn) 
skipping: [localhost] => (item=heat-engine) 
skipping: [localhost]

TASK [heat : Get container facts] **********************************************
ok: [localhost]

TASK [heat : Checking free port for Heat API] **********************************
ok: [localhost]

TASK [heat : Checking free port for Heat API CFN] ******************************
ok: [localhost]

PLAY [Apply role horizon] ******************************************************

TASK [horizon : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/horizon/tasks/precheck.yml for localhost

TASK [service-precheck : horizon | Validate inventory groups] ******************
skipping: [localhost] => (item=horizon) 
skipping: [localhost]

TASK [horizon : Get container facts] *******************************************
ok: [localhost]

TASK [horizon : Checking free port for Horizon] ********************************
ok: [localhost]

PLAY [Apply role magnum] *******************************************************
skipping: no hosts matched

PLAY [Apply role mistral] ******************************************************
skipping: no hosts matched

PLAY [Apply role manila] *******************************************************
skipping: no hosts matched

PLAY [Apply role gnocchi] ******************************************************
skipping: no hosts matched

PLAY [Apply role ceilometer] ***************************************************
skipping: no hosts matched

PLAY [Apply role aodh] *********************************************************
skipping: no hosts matched

PLAY [Apply role barbican] *****************************************************
skipping: no hosts matched

PLAY [Apply role cyborg] *******************************************************
skipping: no hosts matched

PLAY [Apply role designate] ****************************************************
skipping: no hosts matched

PLAY [Apply role trove] ********************************************************
skipping: no hosts matched

PLAY [Apply role watcher] ******************************************************
skipping: no hosts matched

PLAY [Apply role grafana] ******************************************************
skipping: no hosts matched

PLAY [Apply role cloudkitty] ***************************************************
skipping: no hosts matched

PLAY [Apply role tacker] *******************************************************
skipping: no hosts matched

PLAY [Apply role octavia] ******************************************************
skipping: no hosts matched

PLAY [Apply role zun] **********************************************************
skipping: no hosts matched

PLAY [Apply role blazar] *******************************************************
skipping: no hosts matched

PLAY [Apply role masakari] *****************************************************
skipping: no hosts matched

PLAY [Apply role skyline] ******************************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
localhost                  : ok=70   changed=0    unreachable=0    failed=0    skipped=166  rescued=0    ignored=0   

[2025-12-10 13:18:26] Ejecutando deploy

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************
skipping: no hosts matched

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/deploy.yml for localhost

TASK [common : Ensuring config directories exist] ******************************
changed: [localhost] => (item=[{'service_name': 'kolla-toolbox'}, 'kolla-toolbox'])

TASK [common : include_tasks] **************************************************
skipping: [localhost]

TASK [common : Copying over config.json files for services] ********************
ok: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [common : Ensure RabbitMQ Erlang cookie exists] ***************************
ok: [localhost]

TASK [common : Ensuring config directories have correct owner and permission] ***
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [common : Copy rabbitmq-env.conf to kolla toolbox] ************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/rabbitmq-env.conf.j2)

TASK [common : Copy rabbitmq erl_inetrc to kolla toolbox] **********************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/erl_inetrc.j2)

TASK [service-check-containers : common | Check containers] ********************
ok: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : common | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [common : Creating log volume] ********************************************
ok: [localhost]

TASK [common : Link kolla_logs volume to /var/log/kolla] ***********************
ok: [localhost]

TASK [common : Flush handlers] *************************************************

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/deploy.yml for localhost

TASK [cron : Ensuring config directories exist] ********************************
changed: [localhost]

TASK [cron : include_tasks] ****************************************************
skipping: [localhost]

TASK [cron : Copying over config.json files for services] **********************
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [cron : Copying over cron logrotate config file] **************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/templates/cron-logrotate-global.conf.j2)

TASK [cron : Ensuring config directories have correct owner and permission] ****
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : cron | Check containers] **********************
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})

TASK [service-check-containers : cron | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [cron : Flush handlers] ***************************************************

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/deploy.yml for localhost

TASK [fluentd : Ensuring config directories exist] *****************************
changed: [localhost]

TASK [fluentd : include_tasks] *************************************************
skipping: [localhost]

TASK [fluentd : Ensure /var/log/journal exists on EL systems] ******************
skipping: [localhost]

TASK [fluentd : Copying over config.json files for services] *******************
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [fluentd : Find custom fluentd input config files] ************************
ok: [localhost]

TASK [fluentd : Find custom fluentd filter config files] ***********************
ok: [localhost]

TASK [fluentd : Find custom fluentd format config files] ***********************
ok: [localhost]

TASK [fluentd : Find custom fluentd output config files] ***********************
ok: [localhost]

TASK [fluentd : Copying over fluentd.conf] *************************************
ok: [localhost]

TASK [fluentd : Ensuring config directories have correct owner and permission] ***
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [service-check-containers : fluentd | Check containers] *******************
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})

TASK [service-check-containers : fluentd | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [fluentd : Flush handlers] ************************************************

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/deploy.yml for localhost

TASK [loadbalancer : Check IPv6 support] ***************************************
ok: [localhost]

TASK [Setting sysctl values] ***************************************************
included: sysctl for localhost

TASK [sysctl : Check IPv6 support] *********************************************
ok: [localhost]

TASK [sysctl : Setting sysctl values] ******************************************
ok: [localhost] => (item={'name': 'net.ipv6.ip_nonlocal_bind', 'value': 1})
ok: [localhost] => (item={'name': 'net.ipv4.ip_nonlocal_bind', 'value': 1})
ok: [localhost] => (item={'name': 'net.ipv4.tcp_retries2', 'value': 'KOLLA_UNSET'})
ok: [localhost] => (item={'name': 'net.unix.max_dgram_qlen', 'value': 128})

TASK [module-load : Load modules] **********************************************
ok: [localhost] => (item=ip_vs)

TASK [module-load : Persist modules via modules-load.d] ************************
ok: [localhost] => (item=ip_vs)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=ip_vs) 
skipping: [localhost]

TASK [loadbalancer : Ensuring config directories exist] ************************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [loadbalancer : Ensuring haproxy service config subdir exists] ************
changed: [localhost]

TASK [loadbalancer : Ensuring proxysql service config subdirectories exist] ****
changed: [localhost] => (item=users)
changed: [localhost] => (item=rules)

TASK [loadbalancer : Ensuring keepalived checks subdir exists] *****************
changed: [localhost]

TASK [loadbalancer : Remove mariadb.cfg if proxysql enabled] *******************
ok: [localhost]

TASK [loadbalancer : Removing checks for services which are disabled] **********
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__a52564f47ad68be909f3178832d6e319d1ee6e1e', '__omit_place_holder__a52564f47ad68be909f3178832d6e319d1ee6e1e'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [loadbalancer : Copying checks for services which are enabled] ************
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__a52564f47ad68be909f3178832d6e319d1ee6e1e', '__omit_place_holder__a52564f47ad68be909f3178832d6e319d1ee6e1e'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}}) 

TASK [loadbalancer : Copying over config.json files for services] **************
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [loadbalancer : Copying over haproxy.cfg] *********************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_main.cfg.j2)

TASK [loadbalancer : Copying over proxysql config] *****************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql.yaml.j2)

TASK [loadbalancer : Copying over haproxy single external frontend config] *****
skipping: [localhost]

TASK [loadbalancer : Copying over custom haproxy services configuration] *******
skipping: [localhost]

TASK [loadbalancer : Copying over keepalived.conf] *****************************
changed: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/keepalived/keepalived.conf.j2)

TASK [loadbalancer : include_tasks] ********************************************
skipping: [localhost]

TASK [loadbalancer : Copying over haproxy start script] ************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_run.sh.j2)

TASK [loadbalancer : Copying over proxysql start script] ***********************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql_run.sh.j2)

TASK [loadbalancer : Copying files for haproxy-ssh] ****************************
skipping: [localhost] => (item={'src': 'haproxy-ssh/sshd_config.j2', 'dest': 'sshd_config'}) 
skipping: [localhost] => (item={'src': 'haproxy-ssh/id_rsa.pub', 'dest': 'id_rsa.pub'}) 
skipping: [localhost]

TASK [service-check-containers : loadbalancer | Check containers] **************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost]

TASK [include_role : aodh] *****************************************************
skipping: [localhost]

TASK [include_role : barbican] *************************************************
skipping: [localhost]

TASK [include_role : blazar] ***************************************************
skipping: [localhost]

TASK [include_role : ceph-rgw] *************************************************
skipping: [localhost]

TASK [include_role : cinder] ***************************************************
skipping: [localhost]

TASK [include_role : cloudkitty] ***********************************************
skipping: [localhost]

TASK [include_role : cyborg] ***************************************************
skipping: [localhost]

TASK [include_role : designate] ************************************************
skipping: [localhost]

TASK [include_role : etcd] *****************************************************
skipping: [localhost]

TASK [include_role : glance] ***************************************************
included: glance for localhost

TASK [haproxy-config : Copying over glance haproxy config] *********************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}}) 

TASK [haproxy-config : Add configuration for glance when using single external frontend] ***
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for glance] ************************
skipping: [localhost] => (item={'key': 'glance_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost] => (item={'key': 'glance_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over glance ProxySQL users config] *************
ok: [localhost]

TASK [proxysql-config : Copying over glance ProxySQL rules config] *************
ok: [localhost]

TASK [include_role : gnocchi] **************************************************
skipping: [localhost]

TASK [include_role : grafana] **************************************************
skipping: [localhost]

TASK [include_role : heat] *****************************************************
included: heat for localhost

TASK [haproxy-config : Copying over heat haproxy config] ***********************
changed: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for heat when using single external frontend] ***
skipping: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for heat] **************************
skipping: [localhost] => (item={'key': 'heat_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_cfn', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'heat_api_cfn_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over heat ProxySQL users config] ***************
ok: [localhost]

TASK [proxysql-config : Copying over heat ProxySQL rules config] ***************
ok: [localhost]

TASK [include_role : horizon] **************************************************
included: horizon for localhost

TASK [haproxy-config : Copying over horizon haproxy config] ********************
changed: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}})

TASK [haproxy-config : Add configuration for horizon when using single external frontend] ***
skipping: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for horizon] ***********************
skipping: [localhost] => (item={'key': 'horizon', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'horizon_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}}) 
skipping: [localhost] => (item={'key': 'horizon_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'horizon_external_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}}) 
skipping: [localhost] => (item={'key': 'acme_client', 'value': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over horizon ProxySQL users config] ************
ok: [localhost]

TASK [proxysql-config : Copying over horizon ProxySQL rules config] ************
ok: [localhost]

TASK [include_role : influxdb] *************************************************
skipping: [localhost]

TASK [include_role : ironic] ***************************************************
skipping: [localhost]

TASK [include_role : keystone] *************************************************
included: keystone for localhost

TASK [haproxy-config : Copying over keystone haproxy config] *******************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for keystone when using single external frontend] ***
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for keystone] **********************
skipping: [localhost] => (item={'key': 'keystone_internal', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}) 
skipping: [localhost] => (item={'key': 'keystone_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over keystone ProxySQL users config] ***********
ok: [localhost]

TASK [proxysql-config : Copying over keystone ProxySQL rules config] ***********
ok: [localhost]

TASK [include_role : letsencrypt] **********************************************
skipping: [localhost]

TASK [include_role : magnum] ***************************************************
skipping: [localhost]

TASK [include_role : manila] ***************************************************
skipping: [localhost]

TASK [include_role : mariadb] **************************************************
included: mariadb for localhost

TASK [mariadb : Ensure mysql monitor user exist] *******************************
ok: [localhost] => (item=localhost)

TASK [haproxy-config : Copying over mariadb haproxy config] ********************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for mariadb when using single external frontend] ***
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for mariadb] ***********************
skipping: [localhost] => (item={'key': 'mariadb_external_lb', 'value': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over mariadb ProxySQL users config] ************
ok: [localhost]

TASK [proxysql-config : Copying over mariadb ProxySQL rules config] ************
skipping: [localhost]

TASK [include_role : masakari] *************************************************
skipping: [localhost]

TASK [include_role : memcached] ************************************************
included: memcached for localhost

TASK [haproxy-config : Copying over memcached haproxy config] ******************
ok: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})

TASK [haproxy-config : Add configuration for memcached when using single external frontend] ***
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for memcached] *********************
skipping: [localhost] => (item={'key': 'memcached', 'value': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over memcached ProxySQL users config] **********
skipping: [localhost]

TASK [proxysql-config : Copying over memcached ProxySQL rules config] **********
skipping: [localhost]

TASK [include_role : mistral] **************************************************
skipping: [localhost]

TASK [include_role : neutron] **************************************************
included: neutron for localhost

TASK [haproxy-config : Copying over neutron haproxy config] ********************
changed: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}})
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}}) 
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for neutron when using single external frontend] ***
skipping: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}}) 
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}}) 
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}}) 
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}}) 
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for neutron] ***********************
skipping: [localhost] => (item={'key': 'neutron_server', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}) 
skipping: [localhost] => (item={'key': 'neutron_server_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over neutron ProxySQL users config] ************
ok: [localhost]

TASK [proxysql-config : Copying over neutron ProxySQL rules config] ************
ok: [localhost]

TASK [include_role : placement] ************************************************
included: placement for localhost

TASK [haproxy-config : Copying over placement haproxy config] ******************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [haproxy-config : Add configuration for placement when using single external frontend] ***
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for placement] *********************
skipping: [localhost] => (item={'key': 'placement_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}) 
skipping: [localhost] => (item={'key': 'placement_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over placement ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over placement ProxySQL rules config] **********
ok: [localhost]

TASK [include_role : nova] *****************************************************
included: nova for localhost

TASK [haproxy-config : Copying over nova haproxy config] ***********************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 

TASK [haproxy-config : Add configuration for nova when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova] **************************
skipping: [localhost] => (item={'key': 'nova_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_metadata', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost] => (item={'key': 'nova_metadata_external', 'value': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over nova ProxySQL users config] ***************
ok: [localhost]

TASK [proxysql-config : Copying over nova ProxySQL rules config] ***************
ok: [localhost]

TASK [include_role : nova-cell] ************************************************
included: nova-cell for localhost

TASK [nova-cell : Configure loadbalancer for nova-novncproxy] ******************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-novncproxy)

TASK [haproxy-config : Copying over nova-cell:nova-novncproxy haproxy config] ***
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}})

TASK [haproxy-config : Add configuration for nova-cell:nova-novncproxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-novncproxy] *****
skipping: [localhost] => (item={'key': 'nova_novncproxy', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}) 
skipping: [localhost] => (item={'key': 'nova_novncproxy_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
ok: [localhost]

TASK [nova-cell : Configure loadbalancer for nova-spicehtml5proxy] *************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-spicehtml5proxy)

TASK [haproxy-config : Copying over nova-cell:nova-spicehtml5proxy haproxy config] ***
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for nova-cell:nova-spicehtml5proxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-spicehtml5proxy] ***
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
ok: [localhost]

TASK [nova-cell : Configure loadbalancer for nova-serialproxy] *****************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-serialproxy)

TASK [haproxy-config : Copying over nova-cell:nova-serialproxy haproxy config] ***
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Add configuration for nova-cell:nova-serialproxy when using single external frontend] ***
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for nova-cell:nova-serialproxy] ****
skipping: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
ok: [localhost]

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
ok: [localhost]

TASK [include_role : octavia] **************************************************
skipping: [localhost]

TASK [include_role : opensearch] ***********************************************
skipping: [localhost]

TASK [include_role : prometheus] ***********************************************
skipping: [localhost]

TASK [include_role : rabbitmq] *************************************************
included: rabbitmq for localhost

TASK [haproxy-config : Copying over rabbitmq haproxy config] *******************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [haproxy-config : Add configuration for rabbitmq when using single external frontend] ***
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) 
skipping: [localhost]

TASK [haproxy-config : Configuring firewall for rabbitmq] **********************
skipping: [localhost] => (item={'key': 'rabbitmq_management', 'value': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}) 
skipping: [localhost]

TASK [proxysql-config : Copying over rabbitmq ProxySQL users config] ***********
skipping: [localhost]

TASK [proxysql-config : Copying over rabbitmq ProxySQL rules config] ***********
skipping: [localhost]

TASK [include_role : skyline] **************************************************
skipping: [localhost]

TASK [include_role : tacker] ***************************************************
skipping: [localhost]

TASK [include_role : trove] ****************************************************
skipping: [localhost]

TASK [include_role : watcher] **************************************************
skipping: [localhost]

TASK [include_role : zun] ******************************************************
skipping: [localhost]

TASK [include_role : loadbalancer] *********************************************
included: loadbalancer for localhost

TASK [service-check-containers : loadbalancer | Check containers] **************
changed: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) 
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Check IP addresses on the API interface] *******
ok: [localhost]

RUNNING HANDLER [loadbalancer : Group HA nodes by status] **********************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup keepalived container] **************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup haproxy container] *****************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Stop backup proxysql container] ****************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Start backup haproxy container] ****************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Wait for backup haproxy to start] **************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Start backup proxysql container] ***************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Wait for backup proxysql to start] *************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Start backup keepalived container] *************
changed: [localhost]

RUNNING HANDLER [loadbalancer : Stop master haproxy container] *****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Stop master proxysql container] ****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Stop master keepalived container] **************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master haproxy container] ****************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master proxysql container] ***************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Start master keepalived container] *************
skipping: [localhost]

RUNNING HANDLER [loadbalancer : Wait for haproxy to listen on VIP] *************
ok: [localhost]

RUNNING HANDLER [loadbalancer : Wait for proxysql to listen on VIP] ************
ok: [localhost]

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
ok: [localhost] => (item=localhost)

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/deploy.yml for localhost

TASK [mariadb : Ensuring config directories exist] *****************************
changed: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [mariadb : Ensuring database backup config directory exists] **************
skipping: [localhost]

TASK [mariadb : Copying over my.cnf for mariabackup] ***************************
skipping: [localhost]

TASK [mariadb : Copying over config.json files for services] *******************
ok: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [mariadb : Copying over config.json files for mariabackup] ****************
skipping: [localhost]

TASK [mariadb : Copying over galera.cnf] ***************************************
ok: [localhost]

TASK [mariadb : Copying over healthcheck.cnf] **********************************
ok: [localhost]

TASK [mariadb : include_tasks] *************************************************
skipping: [localhost]

TASK [service-check-containers : mariadb | Check containers] *******************
ok: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})

TASK [service-check-containers : mariadb | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Checking for mariadb cluster] **********************************
skipping: [localhost]

TASK [mariadb : Cleaning up temp file on localhost] ****************************
skipping: [localhost]

TASK [mariadb : Stop MariaDB containers] ***************************************
skipping: [localhost]

TASK [mariadb : Run MariaDB wsrep recovery] ************************************
skipping: [localhost]

TASK [mariadb : Copying MariaDB log file to /tmp] ******************************
skipping: [localhost]

TASK [mariadb : Get MariaDB wsrep recovery seqno] ******************************
skipping: [localhost]

TASK [mariadb : Removing MariaDB log file from /tmp] ***************************
skipping: [localhost]

TASK [mariadb : Registering MariaDB seqno variable] ****************************
skipping: [localhost]

TASK [mariadb : Comparing seqno value on all mariadb hosts] ********************
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [mariadb : Writing hostname of host with the largest seqno to temp file] ***
skipping: [localhost]

TASK [mariadb : Registering mariadb_recover_inventory_name from temp file] *****
skipping: [localhost]

TASK [mariadb : Store bootstrap and master hostnames into facts] ***************
skipping: [localhost]

TASK [mariadb : Set grastate.dat file from MariaDB container in bootstrap host] ***
skipping: [localhost]

TASK [mariadb : Refresh galera.cnf to set first MariaDB container as primary] ***
skipping: [localhost]

TASK [mariadb : Starting first MariaDB container] ******************************
skipping: [localhost]

TASK [mariadb : Wait for first MariaDB container] ******************************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB to become operational] ************************
skipping: [localhost]

TASK [mariadb : Restart slave MariaDB container(s)] ****************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Wait for slave MariaDB] ****************************************
skipping: [localhost]

TASK [mariadb : Unset pc.bootstrap for primary MariaDB galera.cnf for next restart] ***
skipping: [localhost]

TASK [mariadb : Restart master MariaDB container(s)] ***************************
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [mariadb : Wait for MariaDB] **********************************************
skipping: [localhost]

TASK [service-check : mariadb | Get container facts] ***************************
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
skipping: [localhost]

TASK [mariadb : Create MariaDB volume] *****************************************
ok: [localhost]

TASK [mariadb : Divide hosts by their MariaDB volume availability] *************
ok: [localhost]

TASK [mariadb : Establish whether the cluster has already existed] *************
ok: [localhost]

TASK [mariadb : Check MariaDB service port liveness] ***************************
ok: [localhost]

TASK [mariadb : Divide hosts by their MariaDB service port liveness] ***********
ok: [localhost]

TASK [mariadb : Fail on existing but stopped cluster] **************************
skipping: [localhost]

TASK [mariadb : Check MariaDB service WSREP sync status] ***********************
ok: [localhost]

TASK [mariadb : Extract MariaDB service WSREP sync status] *********************
ok: [localhost]

TASK [mariadb : Divide hosts by their MariaDB service WSREP sync status] *******
ok: [localhost]

TASK [mariadb : Fail when MariaDB services are not synced across the whole cluster] ***
skipping: [localhost]

TASK [mariadb : include_tasks] *************************************************
skipping: [localhost]

TASK [mariadb : include_tasks] *************************************************
skipping: [localhost]

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************
skipping: no hosts matched

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
included: mariadb for localhost

TASK [mariadb : Creating shard root mysql user] ********************************
ok: [localhost]

TASK [mariadb : Creating mysql monitor user] ***********************************
changed: [localhost]

TASK [mariadb : Creating database backup user and setting permissions] *********
skipping: [localhost]

TASK [mariadb : Granting permissions on Mariabackup database to backup user] ***
skipping: [localhost]

TASK [service-check : mariadb | Get container facts] ***************************
ok: [localhost]

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
skipping: [localhost]

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
skipping: [localhost]

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
ok: [localhost]

TASK [Include mariadb post-upgrade.yml] ****************************************
skipping: [localhost]

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/deploy.yml for localhost

TASK [memcached : Ensuring config directories exist] ***************************
changed: [localhost] => (item=memcached)

TASK [memcached : Copying over config.json files for services] *****************
ok: [localhost] => (item=memcached)

TASK [service-check-containers : memcached | Check containers] *****************
ok: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})

TASK [service-check-containers : memcached | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) 
skipping: [localhost]

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/deploy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : Get current RabbitMQ version] *********************************
ok: [localhost]

TASK [rabbitmq : Get new RabbitMQ version] *************************************
ok: [localhost]

TASK [rabbitmq : Check if running RabbitMQ is at most one version behind] ******
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [rabbitmq : Catch when RabbitMQ is being downgraded] **********************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : List RabbitMQ policies] ***************************************
ok: [localhost]

TASK [rabbitmq : Remove ha-all policy from RabbitMQ] ***************************
skipping: [localhost]

TASK [rabbitmq : Ensuring config directories exist] ****************************
changed: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [rabbitmq : Copying over config.json files for services] ******************
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [rabbitmq : Copying over rabbitmq-env.conf] *******************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2)

TASK [rabbitmq : Copying over rabbitmq.conf] ***********************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq.conf.j2)

TASK [rabbitmq : Copying over erl_inetrc] **************************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/erl_inetrc.j2)

TASK [rabbitmq : Copying over advanced.config] *********************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/advanced.config.j2)

TASK [rabbitmq : Copying over definitions.json] ********************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/definitions.json.j2)

TASK [rabbitmq : Copying over enabled_plugins] *********************************
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/enabled_plugins.j2)

TASK [rabbitmq : include_tasks] ************************************************
skipping: [localhost]

TASK [service-check-containers : rabbitmq | Check containers] ******************
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})

TASK [service-check-containers : rabbitmq | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) 
skipping: [localhost]

TASK [rabbitmq : Creating rabbitmq volume] *************************************
ok: [localhost]

TASK [rabbitmq : Running RabbitMQ bootstrap container] *************************
skipping: [localhost]

PLAY [Restart rabbitmq services] ***********************************************
skipping: no hosts matched

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
included: rabbitmq for localhost

TASK [rabbitmq : Enable all stable feature flags] ******************************
ok: [localhost]

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml for localhost

TASK [keystone : Ensuring config directories exist] ****************************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [keystone : Check if policies shall be overwritten] ***********************
skipping: [localhost]

TASK [keystone : Set keystone policy file] *************************************
skipping: [localhost]

TASK [keystone : Check if Keystone domain-specific config is supplied] *********
ok: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Copying over config.json files for services] ******************
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
ok: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [keystone : Copying over keystone.conf] ***********************************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 

TASK [keystone : Copying keystone-startup script for keystone] *****************
ok: [localhost]

TASK [keystone : Create Keystone domain-specific config directory] *************
skipping: [localhost]

TASK [keystone : Get file list in custom domains folder] ***********************
skipping: [localhost]

TASK [keystone : Copying Keystone Domain specific settings] ********************
skipping: [localhost]

TASK [keystone : Copying over existing policy file] ****************************
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Copying over wsgi-keystone.conf] ******************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/wsgi-keystone.conf.j2) 
skipping: [localhost]

TASK [Configure uWSGI for Keystone] ********************************************
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over keystone uWSGI config] ***************
ok: [localhost]

TASK [keystone : Copying over httpd-keystone.conf] *****************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/httpd-keystone.conf.j2) 
skipping: [localhost]

TASK [keystone : Checking whether keystone-paste.ini file exists] **************
ok: [localhost]

TASK [keystone : Copying over keystone-paste.ini] ******************************
skipping: [localhost]

TASK [keystone : Generate the required cron jobs for the node] *****************
ok: [localhost]

TASK [keystone : Set fact with the generated cron jobs for building the crontab later] ***
ok: [localhost]

TASK [keystone : Copying files for keystone-fernet] ****************************
ok: [localhost] => (item={'src': 'crontab.j2', 'dest': 'crontab'})
ok: [localhost] => (item={'src': 'fernet-rotate.sh.j2', 'dest': 'fernet-rotate.sh'})
ok: [localhost] => (item={'src': 'fernet-node-sync.sh.j2', 'dest': 'fernet-node-sync.sh'})
ok: [localhost] => (item={'src': 'fernet-push.sh.j2', 'dest': 'fernet-push.sh'})
ok: [localhost] => (item={'src': 'fernet-healthcheck.sh.j2', 'dest': 'fernet-healthcheck.sh'})
ok: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'})
ok: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'})

TASK [keystone : Copying files for keystone-ssh] *******************************
ok: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'})
ok: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'})

TASK [service-check-containers : keystone | Check containers] ******************
changed: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})
changed: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})

TASK [service-check-containers : keystone | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

TASK [keystone : Creating keystone database] ***********************************
ok: [localhost]

TASK [keystone : Creating Keystone database user and setting permissions] ******
ok: [localhost]

TASK [keystone : Checking for any running keystone_fernet containers] **********
ok: [localhost]

TASK [keystone : Group nodes where keystone_fernet is running] *****************
ok: [localhost]

TASK [keystone : Fail if any hosts need bootstrapping and not all hosts targeted] ***
skipping: [localhost]

TASK [keystone : Running Keystone bootstrap container] *************************
changed: [localhost]

TASK [keystone : Running Keystone fernet bootstrap container] ******************
skipping: [localhost]

TASK [keystone : Flush handlers] ***********************************************

RUNNING HANDLER [keystone : Restart keystone-fernet container] *****************
changed: [localhost]

RUNNING HANDLER [keystone : Restart keystone container] ************************
changed: [localhost]

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/distribute_fernet.yml for localhost

TASK [keystone : Waiting for Keystone SSH port to be UP] ***********************
ok: [localhost]

TASK [keystone : Run key distribution] *****************************************
changed: [localhost]

TASK [keystone : Creating admin project, user, role, service, and endpoint] ****
changed: [localhost] => (item=RegionOne)

TASK [service-ks-register : keystone | Creating/deleting services] *************
ok: [localhost] => (item=keystone (identity))

TASK [service-ks-register : keystone | Creating/deleting endpoints] ************
ok: [localhost] => (item=keystone -> http://192.168.0.201:5000 -> internal)
ok: [localhost] => (item=keystone -> http://192.168.0.201:5000 -> public)

TASK [service-ks-register : keystone | Creating projects] **********************
skipping: [localhost]

TASK [service-ks-register : keystone | Creating/deleting users] ****************
skipping: [localhost]

TASK [service-ks-register : keystone | Creating roles] *************************
skipping: [localhost]

TASK [service-ks-register : keystone | Granting/revoking user roles] ***********
skipping: [localhost]

TASK [keystone : Creating default user role] ***********************************
ok: [localhost]

TASK [keystone : include_tasks] ************************************************
skipping: [localhost]

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/deploy.yml for localhost

TASK [service-ks-register : glance | Creating/deleting services] ***************
ok: [localhost] => (item=glance (image))

TASK [service-ks-register : glance | Creating/deleting endpoints] **************
changed: [localhost] => (item=glance -> http://192.168.0.201:9292 -> internal)
changed: [localhost] => (item=glance -> http://192.168.0.201:9292 -> public)

TASK [service-ks-register : glance | Creating projects] ************************
ok: [localhost] => (item=service)

TASK [service-ks-register : glance | Creating/deleting users] ******************
changed: [localhost] => (item=glance -> service)

TASK [service-ks-register : glance | Creating roles] ***************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : glance | Granting/revoking user roles] *************
ok: [localhost] => (item=glance -> service -> admin)

TASK [glance : Ensuring config directories exist] ******************************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Check if policies shall be overwritten] *************************
skipping: [localhost]

TASK [glance : Set glance policy file] *****************************************
skipping: [localhost]

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Creating TLS backend PEM File] **********************************
skipping: [localhost]

TASK [glance : Copying over config.json files for services] ********************
ok: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [glance : Copying over glance-api.conf] ***********************************
changed: [localhost]

TASK [glance : Copying over glance-cache.conf for glance_api] ******************
skipping: [localhost]

TASK [glance : Copying over glance-image-import.conf] **************************
skipping: [localhost]

TASK [glance : Copying over property-protections-rules.conf] *******************
skipping: [localhost]

TASK [glance : Copying over existing policy file] ******************************
skipping: [localhost]

TASK [glance : Copying over glance-haproxy-tls.cfg] ****************************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/templates/glance-tls-proxy.cfg.j2) 
skipping: [localhost]

TASK [service-check-containers : glance | Check containers] ********************
changed: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})

TASK [service-check-containers : glance | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) 
skipping: [localhost]

TASK [glance : include_tasks] **************************************************
skipping: [localhost]

TASK [glance : Creating Glance database] ***************************************
ok: [localhost]

TASK [glance : Creating Glance database user and setting permissions] **********
ok: [localhost]

TASK [glance : Enable log_bin_trust_function_creators function] ****************
changed: [localhost]

TASK [glance : Running Glance bootstrap container] *****************************
changed: [localhost]

TASK [glance : Disable log_bin_trust_function_creators function] ***************
changed: [localhost]

TASK [glance : Flush handlers] *************************************************

RUNNING HANDLER [glance : Restart glance-api container] ************************
changed: [localhost]

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/deploy.yml for localhost

TASK [service-ks-register : placement | Creating/deleting services] ************
ok: [localhost] => (item=placement (placement))

TASK [service-ks-register : placement | Creating/deleting endpoints] ***********
changed: [localhost] => (item=placement -> http://192.168.0.201:8780 -> internal)
changed: [localhost] => (item=placement -> http://192.168.0.201:8780 -> public)

TASK [service-ks-register : placement | Creating projects] *********************
ok: [localhost] => (item=service)

TASK [service-ks-register : placement | Creating/deleting users] ***************
changed: [localhost] => (item=placement -> service)

TASK [service-ks-register : placement | Creating roles] ************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : placement | Granting/revoking user roles] **********
ok: [localhost] => (item=placement -> service -> admin)

TASK [placement : include_tasks] ***********************************************
skipping: [localhost]

TASK [placement : Ensuring config directories exist] ***************************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Check if policies shall be overwritten] **********************
skipping: [localhost]

TASK [placement : Set placement policy file] ***********************************
skipping: [localhost]

TASK [placement : include_tasks] ***********************************************
skipping: [localhost]

TASK [placement : Copying over config.json files for services] *****************
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Copying over placement.conf] *********************************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [placement : Copying over placement-api wsgi configuration] ***************
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/templates/placement-api-wsgi.conf.j2) 
skipping: [localhost]

TASK [Configure uWSGI for Placement] *******************************************
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over placement-api uWSGI config] **********
ok: [localhost]

TASK [placement : Copying over migrate-db.rc.j2 configuration] *****************
changed: [localhost]

TASK [placement : Copying over existing policy file] ***************************
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [service-check-containers : placement | Check containers] *****************
changed: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})

TASK [service-check-containers : placement | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) 
skipping: [localhost]

TASK [placement : Creating placement databases] ********************************
ok: [localhost]

TASK [placement : Creating placement databases user and setting permissions] ***
ok: [localhost]

TASK [placement : Running placement bootstrap container] ***********************
changed: [localhost]

TASK [placement : Flush handlers] **********************************************

RUNNING HANDLER [placement : Restart placement-api container] ******************
changed: [localhost]

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/deploy.yml for localhost

TASK [module-load : Load modules] **********************************************
ok: [localhost] => (item=openvswitch)

TASK [module-load : Persist modules via modules-load.d] ************************
ok: [localhost] => (item=openvswitch)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=openvswitch) 
skipping: [localhost]

TASK [openvswitch : Create /run/openvswitch directory on host] *****************
skipping: [localhost]

TASK [openvswitch : Ensuring config directories exist] *************************
changed: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [openvswitch : Copying over config.json files for services] ***************
ok: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [openvswitch : Copying over ovs-vsctl wrapper] ****************************
skipping: [localhost]

TASK [service-check-containers : openvswitch | Check containers] ***************
ok: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})

TASK [service-check-containers : openvswitch | Notify handlers to restart containers] ***
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [openvswitch : Flush Handlers] ********************************************

TASK [openvswitch : Set system-id, hostname and hw-offload] ********************
ok: [localhost] => (item={'col': 'external_ids', 'name': 'system-id', 'value': 'nics-VMware20-1'})
ok: [localhost] => (item={'col': 'external_ids', 'name': 'hostname', 'value': 'nics-VMware20-1'})
ok: [localhost] => (item={'col': 'other_config', 'name': 'hw-offload', 'value': True, 'state': 'absent'})

TASK [openvswitch : Ensuring OVS bridge is properly setup] *********************
ok: [localhost] => (item=br-ex)

TASK [openvswitch : Ensuring OVS ports are properly setup] *********************
ok: [localhost] => (item=['br-ex', 'veth1'])

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
included: nova for localhost

TASK [nova : Creating Nova databases] ******************************************
ok: [localhost] => (item=nova_cell0)
ok: [localhost] => (item=nova_api)

TASK [nova : Creating Nova databases user and setting permissions] *************
ok: [localhost] => (item=None)
ok: [localhost] => (item=None)
ok: [localhost]

TASK [nova : Ensuring config directories exist] ********************************
changed: [localhost]

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}}) 
skipping: [localhost]

TASK [nova : Copying over config.json files for nova-api-bootstrap] ************
ok: [localhost]

TASK [nova : Copying over nova.conf for nova-api-bootstrap] ********************
changed: [localhost]

TASK [nova : include_tasks] ****************************************************
skipping: [localhost]

TASK [nova : Running Nova API bootstrap container] *****************************
ok: [localhost]

TASK [nova : Create cell0 mappings] ********************************************
ok: [localhost]

TASK [nova-cell : Get a list of existing cells] ********************************
ok: [localhost]

TASK [nova-cell : Extract current cell settings from list] *********************
ok: [localhost]

TASK [nova : Update cell0 mappings] ********************************************
skipping: [localhost]

TASK [nova : include_tasks] ****************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
included: nova-cell for localhost

TASK [nova-cell : Creating Nova cell database] *********************************
ok: [localhost]

TASK [nova-cell : Creating Nova cell database user and setting permissions] ****
ok: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
skipping: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
ok: [localhost] => (item=None)
ok: [localhost -> {{ service_rabbitmq_delegate_host }}]

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
skipping: [localhost]

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
skipping: [localhost] => (item=None) 
skipping: [localhost]

TASK [nova-cell : Ensuring config directories exist] ***************************
changed: [localhost]

TASK [nova-cell : Copying over config.json files for nova-cell-bootstrap] ******
ok: [localhost]

TASK [nova-cell : Copying over nova.conf for nova-cell-bootstrap] **************
changed: [localhost]

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}}) 
skipping: [localhost]

TASK [nova-cell : Running Nova cell bootstrap container] ***********************
ok: [localhost]

TASK [nova-cell : Get a list of existing cells] ********************************
ok: [localhost]

TASK [nova-cell : Extract current cell settings from list] *********************
ok: [localhost]

TASK [nova-cell : Create cell] *************************************************
ok: [localhost]

TASK [nova-cell : Update cell] *************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/deploy.yml for localhost

TASK [service-ks-register : nova | Creating/deleting services] *****************
skipping: [localhost] => (item=nova_legacy (compute_legacy)) 
ok: [localhost] => (item=nova (compute))

TASK [service-ks-register : nova | Creating/deleting endpoints] ****************
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.201:8774/v2/%(tenant_id)s -> internal) 
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.201:8774/v2/%(tenant_id)s -> public) 
changed: [localhost] => (item=nova -> http://192.168.0.201:8774/v2.1 -> internal)
changed: [localhost] => (item=nova -> http://192.168.0.201:8774/v2.1 -> public)

TASK [service-ks-register : nova | Creating projects] **************************
ok: [localhost] => (item=service)

TASK [service-ks-register : nova | Creating/deleting users] ********************
changed: [localhost] => (item=nova -> service)

TASK [service-ks-register : nova | Creating roles] *****************************
ok: [localhost] => (item=admin)

TASK [service-ks-register : nova | Granting/revoking user roles] ***************
ok: [localhost] => (item=nova -> service -> admin)
ok: [localhost] => (item=nova -> service -> service)

TASK [nova : Ensuring config directories exist] ********************************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Check if policies shall be overwritten] ***************************
skipping: [localhost]

TASK [nova : Set nova policy file] *********************************************
skipping: [localhost]

TASK [nova : Check for vendordata file] ****************************************
ok: [localhost]

TASK [nova : Set vendordata file path] *****************************************
skipping: [localhost]

TASK [nova : include_tasks] ****************************************************
skipping: [localhost]

TASK [nova : Copying over config.json files for services] **********************
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
ok: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Copying over nova.conf] *******************************************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [nova : Copying over existing policy file] ********************************
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova : Copying over nova-api-wsgi.conf] **********************************
skipping: [localhost]

TASK [nova : Copying over nova-metadata-wsgi.conf] *****************************
skipping: [localhost]

TASK [nova : Copying over vendordata file for nova services] *******************
skipping: [localhost] => (item=nova-metadata) 
skipping: [localhost] => (item=nova-api) 
skipping: [localhost]

TASK [Configure uWSGI for Nova] ************************************************
included: service-uwsgi-config for localhost => (item={'name': 'nova-api', 'port': '8774'})
included: service-uwsgi-config for localhost => (item={'name': 'nova-metadata', 'port': '8775'})

TASK [service-uwsgi-config : Copying over nova-api uWSGI config] ***************
ok: [localhost]

TASK [service-uwsgi-config : Copying over nova-metadata uWSGI config] **********
ok: [localhost]

TASK [service-check-containers : nova | Check containers] **********************
changed: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})
changed: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})

TASK [service-check-containers : nova | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) 
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova : Flush handlers] ***************************************************

RUNNING HANDLER [nova : Restart nova-scheduler container] **********************
changed: [localhost]

RUNNING HANDLER [nova : Restart nova-api container] ****************************
changed: [localhost]

RUNNING HANDLER [nova : Restart nova-metadata container] ***********************
changed: [localhost]

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml for localhost

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Get new Libvirt version] *************************************
changed: [localhost]

TASK [nova-cell : Cache new Libvirt version] ***********************************
ok: [localhost]

TASK [Get nova_libvirt image info] *********************************************
included: service-image-info for localhost

TASK [service-image-info : community.docker.docker_image_info] *****************
ok: [localhost]

TASK [service-image-info : set_fact] *******************************************
ok: [localhost]

TASK [service-image-info : containers.podman.podman_image_info] ****************
skipping: [localhost]

TASK [service-image-info : set_fact] *******************************************
skipping: [localhost]

TASK [nova-cell : Get container facts] *****************************************
ok: [localhost] => (item=localhost)

TASK [nova-cell : Get current Libvirt version] *********************************
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [nova-cell : Check that the new Libvirt version is >= current] ************
skipping: [localhost] => (item={'result': False, 'changed': False, 'containers': {'nova_libvirt': {'Id': '46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e', 'Created': '2025-12-10T12:06:47.964413255Z', 'Path': 'dumb-init', 'Args': ['--single-child', '--', 'kolla_start'], 'State': {'Status': 'running', 'Running': True, 'Paused': False, 'Restarting': False, 'OOMKilled': False, 'Dead': False, 'Pid': 92321, 'ExitCode': 0, 'Error': '', 'StartedAt': '2025-12-10T12:06:49.032795938Z', 'FinishedAt': '0001-01-01T00:00:00Z', 'Health': {'Status': 'healthy', 'FailingStreak': 0}}, 'Image': 'sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a', 'ResolvConfPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/resolv.conf', 'HostnamePath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hostname', 'HostsPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hosts', 'LogPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e-json.log', 'Name': '/nova_libvirt', 'RestartCount': 0, 'Driver': 'overlay2', 'Platform': 'linux', 'MountLabel': '', 'ProcessLabel': '', 'AppArmorProfile': 'unconfined', 'ExecIDs': None, 'HostConfig': {'Binds': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev:rw', '/sys/fs/cgroup:/sys/fs/cgroup:rw', 'kolla_logs:/var/log/kolla/:rw', 'libvirtd:/var/lib/libvirt:rw', 'nova_compute:/var/lib/nova/:rw', 'nova_libvirt_qemu:/etc/libvirt/qemu:rw'], 'ContainerIDFile': '', 'LogConfig': {'Type': 'json-file', 'Config': {'max-file': '5', 'max-size': '50m'}}, 'NetworkMode': 'host', 'PortBindings': {}, 'RestartPolicy': {'Name': 'no', 'MaximumRetryCount': 0}, 'AutoRemove': False, 'VolumeDriver': '', 'VolumesFrom': None, 'ConsoleSize': [0, 0], 'CapAdd': None, 'CapDrop': None, 'CgroupnsMode': 'host', 'Dns': None, 'DnsOptions': None, 'DnsSearch': None, 'ExtraHosts': None, 'GroupAdd': None, 'IpcMode': 'private', 'Cgroup': '', 'Links': None, 'OomScoreAdj': 0, 'PidMode': 'host', 'Privileged': True, 'PublishAllPorts': False, 'ReadonlyRootfs': False, 'SecurityOpt': ['label=disable'], 'UTSMode': '', 'UsernsMode': '', 'ShmSize': 67108864, 'Runtime': 'runc', 'Isolation': '', 'CpuShares': 0, 'Memory': 0, 'NanoCpus': 0, 'CgroupParent': '', 'BlkioWeight': 0, 'BlkioWeightDevice': None, 'BlkioDeviceReadBps': None, 'BlkioDeviceWriteBps': None, 'BlkioDeviceReadIOps': None, 'BlkioDeviceWriteIOps': None, 'CpuPeriod': 0, 'CpuQuota': 0, 'CpuRealtimePeriod': 0, 'CpuRealtimeRuntime': 0, 'CpusetCpus': '', 'CpusetMems': '', 'Devices': None, 'DeviceCgroupRules': None, 'DeviceRequests': None, 'MemoryReservation': 0, 'MemorySwap': 0, 'MemorySwappiness': None, 'OomKillDisable': None, 'PidsLimit': None, 'Ulimits': [{'Name': 'memlock', 'Hard': 67108864, 'Soft': 67108864}], 'CpuCount': 0, 'CpuPercent': 0, 'IOMaximumIOps': 0, 'IOMaximumBandwidth': 0, 'MaskedPaths': None, 'ReadonlyPaths': None}, 'GraphDriver': {'Data': {'ID': '46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e', 'LowerDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc-init/diff:/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff:/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff', 'MergedDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/merged', 'UpperDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/diff', 'WorkDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/work'}, 'Name': 'overlay2'}, 'Mounts': [{'Type': 'bind', 'Source': '/etc/kolla/nova-libvirt', 'Destination': '/var/lib/kolla/config_files', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/etc/localtime', 'Destination': '/etc/localtime', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/etc/timezone', 'Destination': '/etc/timezone', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/dev', 'Destination': '/dev', 'Mode': 'rw', 'RW': True, 'Propagation': 'rprivate'}, {'Type': 'volume', 'Name': 'libvirtd', 'Source': '/var/lib/docker/volumes/libvirtd/_data', 'Destination': '/var/lib/libvirt', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'volume', 'Name': 'nova_compute', 'Source': '/var/lib/docker/volumes/nova_compute/_data', 'Destination': '/var/lib/nova', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'bind', 'Source': '/lib/modules', 'Destination': '/lib/modules', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/run', 'Destination': '/run', 'Mode': 'shared', 'RW': True, 'Propagation': 'shared'}, {'Type': 'bind', 'Source': '/sys/fs/cgroup', 'Destination': '/sys/fs/cgroup', 'Mode': 'rw', 'RW': True, 'Propagation': 'rprivate'}, {'Type': 'volume', 'Name': 'kolla_logs', 'Source': '/var/lib/docker/volumes/kolla_logs/_data', 'Destination': '/var/log/kolla', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'volume', 'Name': 'nova_libvirt_qemu', 'Source': '/var/lib/docker/volumes/nova_libvirt_qemu/_data', 'Destination': '/etc/libvirt/qemu', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}], 'Config': {'Hostname': 'nics-VMware20-1', 'Domainname': '', 'User': '', 'AttachStdin': False, 'AttachStdout': False, 'AttachStderr': False, 'Tty': False, 'OpenStdin': False, 'StdinOnce': False, 'Env': ['KOLLA_CONFIG_STRATEGY=COPY_ALWAYS', 'KOLLA_SERVICE_NAME=nova-libvirt', 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LANG=en_US.UTF-8', 'KOLLA_BASE_DISTRO=ubuntu', 'KOLLA_BASE_ARCH=x86_64', 'PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ', 'DEBIAN_FRONTEND=noninteractive', 'PIP_INDEX_URL=', 'PIP_TRUSTED_HOST=', 'PIP_EXTRA_INDEX_URL='], 'Cmd': ['kolla_start'], 'Healthcheck': {'Test': ['CMD-SHELL', 'virsh version --daemon'], 'Interval': 30000000000, 'Timeout': 30000000000, 'StartPeriod': 5000000000, 'Retries': 3}, 'Image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'Volumes': {'/dev': {}, '/etc/libvirt/qemu': {}, '/etc/localtime': {}, '/etc/timezone': {}, '/lib/modules': {}, '/run': {}, '/sys/fs/cgroup': {}, '/var/lib/kolla/config_files/': {}, '/var/lib/libvirt': {}, '/var/lib/nova/': {}, '/var/log/kolla/': {}}, 'WorkingDir': '', 'Entrypoint': ['dumb-init', '--single-child', '--'], 'Labels': {'build-date': '20251210', 'kolla_version': '21.1.0', 'maintainer': 'Kolla Project (https://launchpad.net/kolla)', 'name': 'nova-libvirt', 'org.opencontainers.image.ref.name': 'ubuntu', 'org.opencontainers.image.version': '24.04'}}, 'NetworkSettings': {'SandboxID': '8b09258d0c3762b1a641de2f52676f3d8d8d69295d507b9e758bb50a6519c934', 'SandboxKey': '/var/run/docker/netns/default', 'Ports': {}, 'Networks': {'host': {'IPAMConfig': None, 'Links': None, 'Aliases': None, 'DriverOpts': None, 'GwPriority': 0, 'NetworkID': '72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af', 'EndpointID': '06fe5587e1b667d8396bd7bfdfe3fb624b6420c8ae2909dcc177255b6ef96bb7', 'Gateway': '', 'IPAddress': '', 'MacAddress': '', 'IPPrefixLen': 0, 'IPv6Gateway': '', 'GlobalIPv6Address': '', 'GlobalIPv6PrefixLen': 0, 'DNSNames': None}}}}}, 'invocation': {'module_args': {'action': 'get_containers', 'container_engine': 'docker', 'name': ['nova_libvirt'], 'api_version': 'auto', 'args': {'get_all_containers': False}}}, 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}) 
skipping: [localhost]

TASK [Load and persist br_netfilter module] ************************************
included: module-load for localhost

TASK [module-load : Load modules] **********************************************
ok: [localhost] => (item=br_netfilter)

TASK [module-load : Persist modules via modules-load.d] ************************
ok: [localhost] => (item=br_netfilter)

TASK [module-load : Drop module persistence] ***********************************
skipping: [localhost] => (item=br_netfilter) 
skipping: [localhost]

TASK [nova-cell : Enable bridge-nf-call sysctl variables] **********************
ok: [localhost] => (item=net.bridge.bridge-nf-call-iptables)
ok: [localhost] => (item=net.bridge.bridge-nf-call-ip6tables)

TASK [nova-cell : Install udev kolla kvm rules] ********************************
skipping: [localhost]

TASK [nova-cell : Mask qemu-kvm service] ***************************************
skipping: [localhost]

TASK [nova-cell : Ensuring config directories exist] ***************************
changed: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Check if policies shall be overwritten] **********************
skipping: [localhost]

TASK [nova-cell : Set nova policy file] ****************************************
skipping: [localhost]

TASK [nova-cell : Check for vendordata file] ***********************************
ok: [localhost]

TASK [nova-cell : Set vendordata file path] ************************************
skipping: [localhost]

TASK [nova-cell : Copying over config.json files for services] *****************
ok: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : Copying over nova.conf] **************************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [nova-cell : Copying over Nova compute provider config] *******************
skipping: [localhost]

TASK [nova-cell : Copying over libvirt configuration] **************************
ok: [localhost] => (item={'src': 'qemu.conf.j2', 'dest': 'qemu.conf'})
ok: [localhost] => (item={'src': 'libvirtd.conf.j2', 'dest': 'libvirtd.conf'})

TASK [nova-cell : Copying over libvirt TLS keys] *******************************
skipping: [localhost]

TASK [nova-cell : Copying over libvirt SASL configuration] *********************
ok: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-compute'})
ok: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-libvirt'})
ok: [localhost] => (item={'src': 'sasl.conf.j2', 'dest': 'sasl.conf', 'service': 'nova-libvirt'})

TASK [nova-cell : Copying files for nova-ssh] **********************************
ok: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'})
ok: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'})
ok: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'})
ok: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'})

TASK [nova-cell : Copying 'release' file for nova_compute] *********************
skipping: [localhost]

TASK [nova-cell : Generating 'hostnqn' file for nova_compute] ******************
ok: [localhost]

TASK [nova-cell : Copying over existing policy file] ***************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova-cell : Copying over vendordata file to containers] ******************
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost]

TASK [service-check-containers : nova_cell | Check containers] *****************
ok: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})
ok: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})
changed: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})

TASK [service-check-containers : nova_cell | Notify handlers to restart containers] ***
changed: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) 
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) 
skipping: [localhost]

TASK [nova-cell : include_tasks] ***********************************************
skipping: [localhost]

TASK [nova-cell : Flush handlers] **********************************************

RUNNING HANDLER [nova-cell : Restart nova-conductor container] *****************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-novncproxy container] ****************
changed: [localhost]

RUNNING HANDLER [nova-cell : Restart nova-compute container] *******************
changed: [localhost]

RUNNING HANDLER [nova-cell : Wait for nova-compute services to update service versions] ***
skipping: [localhost]

TASK [nova-cell : Waiting for nova-compute services to register themselves] ****
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
fatal: [localhost]: FAILED! => {"msg": "Unexpected failure during module execution: Expecting value: line 1 column 1 (char 0)", "stdout": ""}

PLAY RECAP *********************************************************************
localhost                  : ok=303  changed=83   unreachable=0    failed=1    skipped=215  rescued=0    ignored=0   

[2025-12-10 13:59:01] === Iniciando despliegue de OpenStack con Kolla-Ansible ===
[2025-12-10 13:59:01] Activando entorno virtual: /home/nics/openstack_venv
[2025-12-10 13:59:01] Instalando dependencias Galaxy (kolla-ansible install-deps)
Your branch is up to date with 'origin/master'.
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Installing 'openstack.kolla:1.0.0' to '/home/nics/.ansible/collections/ansible_collections/openstack/kolla'
Created collection for openstack.kolla:1.0.0 at /home/nics/.ansible/collections/ansible_collections/openstack/kolla
openstack.kolla:1.0.0 was installed successfully
Starting galaxy collection install process
Process install dependency map
Starting collection install process
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-posix-2.1.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/ansible-posix-2.1.0-mjnajbte
Installing 'ansible.posix:2.1.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/posix'
ansible.posix:2.1.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-utils-6.0.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/ansible-utils-6.0.0-9pnrmn2u
Installing 'ansible.utils:6.0.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/utils'
ansible.utils:6.0.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/ansible-netcommon-8.2.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/ansible-netcommon-8.2.0-69_gfvtq
Installing 'ansible.netcommon:8.2.0' to '/home/nics/.ansible/collections/ansible_collections/ansible/netcommon'
ansible.netcommon:8.2.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/containers-podman-1.18.0.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/containers-podman-1.18.0-am1mi1ni
Installing 'containers.podman:1.18.0' to '/home/nics/.ansible/collections/ansible_collections/containers/podman'
containers.podman:1.18.0 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-crypto-3.0.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/community-crypto-3.0.5-y20pocy1
Installing 'community.crypto:3.0.5' to '/home/nics/.ansible/collections/ansible_collections/community/crypto'
community.crypto:3.0.5 was installed successfully
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-docker-4.8.5.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/community-docker-4.8.5-2mamtgmw
Installing 'community.docker:4.8.5' to '/home/nics/.ansible/collections/ansible_collections/community/docker'
community.docker:4.8.5 was installed successfully
'community.library_inventory_filtering_v1:1.1.1' is already installed, skipping.
Downloading https://galaxy.ansible.com/api/v3/plugin/ansible/content/published/collections/artifacts/community-general-11.4.2.tar.gz to /home/nics/.ansible/tmp/ansible-local-235041eset_xm_/tmp0sh00e5l/community-general-11.4.2-kvza_apu
Installing 'community.general:11.4.2' to '/home/nics/.ansible/collections/ansible_collections/community/general'
community.general:11.4.2 was installed successfully
[2025-12-10 13:59:30] Ejecutando bootstrap-servers

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Apply role baremetal] ****************************************************

TASK [openstack.kolla.etc_hosts : Include etc-hosts.yml] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/etc_hosts/tasks/etc-hosts.yml for localhost

TASK [openstack.kolla.etc_hosts : Ensure localhost in /etc/hosts] **************
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Ensure hostname does not point to 127.0.1.1 in /etc/hosts] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Generate /etc/hosts for all of the nodes] ****
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Check whether /etc/cloud/cloud.cfg exists] ***
ok: [localhost]

TASK [openstack.kolla.etc_hosts : Disable cloud-init manage_etc_hosts] *********
ok: [localhost]

TASK [openstack.kolla.baremetal : Ensure unprivileged users can use ping] ******
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set firewall default policy] *****************
ok: [localhost]

TASK [openstack.kolla.baremetal : Check if firewalld is installed] *************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Disable firewalld] ***************************
skipping: [localhost] => (item=firewalld) 
skipping: [localhost]

TASK [openstack.kolla.packages : Install packages] *****************************
ok: [localhost]

TASK [openstack.kolla.packages : Remove packages] ******************************
ok: [localhost]

TASK [openstack.kolla.docker : Install/Uninstall] ******************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/install.yml for localhost

TASK [openstack.kolla.docker : Enable Docker repository] ***********************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker/tasks/repo-Debian.yml for localhost

TASK [openstack.kolla.docker : Install CA certificates and gnupg packages] *****
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt sources list directory exists] *******
ok: [localhost]

TASK [openstack.kolla.docker : Ensure apt keyrings directory exists] ***********
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt gpg key] *********************
ok: [localhost]

TASK [openstack.kolla.docker : Install docker apt pin] *************************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure old docker repository absent] ************
ok: [localhost]

TASK [openstack.kolla.docker : Enable docker apt repository] *******************
ok: [localhost]

TASK [openstack.kolla.docker : Update the apt cache] ***************************
changed: [localhost]

TASK [openstack.kolla.docker : Check which containers are running] *************
ok: [localhost]

TASK [openstack.kolla.docker : Check if docker systemd unit exists] ************
ok: [localhost]

TASK [openstack.kolla.docker : Mask the docker systemd unit on Debian/Ubuntu] ***
changed: [localhost]

TASK [openstack.kolla.docker : Install packages] *******************************
ok: [localhost]

TASK [openstack.kolla.docker : Start docker] ***********************************
skipping: [localhost]

TASK [openstack.kolla.docker : Wait for Docker to start] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure containers are running after Docker upgrade] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure docker config directory exists] **********
ok: [localhost]

TASK [openstack.kolla.docker : Write docker config] ****************************
ok: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Get Docker API version] *************************
ok: [localhost]

TASK [openstack.kolla.docker : Parse Docker system info] ***********************
ok: [localhost]

TASK [openstack.kolla.docker : Determine if Docker uses containerd image store] ***
ok: [localhost]

TASK [openstack.kolla.docker : Copying over containerd config] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Remove old docker options file] *****************
ok: [localhost]

TASK [openstack.kolla.docker : Ensure docker service directory exists] *********
skipping: [localhost]

TASK [openstack.kolla.docker : Configure docker service] ***********************
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the path for CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Ensure the CA file for private registry exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker : Flush handlers] *********************************

TASK [openstack.kolla.docker : Start and enable docker] ************************
changed: [localhost]

TASK [openstack.kolla.docker : Configure containerd for Zun] *******************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Ensure groups are present] ******************
skipping: [localhost] => (item=docker) 
skipping: [localhost] => (item=sudo) 
skipping: [localhost] => (item=kolla) 
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Create kolla user] **************************
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Add public key to kolla user authorized keys] ***
skipping: [localhost]

TASK [openstack.kolla.kolla_user : Grant kolla user passwordless sudo] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Get Python] *********************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if Python environment is externally managed] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Set docker_sdk_python_externally_managed fact] ***
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Install/Uninstall] **************************
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/docker_sdk/tasks/install.yml for localhost

TASK [openstack.kolla.docker_sdk : Ensure apt sources list directory exists] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Ensure apt keyrings directory exists] *******
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install osbpo apt gpg key] ******************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Enable osbpo apt repository] ****************
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packages] ***************************
ok: [localhost]

TASK [openstack.kolla.docker_sdk : Check if virtualenv is a directory] *********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Check if packaging is already installed] ****
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install packaging into virtualenv] **********
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install latest pip and packaging in the virtualenv] ***
skipping: [localhost]

TASK [openstack.kolla.docker_sdk : Install docker SDK for python using pip] ****
skipping: [localhost]

TASK [openstack.kolla.baremetal : Ensure node_config_directory directory exists] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Include tasks from remove-profile.yml] ***
included: /home/nics/.ansible/collections/ansible_collections/openstack/kolla/roles/apparmor_libvirt/tasks/remove-profile.yml for localhost

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Get stat of libvirtd apparmor disable profile] ***
ok: [localhost]

TASK [openstack.kolla.apparmor_libvirt : Remove apparmor profile for libvirt] ***
skipping: [localhost]

TASK [openstack.kolla.baremetal : Change state of selinux] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set https proxy for git] *********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Set http proxy for git] **********************
skipping: [localhost]

TASK [openstack.kolla.baremetal : Copying over kolla.target] *******************
ok: [localhost]

TASK [openstack.kolla.baremetal : Configure ceph for zun] **********************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=42   changed=3    unreachable=0    failed=0    skipped=30   rescued=0    ignored=0   

[2025-12-10 14:00:04] Ejecutando prechecks

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
ok: [localhost]

TASK [Gather facts] ************************************************************
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
ok: [localhost]

TASK [Group hosts based on enabled services] ***********************************
ok: [localhost] => (item=enable_aodh_False)
ok: [localhost] => (item=enable_barbican_False)
ok: [localhost] => (item=enable_blazar_False)
ok: [localhost] => (item=enable_ceilometer_False)
ok: [localhost] => (item=enable_ceph_rgw_False)
ok: [localhost] => (item=enable_cinder_False)
ok: [localhost] => (item=enable_cloudkitty_False)
ok: [localhost] => (item=enable_collectd_False)
ok: [localhost] => (item=enable_cyborg_False)
ok: [localhost] => (item=enable_designate_False)
ok: [localhost] => (item=enable_etcd_False)
ok: [localhost] => (item=enable_fluentd_True)
ok: [localhost] => (item=enable_glance_True)
ok: [localhost] => (item=enable_gnocchi_False)
ok: [localhost] => (item=enable_grafana_False)
ok: [localhost] => (item=enable_hacluster_False)
ok: [localhost] => (item=enable_heat_True)
ok: [localhost] => (item=enable_horizon_True)
ok: [localhost] => (item=enable_influxdb_False)
ok: [localhost] => (item=enable_ironic_False)
ok: [localhost] => (item=enable_iscsid_False)
ok: [localhost] => (item=enable_keystone_True)
ok: [localhost] => (item=enable_kuryr_False)
ok: [localhost] => (item=enable_letsencrypt_False)
ok: [localhost] => (item=enable_loadbalancer_True)
ok: [localhost] => (item=enable_magnum_False)
ok: [localhost] => (item=enable_manila_False)
ok: [localhost] => (item=enable_mariadb_True)
ok: [localhost] => (item=enable_masakari_False)
ok: [localhost] => (item=enable_memcached_True)
ok: [localhost] => (item=enable_mistral_False)
ok: [localhost] => (item=enable_multipathd_False)
ok: [localhost] => (item=enable_neutron_True)
ok: [localhost] => (item=enable_nova_True)
ok: [localhost] => (item=enable_octavia_False)
ok: [localhost] => (item=enable_opensearch_False)
ok: [localhost] => (item=enable_opensearch_dashboards_False)
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False)
ok: [localhost] => (item=enable_ovn_False)
ok: [localhost] => (item=enable_placement_True)
ok: [localhost] => (item=enable_prometheus_False)
ok: [localhost] => (item=enable_rabbitmq_True)
ok: [localhost] => (item=enable_valkey_False)
ok: [localhost] => (item=enable_skyline_False)
ok: [localhost] => (item=enable_tacker_False)
ok: [localhost] => (item=enable_telegraf_False)
ok: [localhost] => (item=enable_trove_False)
ok: [localhost] => (item=enable_watcher_False)
ok: [localhost] => (item=enable_zun_False)

PLAY [Apply role prechecks] ****************************************************

TASK [prechecks : Checking loadbalancer group] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/host_os_checks.yml for localhost

TASK [prechecks : Checking host OS distribution] *******************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking host OS release or version] *************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking if CentOS is Stream] ********************************
skipping: [localhost]

TASK [prechecks : Fail if not running on CentOS Stream] ************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/localtime exist] *********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/localtime is absent] ****************************
skipping: [localhost]

TASK [prechecks : Ensure /etc/timezone exist] **********************************
ok: [localhost]

TASK [prechecks : Fail if /etc/timezone is absent] *****************************
skipping: [localhost]

TASK [prechecks : include_tasks] ***********************************************
skipping: [localhost]

TASK [prechecks : Checking if system uses systemd] *****************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking Docker version] *************************************
ok: [localhost]

TASK [prechecks : Checking empty passwords in passwords.yml. Run kolla-genpwd if this task fails] ***
ok: [localhost]

TASK [prechecks : Check if nscd is running] ************************************
ok: [localhost]

TASK [prechecks : Fail if nscd is running] *************************************
skipping: [localhost]

TASK [prechecks : Validate that internal and external vip address are different when TLS is enabled only on either the internal and external network] ***
skipping: [localhost]

TASK [prechecks : Validate that enable_ceph is disabled] ***********************
skipping: [localhost]

TASK [prechecks : Validate that enable_redis is disabled] **********************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Checking docker SDK version] *********************************
ok: [localhost]

TASK [prechecks : Checking dbus-python package] ********************************
ok: [localhost]

TASK [prechecks : Checking Ansible version] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [prechecks : Check if config_owner_user existed] **************************
ok: [localhost]

TASK [prechecks : Check if config_owner_group existed] *************************
ok: [localhost]

TASK [prechecks : Check if ansible user can do passwordless sudo] **************
ok: [localhost]

TASK [prechecks : Check if external mariadb hosts are reachable from the load balancer] ***
skipping: [localhost] => (item=localhost) 
skipping: [localhost]

TASK [prechecks : Check if external database address is reachable from all hosts] ***
skipping: [localhost]

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/precheck.yml for localhost

TASK [service-precheck : common | Validate inventory groups] *******************
skipping: [localhost] => (item=kolla-toolbox) 
skipping: [localhost]

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/precheck.yml for localhost

TASK [service-precheck : cron | Validate inventory groups] *********************
skipping: [localhost] => (item=cron) 
skipping: [localhost]

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/precheck.yml for localhost

TASK [service-precheck : fluentd | Validate inventory groups] ******************
skipping: [localhost] => (item=fluentd) 
skipping: [localhost]

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/precheck.yml for localhost

TASK [service-precheck : loadbalancer | Validate inventory groups] *************
skipping: [localhost] => (item=haproxy) 
skipping: [localhost] => (item=proxysql) 
skipping: [localhost] => (item=keepalived) 
skipping: [localhost] => (item=haproxy-ssh) 
skipping: [localhost]

TASK [loadbalancer : Get container facts] **************************************
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running keepalived] *******
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running HAProxy] **********
ok: [localhost]

TASK [loadbalancer : Group hosts by whether they are running ProxySQL] *********
ok: [localhost]

TASK [loadbalancer : Set facts about whether we can run HAProxy and keepalived VIP prechecks] ***
ok: [localhost]

TASK [loadbalancer : Checking if external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that external haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking if internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Assert that internal haproxy certificate exists] **********
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is present] *****
skipping: [localhost]

TASK [loadbalancer : Checking the kolla_external_vip_interface is active] ******
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address and kolla_external_vip_address are not pingable from any node] ***
skipping: [localhost] => (item=192.168.0.201) 
skipping: [localhost] => (item=192.168.0.201) 
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy stats] *********************
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (api interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for HAProxy monitor (vip interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (api interface)] ****
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL admin (vip interface)] ****
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (api interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking free port for ProxySQL prometheus exporter (vip interface)] ***
skipping: [localhost]

TASK [loadbalancer : Checking if kolla_internal_vip_address is in the same network as api_interface on all nodes] ***
skipping: [localhost]

TASK [loadbalancer : Getting haproxy stat] *************************************
ok: [localhost]

TASK [loadbalancer : Setting haproxy stat fact] ********************************
ok: [localhost]

TASK [loadbalancer : Checking free port for Aodh API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Barbican API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Blazar API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Ceph RadosGW HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cinder API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cloudkitty API HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Cyborg API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Designate API HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Glance API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Gnocchi API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Grafana server HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Heat API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Heat API CFN HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Horizon HAProxy] *******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Ironic API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Keystone Internal HAProxy] *********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Keystone Public HAProxy] ***********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Magnum API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Manila API HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for MariaDB HAProxy/ProxySQL] **********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Masakari API HAProxy] **************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Mistral API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Neutron Server HAProxy] ************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova API HAProxy] ******************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Metadata HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova NoVNC HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Serial Proxy HAProxy] *********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Spice HTML5 HAProxy] **********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Nova Placement API HAProxy] ********
skipping: [localhost]

TASK [loadbalancer : Checking free port for Octavia API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch HAProxy] ****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for OpenSearch Dashboards HAProxy] *****
skipping: [localhost]

TASK [loadbalancer : Checking free port for RabbitMQ Management HAProxy] *******
skipping: [localhost]

TASK [loadbalancer : Checking free port for Tacker Server HAProxy] *************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Trove API HAProxy] *****************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Watcher API HAProxy] ***************
skipping: [localhost]

TASK [loadbalancer : Checking free port for Zun API HAProxy] *******************
skipping: [localhost]

TASK [loadbalancer : Check if firewalld is running] ****************************
skipping: [localhost]

TASK [loadbalancer : Fail if firewalld is not running] *************************
skipping: [localhost]

TASK [include_role : aodh] *****************************************************
skipping: [localhost]

TASK [include_role : barbican] *************************************************
skipping: [localhost]

TASK [include_role : blazar] ***************************************************
skipping: [localhost]

TASK [include_role : ceph-rgw] *************************************************
skipping: [localhost]

TASK [include_role : cinder] ***************************************************
skipping: [localhost]

TASK [include_role : cloudkitty] ***********************************************
skipping: [localhost]

TASK [include_role : cyborg] ***************************************************
skipping: [localhost]

TASK [include_role : designate] ************************************************
skipping: [localhost]

TASK [include_role : etcd] *****************************************************
skipping: [localhost]

TASK [include_role : glance] ***************************************************
skipping: [localhost]

TASK [include_role : gnocchi] **************************************************
skipping: [localhost]

TASK [include_role : grafana] **************************************************
skipping: [localhost]

TASK [include_role : heat] *****************************************************
skipping: [localhost]

TASK [include_role : horizon] **************************************************
skipping: [localhost]

TASK [include_role : influxdb] *************************************************
skipping: [localhost]

TASK [include_role : ironic] ***************************************************
skipping: [localhost]

TASK [include_role : keystone] *************************************************
skipping: [localhost]

TASK [include_role : letsencrypt] **********************************************
skipping: [localhost]

TASK [include_role : magnum] ***************************************************
skipping: [localhost]

TASK [include_role : manila] ***************************************************
skipping: [localhost]

TASK [include_role : mariadb] **************************************************
skipping: [localhost]

TASK [include_role : masakari] *************************************************
skipping: [localhost]

TASK [include_role : memcached] ************************************************
skipping: [localhost]

TASK [include_role : mistral] **************************************************
skipping: [localhost]

TASK [include_role : neutron] **************************************************
skipping: [localhost]

TASK [include_role : placement] ************************************************
skipping: [localhost]

TASK [include_role : nova] *****************************************************
skipping: [localhost]

TASK [include_role : nova-cell] ************************************************
skipping: [localhost]

TASK [include_role : octavia] **************************************************
skipping: [localhost]

TASK [include_role : opensearch] ***********************************************
skipping: [localhost]

TASK [include_role : prometheus] ***********************************************
skipping: [localhost]

TASK [include_role : rabbitmq] *************************************************
skipping: [localhost]

TASK [include_role : skyline] **************************************************
skipping: [localhost]

TASK [include_role : tacker] ***************************************************
skipping: [localhost]

TASK [include_role : trove] ****************************************************
skipping: [localhost]

TASK [include_role : watcher] **************************************************
skipping: [localhost]

TASK [include_role : zun] ******************************************************
skipping: [localhost]

TASK [include_role : loadbalancer] *********************************************
skipping: [localhost]

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
ok: [localhost] => (item=localhost)

TASK [mariadb : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/precheck.yml for localhost

TASK [service-precheck : mariadb | Validate inventory groups] ******************
skipping: [localhost] => (item=mariadb) 
skipping: [localhost]

TASK [mariadb : Get container facts] *******************************************
ok: [localhost]

TASK [mariadb : Checking free port for MariaDB] ********************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB WSREP] **************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB IST] ****************************
skipping: [localhost]

TASK [mariadb : Checking free port for MariaDB SST] ****************************
skipping: [localhost]

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************
skipping: no hosts matched

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
skipping: [localhost]

TASK [Include mariadb post-upgrade.yml] ****************************************
skipping: [localhost]

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/precheck.yml for localhost

TASK [service-precheck : memcached | Validate inventory groups] ****************
skipping: [localhost] => (item=memcached) 
skipping: [localhost]

TASK [memcached : Get container facts] *****************************************
ok: [localhost]

TASK [memcached : Checking free port for Memcached] ****************************
skipping: [localhost]

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/precheck.yml for localhost

TASK [service-precheck : rabbitmq | Validate inventory groups] *****************
skipping: [localhost] => (item=rabbitmq) 
skipping: [localhost]

TASK [rabbitmq : Get container facts] ******************************************
ok: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ] ******************************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Management] *******************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ Cluster] **********************
skipping: [localhost]

TASK [rabbitmq : Checking free port for RabbitMQ EPMD] *************************
skipping: [localhost]

TASK [rabbitmq : Check if all rabbit hostnames are resolvable] *****************
ok: [localhost] => (item=localhost)

TASK [rabbitmq : Check if each rabbit hostname resolves uniquely to the proper IP address] ***
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 14:00:29.380009', 'end': '2025-12-10 14:00:29.386420', 'delta': '0:00:00.006411', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   STREAM nics-VMware20-1']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 14:00:29.380009', 'end': '2025-12-10 14:00:29.386420', 'delta': '0:00:00.006411', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   DGRAM  ']) 
skipping: [localhost] => (item=[{'changed': False, 'stdout': '192.168.0.195   STREAM nics-VMware20-1\n192.168.0.195   DGRAM  \n192.168.0.195   RAW    ', 'stderr': '', 'rc': 0, 'cmd': ['getent', 'ahostsv4', 'nics-VMware20-1'], 'start': '2025-12-10 14:00:29.380009', 'end': '2025-12-10 14:00:29.386420', 'delta': '0:00:00.006411', 'msg': '', 'invocation': {'module_args': {'_raw_params': 'getent ahostsv4 nics-VMware20-1', '_uses_shell': False, 'expand_argument_vars': True, 'stdin_add_newline': True, 'strip_empty_ends': True, 'argv': None, 'chdir': None, 'executable': None, 'creates': None, 'removes': None, 'stdin': None}}, 'stderr_lines': [], 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'}, '192.168.0.195   RAW    ']) 
skipping: [localhost]

TASK [rabbitmq : Check if TLS certificate exists for RabbitMQ] *****************
skipping: [localhost]

TASK [rabbitmq : Check if TLS key exists for RabbitMQ] *************************
skipping: [localhost]

TASK [rabbitmq : List RabbitMQ queues] *****************************************
ok: [localhost]

TASK [rabbitmq : Check if RabbitMQ quorum queues need to be configured] ********
ok: [localhost] => (item=conductor.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=compute_fanout) 
skipping: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) 
skipping: [localhost] => (item=scheduler_fanout) 
ok: [localhost] => (item=conductor) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=scheduler.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=conductor_fanout) 
ok: [localhost] => (item=compute) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=compute.nics-VMware20-1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute.nics-VMware20-1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
ok: [localhost] => (item=scheduler) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}

TASK [rabbitmq : Check if RabbitMQ quorum queues for transient queues need to be configured] ***
skipping: [localhost] => (item=conductor.nics-VMware20-1) 
skipping: [localhost] => (item=compute_fanout) 
ok: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "reply_nics-VMware20-1:nova-compute:1",
        "type": "quorum"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=scheduler_fanout) 
skipping: [localhost] => (item=conductor) 
skipping: [localhost] => (item=scheduler.nics-VMware20-1) 
skipping: [localhost] => (item=conductor_fanout) 
skipping: [localhost] => (item=compute) 
skipping: [localhost] => (item=compute.nics-VMware20-1) 
skipping: [localhost] => (item=scheduler) 

TASK [rabbitmq : Check if RabbitMQ streams need to be configured] **************
skipping: [localhost] => (item=conductor.nics-VMware20-1) 
ok: [localhost] => (item=compute_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "compute_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=reply_nics-VMware20-1:nova-compute:1) 
ok: [localhost] => (item=scheduler_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "scheduler_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=conductor) 
skipping: [localhost] => (item=scheduler.nics-VMware20-1) 
ok: [localhost] => (item=conductor_fanout) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "name": "conductor_fanout",
        "type": "stream"
    },
    "msg": "All assertions passed"
}
skipping: [localhost] => (item=compute) 
skipping: [localhost] => (item=compute.nics-VMware20-1) 
skipping: [localhost] => (item=scheduler) 

PLAY [Restart rabbitmq services] ***********************************************
skipping: no hosts matched

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
skipping: [localhost]

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/precheck.yml for localhost

TASK [service-precheck : keystone | Validate inventory groups] *****************
skipping: [localhost] => (item=keystone) 
skipping: [localhost] => (item=keystone-fernet) 
skipping: [localhost] => (item=keystone-httpd) 
skipping: [localhost] => (item=keystone-ssh) 
skipping: [localhost]

TASK [keystone : Get container facts] ******************************************
ok: [localhost]

TASK [keystone : Checking free port for Keystone Public] ***********************
skipping: [localhost]

TASK [keystone : Checking free port for Keystone SSH] **************************
skipping: [localhost]

TASK [keystone : Checking fernet_token_expiry] *********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/precheck.yml for localhost

TASK [service-precheck : glance | Validate inventory groups] *******************
skipping: [localhost] => (item=glance-api) 
skipping: [localhost] => (item=glance-tls-proxy) 
skipping: [localhost]

TASK [glance : Get container facts] ********************************************
ok: [localhost]

TASK [glance : Checking free port for Glance API] ******************************
skipping: [localhost]

TASK [glance : Check if S3 configurations are defined] *************************
skipping: [localhost] => (item=glance_backend_s3_url) 
skipping: [localhost] => (item=glance_backend_s3_bucket) 
skipping: [localhost] => (item=glance_backend_s3_access_key) 
skipping: [localhost] => (item=glance_backend_s3_secret_key) 
skipping: [localhost]

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/precheck.yml for localhost

TASK [service-precheck : placement | Validate inventory groups] ****************
skipping: [localhost] => (item=placement-api) 
skipping: [localhost]

TASK [placement : Get container facts] *****************************************
ok: [localhost]

TASK [placement : Checking free port for Placement API] ************************
skipping: [localhost]

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/precheck.yml for localhost

TASK [service-precheck : openvswitch | Validate inventory groups] **************
skipping: [localhost] => (item=openvswitch-db-server) 
skipping: [localhost] => (item=openvswitch-vswitchd) 
skipping: [localhost]

TASK [openvswitch : Get container facts] ***************************************
ok: [localhost]

TASK [openvswitch : Checking free port for OVSDB] ******************************
skipping: [localhost]

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
skipping: [localhost]

TASK [Bootstrap upgrade] *******************************************************
skipping: [localhost]

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-api) 
skipping: [localhost] => (item=nova-metadata) 
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-super-conductor) 
skipping: [localhost]

TASK [nova : Get container facts] **********************************************
ok: [localhost]

TASK [nova : Checking free port for Nova API] **********************************
skipping: [localhost]

TASK [nova : Checking free port for Nova Metadata] *****************************
skipping: [localhost]

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/precheck.yml for localhost

TASK [service-precheck : nova | Validate inventory groups] *********************
skipping: [localhost] => (item=nova-libvirt) 
skipping: [localhost] => (item=nova-ssh) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost]

TASK [nova-cell : Get container facts] *****************************************
ok: [localhost]

TASK [nova-cell : Checking available compute nodes in inventory] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova NoVNC Proxy] *********************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Serial Proxy] ********************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Spice HTML5 Proxy] ***************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (API interface)] *************
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova SSH (migration interface)] *******
skipping: [localhost]

TASK [nova-cell : Checking free port for Nova Libvirt] *************************
skipping: [localhost]

TASK [nova-cell : Checking that host libvirt is not running] *******************
skipping: [localhost]

TASK [nova-cell : Checking that nova_libvirt container is not running] *********
skipping: [localhost]

PLAY [Refresh nova scheduler cell cache] ***************************************

TASK [nova : Refresh cell cache in nova scheduler] *****************************
skipping: [localhost]

PLAY [Reload global Nova super conductor services] *****************************

TASK [nova : Reload nova super conductor services to remove RPC version pin] ***
skipping: [localhost]

PLAY [Reload Nova cell services] ***********************************************

TASK [nova-cell : Reload nova cell services to remove RPC version cap] *********
skipping: [localhost] => (item=nova-conductor) 
skipping: [localhost] => (item=nova-compute) 
skipping: [localhost] => (item=nova-compute-ironic) 
skipping: [localhost] => (item=nova-novncproxy) 
skipping: [localhost] => (item=nova-serialproxy) 
skipping: [localhost] => (item=nova-spicehtml5proxy) 
skipping: [localhost]

PLAY [Reload global Nova API services] *****************************************

TASK [nova : Reload nova API services to remove RPC version pin] ***************
skipping: [localhost] => (item=nova-scheduler) 
skipping: [localhost] => (item=nova-api) 
skipping: [localhost]

PLAY [Run Nova API online data migrations] *************************************

TASK [nova : Run Nova API online database migrations] **************************
skipping: [localhost]

PLAY [Run Nova cell online data migrations] ************************************

TASK [nova-cell : Run Nova cell online database migrations] ********************
skipping: [localhost]

PLAY [Apply role neutron] ******************************************************

TASK [neutron : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/neutron/tasks/precheck.yml for localhost

TASK [service-precheck : neutron | Validate inventory groups] ******************
skipping: [localhost] => (item=neutron-server) 
skipping: [localhost] => (item=neutron-rpc-server) 
skipping: [localhost] => (item=neutron-periodic-worker) 
skipping: [localhost] => (item=neutron-ovn-maintenance-worker) 
skipping: [localhost] => (item=neutron-openvswitch-agent) 
skipping: [localhost] => (item=neutron-dhcp-agent) 
skipping: [localhost] => (item=neutron-l3-agent) 
skipping: [localhost] => (item=neutron-sriov-agent) 
skipping: [localhost] => (item=neutron-mlnx-agent) 
skipping: [localhost] => (item=neutron-eswitchd) 
skipping: [localhost] => (item=neutron-metadata-agent) 
skipping: [localhost] => (item=neutron-ovn-metadata-agent) 
skipping: [localhost] => (item=neutron-bgp-dragent) 
skipping: [localhost] => (item=neutron-infoblox-ipam-agent) 
skipping: [localhost] => (item=neutron-metering-agent) 
skipping: [localhost] => (item=ironic-neutron-agent) 
skipping: [localhost] => (item=neutron-ovn-agent) 
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Checking free port for Neutron Server] *************************
ok: [localhost]

TASK [neutron : Checking number of network agents] *****************************
skipping: [localhost]

TASK [neutron : Checking tenant network types] *********************************
ok: [localhost] => (item=vxlan) => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": "vxlan",
    "msg": "All assertions passed"
}

TASK [neutron : Checking whether Ironic enabled] *******************************
skipping: [localhost]

TASK [neutron : Checking if neutron's dns domain has proper value] *************
skipping: [localhost]

TASK [neutron : Get container facts] *******************************************
ok: [localhost]

TASK [neutron : Get container volume facts] ************************************
ok: [localhost]

TASK [neutron : Check for ML2/OVN presence] ************************************
skipping: [localhost]

TASK [neutron : Check for ML2/OVS presence] ************************************
skipping: [localhost]

PLAY [Apply role kuryr] ********************************************************
skipping: no hosts matched

PLAY [Apply role hacluster] ****************************************************
skipping: no hosts matched

PLAY [Apply role heat] *********************************************************

TASK [heat : include_tasks] ****************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/heat/tasks/precheck.yml for localhost

TASK [service-precheck : heat | Validate inventory groups] *********************
skipping: [localhost] => (item=heat-api) 
skipping: [localhost] => (item=heat-api-cfn) 
skipping: [localhost] => (item=heat-engine) 
skipping: [localhost]

TASK [heat : Get container facts] **********************************************
ok: [localhost]

TASK [heat : Checking free port for Heat API] **********************************
ok: [localhost]

TASK [heat : Checking free port for Heat API CFN] ******************************
ok: [localhost]

PLAY [Apply role horizon] ******************************************************

TASK [horizon : include_tasks] *************************************************
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/horizon/tasks/precheck.yml for localhost

TASK [service-precheck : horizon | Validate inventory groups] ******************
skipping: [localhost] => (item=horizon) 
skipping: [localhost]

TASK [horizon : Get container facts] *******************************************
ok: [localhost]

TASK [horizon : Checking free port for Horizon] ********************************
ok: [localhost]

PLAY [Apply role magnum] *******************************************************
skipping: no hosts matched

PLAY [Apply role mistral] ******************************************************
skipping: no hosts matched

PLAY [Apply role manila] *******************************************************
skipping: no hosts matched

PLAY [Apply role gnocchi] ******************************************************
skipping: no hosts matched

PLAY [Apply role ceilometer] ***************************************************
skipping: no hosts matched

PLAY [Apply role aodh] *********************************************************
skipping: no hosts matched

PLAY [Apply role barbican] *****************************************************
skipping: no hosts matched

PLAY [Apply role cyborg] *******************************************************
skipping: no hosts matched

PLAY [Apply role designate] ****************************************************
skipping: no hosts matched

PLAY [Apply role trove] ********************************************************
skipping: no hosts matched

PLAY [Apply role watcher] ******************************************************
skipping: no hosts matched

PLAY [Apply role grafana] ******************************************************
skipping: no hosts matched

PLAY [Apply role cloudkitty] ***************************************************
skipping: no hosts matched

PLAY [Apply role tacker] *******************************************************
skipping: no hosts matched

PLAY [Apply role octavia] ******************************************************
skipping: no hosts matched

PLAY [Apply role zun] **********************************************************
skipping: no hosts matched

PLAY [Apply role blazar] *******************************************************
skipping: no hosts matched

PLAY [Apply role masakari] *****************************************************
skipping: no hosts matched

PLAY [Apply role skyline] ******************************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
localhost                  : ok=70   changed=0    unreachable=0    failed=0    skipped=166  rescued=0    ignored=0   

[2025-12-10 14:00:54] Ejecutando deploy con logs detallados (-vvv)
ansible-playbook [core 2.18.5]
  config file = None
  configured module search path = ['/home/nics/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/nics/openstack_venv/lib/python3.12/site-packages/ansible
  ansible collection location = /home/nics/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/nics/openstack_venv/bin/ansible-playbook
  python version = 3.12.3 (main, Nov  6 2025, 13:44:16) [GCC 13.3.0] (/home/nics/openstack_venv/bin/python)
  jinja version = 3.1.6
  libyaml = True
No config file found; using defaults
host_list declined parsing /etc/kolla/ansible/inventory/all-in-one as it did not pass its verify_file() method
script declined parsing /etc/kolla/ansible/inventory/all-in-one as it did not pass its verify_file() method
auto declined parsing /etc/kolla/ansible/inventory/all-in-one as it did not pass its verify_file() method
Parsed /etc/kolla/ansible/inventory/all-in-one inventory source with ini plugin
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/inventory_checks.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/datetime_checks.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/service_checks.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/package_checks.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/user_checks.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/prechecks/tasks/database_checks.yml
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: site.yml *************************************************************
72 plays in /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml

PLAY [Gather facts for all hosts] **********************************************

TASK [Group hosts to determine when using --limit] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/gather-facts.yml:14
ok: [localhost] => {
    "add_group": "all_using_limit_False",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [Gather facts] ************************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/gather-facts.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327 `" && echo ansible-tmp-1765371657.041704-242279-186884083392327="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327 `" ) && sleep 0'
<localhost> Attempting python interpreter discovery
<localhost> EXEC /bin/sh -c 'echo PLATFORM; uname; echo FOUND; command -v '"'"'python3.13'"'"'; command -v '"'"'python3.12'"'"'; command -v '"'"'python3.11'"'"'; command -v '"'"'python3.10'"'"'; command -v '"'"'python3.9'"'"'; command -v '"'"'python3.8'"'"'; command -v '"'"'/usr/bin/python3'"'"'; command -v '"'"'python3'"'"'; echo ENDFOUND && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 && sleep 0'
<localhost> Python interpreter discovery fallback (unsupported Linux distribution: ubuntu)
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/setup.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfbkisxi0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327/AnsiballZ_setup.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327/ /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371657.041704-242279-186884083392327/ > /dev/null 2>&1 && sleep 0'
ok: [localhost]

PLAY [Gather facts for all hosts (if using --limit)] ***************************
skipping: no hosts matched

PLAY [Group hosts based on configuration] **************************************

TASK [Group hosts based on Kolla action] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:16
ok: [localhost] => {
    "add_group": "kolla_action_deploy",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [Group hosts based on enabled services] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:21
ok: [localhost] => (item=enable_aodh_False) => {
    "add_group": "enable_aodh_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_aodh_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_barbican_False) => {
    "add_group": "enable_barbican_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_barbican_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_blazar_False) => {
    "add_group": "enable_blazar_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_blazar_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_ceilometer_False) => {
    "add_group": "enable_ceilometer_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_ceilometer_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_ceph_rgw_False) => {
    "add_group": "enable_ceph_rgw_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_ceph_rgw_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_cinder_False) => {
    "add_group": "enable_cinder_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_cinder_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_cloudkitty_False) => {
    "add_group": "enable_cloudkitty_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_cloudkitty_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_collectd_False) => {
    "add_group": "enable_collectd_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_collectd_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_cyborg_False) => {
    "add_group": "enable_cyborg_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_cyborg_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_designate_False) => {
    "add_group": "enable_designate_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_designate_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_etcd_False) => {
    "add_group": "enable_etcd_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_etcd_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_fluentd_True) => {
    "add_group": "enable_fluentd_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_fluentd_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_glance_True) => {
    "add_group": "enable_glance_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_glance_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_gnocchi_False) => {
    "add_group": "enable_gnocchi_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_gnocchi_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_grafana_False) => {
    "add_group": "enable_grafana_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_grafana_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_hacluster_False) => {
    "add_group": "enable_hacluster_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_hacluster_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_heat_True) => {
    "add_group": "enable_heat_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_heat_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_horizon_True) => {
    "add_group": "enable_horizon_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_horizon_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_influxdb_False) => {
    "add_group": "enable_influxdb_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_influxdb_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_ironic_False) => {
    "add_group": "enable_ironic_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_ironic_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_iscsid_False) => {
    "add_group": "enable_iscsid_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_iscsid_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_keystone_True) => {
    "add_group": "enable_keystone_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_keystone_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_kuryr_False) => {
    "add_group": "enable_kuryr_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_kuryr_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_letsencrypt_False) => {
    "add_group": "enable_letsencrypt_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_letsencrypt_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_loadbalancer_True) => {
    "add_group": "enable_loadbalancer_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_loadbalancer_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_magnum_False) => {
    "add_group": "enable_magnum_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_magnum_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_manila_False) => {
    "add_group": "enable_manila_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_manila_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_mariadb_True) => {
    "add_group": "enable_mariadb_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_mariadb_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_masakari_False) => {
    "add_group": "enable_masakari_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_masakari_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_memcached_True) => {
    "add_group": "enable_memcached_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_memcached_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_mistral_False) => {
    "add_group": "enable_mistral_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_mistral_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_multipathd_False) => {
    "add_group": "enable_multipathd_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_multipathd_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_neutron_True) => {
    "add_group": "enable_neutron_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_neutron_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_nova_True) => {
    "add_group": "enable_nova_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_nova_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_octavia_False) => {
    "add_group": "enable_octavia_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_octavia_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_opensearch_False) => {
    "add_group": "enable_opensearch_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_opensearch_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_opensearch_dashboards_False) => {
    "add_group": "enable_opensearch_dashboards_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_opensearch_dashboards_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_openvswitch_True_enable_ovs_dpdk_False) => {
    "add_group": "enable_openvswitch_True_enable_ovs_dpdk_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_openvswitch_True_enable_ovs_dpdk_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_ovn_False) => {
    "add_group": "enable_ovn_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_ovn_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_placement_True) => {
    "add_group": "enable_placement_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_placement_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_prometheus_False) => {
    "add_group": "enable_prometheus_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_prometheus_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_rabbitmq_True) => {
    "add_group": "enable_rabbitmq_True",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_rabbitmq_True",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_valkey_False) => {
    "add_group": "enable_valkey_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_valkey_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_skyline_False) => {
    "add_group": "enable_skyline_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_skyline_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_tacker_False) => {
    "add_group": "enable_tacker_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_tacker_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_telegraf_False) => {
    "add_group": "enable_telegraf_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_telegraf_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_trove_False) => {
    "add_group": "enable_trove_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_trove_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_watcher_False) => {
    "add_group": "enable_watcher_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_watcher_False",
    "parent_groups": [
        "all"
    ]
}
ok: [localhost] => (item=enable_zun_False) => {
    "add_group": "enable_zun_False",
    "ansible_loop_var": "item",
    "changed": false,
    "item": "enable_zun_False",
    "parent_groups": [
        "all"
    ]
}

PLAY [Apply role prechecks] ****************************************************
skipping: no hosts matched

PLAY [Apply role common] *******************************************************

TASK [common : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/bootstrap.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/deploy.yml for localhost

TASK [common : Ensuring config directories exist] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993 `" && echo ansible-tmp-1765371659.2948112-242462-245418287394993="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmplh18cuey TO /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993/ /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-edqdbylzukhcmvxtknelqqjhoatxgoha ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371659.2948112-242462-245418287394993/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=[{'service_name': 'kolla-toolbox'}, 'kolla-toolbox']) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/kolla-toolbox"
        },
        "before": {
            "path": "/etc/kolla/kolla-toolbox"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/kolla-toolbox",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": [
        {
            "service_name": "kolla-toolbox"
        },
        "kolla-toolbox"
    ],
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/kolla-toolbox",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [common : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:20
skipping: [localhost] => {
    "changed": false,
    "false_condition": "common_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [common : Copying over config.json files for services] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:24
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675 `" && echo ansible-tmp-1765371659.93144-242492-227360384460675="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptr61fpy2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/ /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-eiedhruuwqfkdppnmujfbnkyjwdwjtbc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfzimh0nd TO /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/ /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qbxftmxpvowgomuulfbkkkltvrabtvqw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371659.93144-242492-227360384460675/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "0eb2d0b34a8fcd8ca5b081148e52cd37fb50cb88",
    "dest": "/etc/kolla/kolla-toolbox/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/kolla-toolbox/config.json"
        },
        "before": {
            "path": "/etc/kolla/kolla-toolbox/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "kolla-toolbox.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/kolla-toolbox/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/kolla-toolbox/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "kolla-toolbox",
        "value": {
            "container_name": "kolla_toolbox",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ANSIBLE_LIBRARY": "/usr/share/ansible",
                "ANSIBLE_NOCOLOR": "1",
                "REQUESTS_CA_BUNDLE": ""
            },
            "group": "kolla-toolbox",
            "image": "quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/dev/:/dev/",
                "/run/:/run/:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/kolla-toolbox/config.json",
    "size": 838,
    "state": "file",
    "uid": 1000
}

TASK [common : Ensure RabbitMQ Erlang cookie exists] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:32
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688 `" && echo ansible-tmp-1765371660.780086-242587-46572057553688="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpg60n2hux TO /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/ /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-roojdhynftfrgssgcodxwptibkigwdir ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpky2p_71r TO /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/ /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wlkczlomzpxfguptmchegnlzxsbvksmy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371660.780086-242587-46572057553688/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "d8b4d37b73193e74be2fedfa9b8f215599cf4353",
    "dest": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie",
    "diff": {
        "after": {
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie"
        },
        "before": {
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rabbitmq-erlang.cookie.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/kolla-toolbox/rabbitmq-erlang.cookie",
    "size": 41,
    "state": "file",
    "uid": 1000
}

TASK [common : Ensuring config directories have correct owner and permission] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:42
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key != \"kolla-toolbox\"",
    "item": {
        "key": "kolla-toolbox",
        "value": {
            "container_name": "kolla_toolbox",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ANSIBLE_LIBRARY": "/usr/share/ansible",
                "ANSIBLE_NOCOLOR": "1",
                "REQUESTS_CA_BUNDLE": ""
            },
            "group": "kolla-toolbox",
            "image": "quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/dev/:/dev/",
                "/run/:/run/:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [common : Copy rabbitmq-env.conf to kolla toolbox] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:54
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174 `" && echo ansible-tmp-1765371661.571034-242644-238105281624174="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp890ys94t TO /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/ /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xnfxpbxwutusudxnwcsahotwaggpmows ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp718q0irh TO /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/ /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jmwqjnnzpqswtolbtnklulwuimpjjvdp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371661.571034-242644-238105281624174/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/rabbitmq-env.conf.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "e55b277931400f40de0cdba9248de82387573be4",
    "dest": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf"
        },
        "before": {
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rabbitmq-env.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0600",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/rabbitmq-env.conf.j2",
    "mode": "0600",
    "owner": "nics",
    "path": "/etc/kolla/kolla-toolbox/rabbitmq-env.conf",
    "size": 68,
    "state": "file",
    "uid": 1000
}

TASK [common : Copy rabbitmq erl_inetrc to kolla toolbox] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/config.yml:68
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600 `" && echo ansible-tmp-1765371662.3324904-242697-198008630770600="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmps4tvl7a_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/ /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xexrwveylxjlhpsqjhwfddamcslcuitd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7rcn2n5c TO /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/ /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ubewanhgqpwyusvbkfxxdgjgclparkix ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371662.3324904-242697-198008630770600/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/erl_inetrc.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "adc83b19e793491b1c6ea0fd8b46cd9f32e592fc",
    "dest": "/etc/kolla/kolla-toolbox/erl_inetrc",
    "diff": {
        "after": {
            "path": "/etc/kolla/kolla-toolbox/erl_inetrc"
        },
        "before": {
            "path": "/etc/kolla/kolla-toolbox/erl_inetrc"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "erl_inetrc.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/kolla-toolbox/erl_inetrc",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0600",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/kolla-toolbox/erl_inetrc",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/templates/erl_inetrc.j2",
    "mode": "0600",
    "owner": "nics",
    "path": "/etc/kolla/kolla-toolbox/erl_inetrc",
    "size": 1,
    "state": "file",
    "uid": 1000
}

TASK [service-check-containers : common | Check containers] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605 `" && echo ansible-tmp-1765371663.1210155-242748-216458249791605="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpaeswpn18 TO /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605/ /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-npzxsalemzjasutinrpimwkjcnjrzhwu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371663.1210155-242748-216458249791605/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "ANSIBLE_LIBRARY": "/usr/share/ansible",
                "ANSIBLE_NOCOLOR": "1",
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "REQUESTS_CA_BUNDLE": ""
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble",
            "labels": {},
            "name": "kolla_toolbox",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/dev/:/dev/",
                "/run/:/run/:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "item": {
        "key": "kolla-toolbox",
        "value": {
            "container_name": "kolla_toolbox",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ANSIBLE_LIBRARY": "/usr/share/ansible",
                "ANSIBLE_NOCOLOR": "1",
                "REQUESTS_CA_BUNDLE": ""
            },
            "group": "kolla-toolbox",
            "image": "quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/dev/:/dev/",
                "/run/:/run/:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : common | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'kolla-toolbox', 'value': {'container_name': 'kolla_toolbox', 'group': 'kolla-toolbox', 'enabled': True, 'image': 'quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble', 'environment': {'ANSIBLE_NOCOLOR': '1', 'ANSIBLE_LIBRARY': '/usr/share/ansible', 'REQUESTS_CA_BUNDLE': ''}, 'privileged': True, 'volumes': ['/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/dev/:/dev/', '/run/:/run/:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "kolla-toolbox",
        "value": {
            "container_name": "kolla_toolbox",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ANSIBLE_LIBRARY": "/usr/share/ansible",
                "ANSIBLE_NOCOLOR": "1",
                "REQUESTS_CA_BUNDLE": ""
            },
            "group": "kolla-toolbox",
            "image": "quay.io/openstack.kolla/kolla-toolbox:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/kolla-toolbox/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/dev/:/dev/",
                "/run/:/run/:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [common : Creating log volume] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018 `" && echo ansible-tmp-1765371664.3935041-242814-207596174940018="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpn46rh68y TO /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018/ /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hqymqklpdongpdbtfvznxspgfjfgoydb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371664.3935041-242814-207596174940018/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "create_volume",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "labels": {},
            "name": "kolla_logs",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false
        }
    },
    "result": false
}

TASK [common : Link kolla_logs volume to /var/log/kolla] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/bootstrap.yml:10
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126 `" && echo ansible-tmp-1765371665.183513-242871-152844395044126="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpg0po83dj TO /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126/ /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wuncmloslxhstqxemnrnjxhhksgxqbnb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371665.183513-242871-152844395044126/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "dest": "/var/log/kolla",
    "diff": {
        "after": {
            "path": "/var/log/kolla"
        },
        "before": {
            "path": "/var/log/kolla"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/var/log/kolla",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/var/lib/docker/volumes/kolla_logs/_data",
            "state": "link",
            "unsafe_writes": false
        }
    },
    "mode": "0777",
    "owner": "root",
    "size": 40,
    "src": "/var/lib/docker/volumes/kolla_logs/_data",
    "state": "link",
    "uid": 0
}

TASK [common : Flush handlers] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/common/tasks/deploy.yml:8
META: triggered running handlers for localhost

PLAY [Apply role cron] *********************************************************

TASK [cron : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/check-containers.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/deploy.yml for localhost

TASK [cron : Ensuring config directories exist] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855 `" && echo ansible-tmp-1765371665.7258327-242902-108841237051855="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpvksdyslv TO /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855/ /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zatxerwecapjaopiuxowinkxxmvrmhmx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371665.7258327-242902-108841237051855/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/cron"
        },
        "before": {
            "path": "/etc/kolla/cron"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/cron",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/cron",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [cron : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml:15
skipping: [localhost] => {
    "changed": false,
    "false_condition": "cron_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [cron : Copying over config.json files for services] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275 `" && echo ansible-tmp-1765371666.276409-242943-259841677352275="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpbvu_8l3z TO /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/ /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cdcewuzglpvqbydjpixpydxcckosqudp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpz_h0k2dw TO /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/ /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-glpqnlhiowkymqjeetwlzladcaexttha ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371666.276409-242943-259841677352275/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "7edd454148188146d9d903037f4595200dd05eb8",
    "dest": "/etc/kolla/cron/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/cron/config.json"
        },
        "before": {
            "path": "/etc/kolla/cron/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "cron.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/cron/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/cron/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "cron",
        "value": {
            "container_name": "cron",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_LOGROTATE_SCHEDULE": "daily"
            },
            "group": "cron",
            "image": "quay.io/openstack.kolla/cron:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/cron/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/cron/config.json",
    "size": 244,
    "state": "file",
    "uid": 1000
}

TASK [cron : Copying over cron logrotate config file] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml:27
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323 `" && echo ansible-tmp-1765371667.044839-242995-210614007102323="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkirvy8x6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/ /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kkopuqkedfeupkqtvstzgqfqnlllgqwq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpnvoldlm5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/ /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xlwymbkqykqjxgmvaqobbzkieihodmff ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371667.044839-242995-210614007102323/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/templates/cron-logrotate-global.conf.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "3261734e4737e4836331dc904dee401a647b3947",
    "dest": "/etc/kolla/cron/logrotate.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/cron/logrotate.conf"
        },
        "before": {
            "path": "/etc/kolla/cron/logrotate.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "cron-logrotate-global.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/cron/logrotate.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/cron/logrotate.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/templates/cron-logrotate-global.conf.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/cron/logrotate.conf",
    "size": 723,
    "state": "file",
    "uid": 1000
}

TASK [cron : Ensuring config directories have correct owner and permission] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/config.yml:92
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630 `" && echo ansible-tmp-1765371667.8898878-243048-179561847292630="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpnxsja4e9 TO /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630/ /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-eqljnbxcvchcpoxweqqwziftrzwztuhx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371667.8898878-243048-179561847292630/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/cron"
        },
        "before": {
            "path": "/etc/kolla/cron"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/cron",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "cron",
        "value": {
            "container_name": "cron",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_LOGROTATE_SCHEDULE": "daily"
            },
            "group": "cron",
            "image": "quay.io/openstack.kolla/cron:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/cron/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/cron",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [service-check-containers : cron | Check containers] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123 `" && echo ansible-tmp-1765371668.3471785-243076-249446152511123="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpj3jn8bap TO /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123/ /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rpojfrhudkwwjuihwoibthbdgfexmpri ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371668.3471785-243076-249446152511123/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_LOGROTATE_SCHEDULE": "daily"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/cron:master-ubuntu-noble",
            "labels": {},
            "name": "cron",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/cron/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "item": {
        "key": "cron",
        "value": {
            "container_name": "cron",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_LOGROTATE_SCHEDULE": "daily"
            },
            "group": "cron",
            "image": "quay.io/openstack.kolla/cron:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/cron/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : cron | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'cron', 'value': {'container_name': 'cron', 'group': 'cron', 'enabled': True, 'image': 'quay.io/openstack.kolla/cron:master-ubuntu-noble', 'environment': {'KOLLA_LOGROTATE_SCHEDULE': 'daily'}, 'volumes': ['/etc/kolla/cron/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "cron",
        "value": {
            "container_name": "cron",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_LOGROTATE_SCHEDULE": "daily"
            },
            "group": "cron",
            "image": "quay.io/openstack.kolla/cron:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/cron/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [cron : Flush handlers] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/cron/tasks/deploy.yml:8
META: triggered running handlers for localhost

PLAY [Apply role fluentd] ******************************************************

TASK [fluentd : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/check-containers.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/deploy.yml for localhost

TASK [fluentd : Ensuring config directories exist] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829 `" && echo ansible-tmp-1765371669.692557-243231-249167313257829="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpghsroznb TO /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829/ /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-scbmbgtowqxuerngnffwlrozdfenjdsg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371669.692557-243231-249167313257829/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/fluentd"
        },
        "before": {
            "path": "/etc/kolla/fluentd"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/fluentd",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/fluentd",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [fluentd : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:15
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_copy_ca_into_containers | bool",
    "skip_reason": "Conditional result was False"
}

TASK [fluentd : Ensure /var/log/journal exists on EL systems] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:19
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_base_distro in ['centos', 'rocky']",
    "skip_reason": "Conditional result was False"
}

TASK [fluentd : Copying over config.json files for services] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:29
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300 `" && echo ansible-tmp-1765371670.23265-243284-217269641956300="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpp449jm2e TO /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/ /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ptfqdtwanyjcudniqcxqhxcknvnveerq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpsu7e6nvb TO /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/ /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qsfornichquusgmfpnbsxdlwaxddysoa ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371670.23265-243284-217269641956300/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "144759d826f87bc09a70db0de99d773da0831750",
    "dest": "/etc/kolla/fluentd/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/fluentd/config.json"
        },
        "before": {
            "path": "/etc/kolla/fluentd/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fluentd.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/fluentd/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/fluentd/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "fluentd",
        "value": {
            "container_name": "fluentd",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "group": "fluentd",
            "image": "quay.io/openstack.kolla/fluentd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "fluentd_data:/var/lib/fluentd/data/",
                "/var/log/journal:/var/log/journal:ro"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/fluentd/config.json",
    "size": 750,
    "state": "file",
    "uid": 1000
}

TASK [fluentd : Find custom fluentd input config files] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:37
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580 `" && echo ansible-tmp-1765371670.9822888-243336-266619964398580="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/find.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2h6u1txy TO /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580/AnsiballZ_find.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580/ /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371670.9822888-243336-266619964398580/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "examined": 0,
    "files": [],
    "invocation": {
        "module_args": {
            "age": null,
            "age_stamp": "mtime",
            "contains": null,
            "depth": null,
            "encoding": null,
            "exact_mode": true,
            "excludes": null,
            "file_type": "file",
            "follow": false,
            "get_checksum": false,
            "hidden": false,
            "limit": null,
            "mode": null,
            "path": "/etc/kolla/config/fluentd/input",
            "paths": [
                "/etc/kolla/config/fluentd/input"
            ],
            "pattern": "*.conf",
            "patterns": [
                "*.conf"
            ],
            "read_whole_file": false,
            "recurse": false,
            "size": null,
            "use_regex": false
        }
    },
    "matched": 0,
    "msg": "Not all paths examined, check warnings for details",
    "skipped_paths": {
        "/etc/kolla/config/fluentd/input": "'/etc/kolla/config/fluentd/input' is not a directory"
    }
}

TASK [fluentd : Find custom fluentd filter config files] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:45
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676 `" && echo ansible-tmp-1765371671.6092515-243375-148915797805676="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/find.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2_2oja_8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676/AnsiballZ_find.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676/ /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371671.6092515-243375-148915797805676/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "examined": 0,
    "files": [],
    "invocation": {
        "module_args": {
            "age": null,
            "age_stamp": "mtime",
            "contains": null,
            "depth": null,
            "encoding": null,
            "exact_mode": true,
            "excludes": null,
            "file_type": "file",
            "follow": false,
            "get_checksum": false,
            "hidden": false,
            "limit": null,
            "mode": null,
            "path": "/etc/kolla/config/fluentd/filter",
            "paths": [
                "/etc/kolla/config/fluentd/filter"
            ],
            "pattern": "*.conf",
            "patterns": [
                "*.conf"
            ],
            "read_whole_file": false,
            "recurse": false,
            "size": null,
            "use_regex": false
        }
    },
    "matched": 0,
    "msg": "Not all paths examined, check warnings for details",
    "skipped_paths": {
        "/etc/kolla/config/fluentd/filter": "'/etc/kolla/config/fluentd/filter' is not a directory"
    }
}

TASK [fluentd : Find custom fluentd format config files] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:53
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505 `" && echo ansible-tmp-1765371671.9999137-243400-157716223584505="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/find.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4n5v9ien TO /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505/AnsiballZ_find.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505/ /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371671.9999137-243400-157716223584505/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "examined": 0,
    "files": [],
    "invocation": {
        "module_args": {
            "age": null,
            "age_stamp": "mtime",
            "contains": null,
            "depth": null,
            "encoding": null,
            "exact_mode": true,
            "excludes": null,
            "file_type": "file",
            "follow": false,
            "get_checksum": false,
            "hidden": false,
            "limit": null,
            "mode": null,
            "path": "/etc/kolla/config/fluentd/format",
            "paths": [
                "/etc/kolla/config/fluentd/format"
            ],
            "pattern": "*.conf",
            "patterns": [
                "*.conf"
            ],
            "read_whole_file": false,
            "recurse": false,
            "size": null,
            "use_regex": false
        }
    },
    "matched": 0,
    "msg": "Not all paths examined, check warnings for details",
    "skipped_paths": {
        "/etc/kolla/config/fluentd/format": "'/etc/kolla/config/fluentd/format' is not a directory"
    }
}

TASK [fluentd : Find custom fluentd output config files] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:61
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020 `" && echo ansible-tmp-1765371672.392476-243486-209440139267020="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/find.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_3csf1rk TO /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020/AnsiballZ_find.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020/ /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020/AnsiballZ_find.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371672.392476-243486-209440139267020/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "examined": 0,
    "files": [],
    "invocation": {
        "module_args": {
            "age": null,
            "age_stamp": "mtime",
            "contains": null,
            "depth": null,
            "encoding": null,
            "exact_mode": true,
            "excludes": null,
            "file_type": "file",
            "follow": false,
            "get_checksum": false,
            "hidden": false,
            "limit": null,
            "mode": null,
            "path": "/etc/kolla/config/fluentd/output",
            "paths": [
                "/etc/kolla/config/fluentd/output"
            ],
            "pattern": "*.conf",
            "patterns": [
                "*.conf"
            ],
            "read_whole_file": false,
            "recurse": false,
            "size": null,
            "use_regex": false
        }
    },
    "matched": 0,
    "msg": "Not all paths examined, check warnings for details",
    "skipped_paths": {
        "/etc/kolla/config/fluentd/output": "'/etc/kolla/config/fluentd/output' is not a directory"
    }
}

TASK [fluentd : Copying over fluentd.conf] *************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:69
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457 `" && echo ansible-tmp-1765371672.7958326-243514-244458879414457="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpvjq2yq7s TO /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/ /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ohguuzipqawbqdmxdovtvhnmhhvqclas ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpvndw6z2s TO /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/ /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xpwpdkmdqygwhknrgxpmeckxmshvkksl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371672.7958326-243514-244458879414457/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "f15460dd5caf11c466789b415792cc376c04a6f9",
    "dest": "/etc/kolla/fluentd/fluentd.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/fluentd/fluentd.conf"
        },
        "before": {
            "path": "/etc/kolla/fluentd/fluentd.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fluentd.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/fluentd/fluentd.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/fluentd/fluentd.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/fluentd/fluentd.conf",
    "size": 13193,
    "state": "file",
    "uid": 1000
}

TASK [fluentd : Ensuring config directories have correct owner and permission] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/config.yml:134
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716 `" && echo ansible-tmp-1765371673.7830408-243556-73141449956716="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0ozplgh3 TO /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716/ /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sbrxrctamwuhdhueqpuzyjedlizfhyon ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371673.7830408-243556-73141449956716/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/fluentd"
        },
        "before": {
            "path": "/etc/kolla/fluentd"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/fluentd",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "fluentd",
        "value": {
            "container_name": "fluentd",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "group": "fluentd",
            "image": "quay.io/openstack.kolla/fluentd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "fluentd_data:/var/lib/fluentd/data/",
                "/var/log/journal:/var/log/journal:ro"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/fluentd",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [service-check-containers : fluentd | Check containers] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666 `" && echo ansible-tmp-1765371674.262039-243604-259397307026666="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfden5gsd TO /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666/ /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-exetbfpsxrtkqxawxyqiqlfdxhnmtqko ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371674.262039-243604-259397307026666/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/fluentd:master-ubuntu-noble",
            "labels": {},
            "name": "fluentd",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "fluentd_data:/var/lib/fluentd/data/",
                "/var/log/journal:/var/log/journal:ro"
            ]
        }
    },
    "item": {
        "key": "fluentd",
        "value": {
            "container_name": "fluentd",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "group": "fluentd",
            "image": "quay.io/openstack.kolla/fluentd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "fluentd_data:/var/lib/fluentd/data/",
                "/var/log/journal:/var/log/journal:ro"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : fluentd | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'fluentd', 'value': {'container_name': 'fluentd', 'group': 'fluentd', 'enabled': True, 'image': 'quay.io/openstack.kolla/fluentd:master-ubuntu-noble', 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS'}, 'volumes': ['/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'fluentd_data:/var/lib/fluentd/data/', '/var/log/journal:/var/log/journal:ro'], 'dimensions': {}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "fluentd",
        "value": {
            "container_name": "fluentd",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "group": "fluentd",
            "image": "quay.io/openstack.kolla/fluentd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/fluentd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "fluentd_data:/var/lib/fluentd/data/",
                "/var/log/journal:/var/log/journal:ro"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [fluentd : Flush handlers] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/fluentd/tasks/deploy.yml:8
META: triggered running handlers for localhost

PLAY [Apply role loadbalancer] *************************************************

TASK [loadbalancer : include_tasks] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config-host.yml
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/check-containers.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/deploy.yml for localhost

TASK [loadbalancer : Check IPv6 support] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config-host.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251 `" && echo ansible-tmp-1765371675.6266093-243715-79877736048251="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp32k2dhxo TO /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251/ /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371675.6266093-243715-79877736048251/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "/usr/sbin/sysctl",
        "-n",
        "net.ipv6.conf.all.disable_ipv6"
    ],
    "delta": "0:00:00.006406",
    "end": "2025-12-10 14:01:16.051738",
    "invocation": {
        "module_args": {
            "_raw_params": "/usr/sbin/sysctl -n net.ipv6.conf.all.disable_ipv6",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:01:16.045332",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "0",
    "stdout_lines": [
        "0"
    ]
}

TASK [Setting sysctl values] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config-host.yml:8
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
included: sysctl for localhost

TASK [sysctl : Check IPv6 support] *********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/sysctl/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243 `" && echo ansible-tmp-1765371676.2162836-243775-253755015004243="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwa9x2jrc TO /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243/ /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371676.2162836-243775-253755015004243/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "/usr/sbin/sysctl",
        "-n",
        "net.ipv6.conf.all.disable_ipv6"
    ],
    "delta": "0:00:00.005906",
    "end": "2025-12-10 14:01:16.488396",
    "invocation": {
        "module_args": {
            "_raw_params": "/usr/sbin/sysctl -n net.ipv6.conf.all.disable_ipv6",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:01:16.482490",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "0",
    "stdout_lines": [
        "0"
    ]
}

TASK [sysctl : Setting sysctl values] ******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/sysctl/tasks/main.yml:7
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106 `" && echo ansible-tmp-1765371676.5844274-243811-75479556349106="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxranrt6j TO /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106/ /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hdtefdmzsmjsmtkbydejmixycfgtzrfy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371676.5844274-243811-75479556349106/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'name': 'net.ipv6.ip_nonlocal_bind', 'value': 1}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.ipv6.ip_nonlocal_bind",
            "reload": true,
            "state": "present",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": true,
            "value": "1"
        }
    },
    "item": {
        "name": "net.ipv6.ip_nonlocal_bind",
        "value": 1
    }
}
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439 `" && echo ansible-tmp-1765371677.067999-243811-96748956404439="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpgvdrq4hz TO /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439/ /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cwexgqscfhqwncrdcfoolrnjibofachl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371677.067999-243811-96748956404439/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'name': 'net.ipv4.ip_nonlocal_bind', 'value': 1}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.ipv4.ip_nonlocal_bind",
            "reload": true,
            "state": "present",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": true,
            "value": "1"
        }
    },
    "item": {
        "name": "net.ipv4.ip_nonlocal_bind",
        "value": 1
    }
}
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380 `" && echo ansible-tmp-1765371677.417213-243811-124892000998380="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpnw9njeqj TO /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380/ /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gylhgmscplrfgwefarcpofuqpolsswqe ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371677.417213-243811-124892000998380/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'name': 'net.ipv4.tcp_retries2', 'value': 'KOLLA_UNSET'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.ipv4.tcp_retries2",
            "reload": true,
            "state": "absent",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": false,
            "value": ""
        }
    },
    "item": {
        "name": "net.ipv4.tcp_retries2",
        "value": "KOLLA_UNSET"
    }
}
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331 `" && echo ansible-tmp-1765371677.7746289-243811-149410982019331="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprcuan857 TO /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331/ /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sbesmmejjfzkfayljzlfiddouctfcerk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371677.7746289-243811-149410982019331/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'name': 'net.unix.max_dgram_qlen', 'value': 128}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.unix.max_dgram_qlen",
            "reload": true,
            "state": "present",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": true,
            "value": "128"
        }
    },
    "item": {
        "name": "net.unix.max_dgram_qlen",
        "value": 128
    }
}

TASK [module-load : Load modules] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:8
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009 `" && echo ansible-tmp-1765371678.1845062-243957-158190680304009="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
Using module file /home/nics/.ansible/collections/ansible_collections/community/general/plugins/modules/modprobe.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjfmfeio8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009/AnsiballZ_modprobe.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009/ /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009/AnsiballZ_modprobe.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dnxltukjzwmlrghwzylomilxkvlzafbq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009/AnsiballZ_modprobe.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371678.1845062-243957-158190680304009/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=ip_vs) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "name": "ip_vs",
            "params": "",
            "persistent": "disabled",
            "state": "present"
        }
    },
    "item": {
        "name": "ip_vs"
    },
    "name": "ip_vs",
    "params": "",
    "state": "present"
}

TASK [module-load : Persist modules via modules-load.d] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:18
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199 `" && echo ansible-tmp-1765371678.720789-243995-163255654734199="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0hf5oj_a TO /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/ /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hmgssryqmxqtktnxxpllionfyegtbtck ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpnmp1t40c TO /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/ /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qhqthkegtizfdqpaykstnqiuffypvgzq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371678.720789-243995-163255654734199/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=ip_vs) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "946b94c34ba96c4823933f2912d9d431cbc5b742",
    "dest": "/etc/modules-load.d/ip_vs.conf",
    "diff": {
        "after": {
            "path": "/etc/modules-load.d/ip_vs.conf"
        },
        "before": {
            "path": "/etc/modules-load.d/ip_vs.conf"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "module-load.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/modules-load.d/ip_vs.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/modules-load.d/ip_vs.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "name": "ip_vs"
    },
    "mode": "0644",
    "owner": "root",
    "path": "/etc/modules-load.d/ip_vs.conf",
    "size": 25,
    "state": "file",
    "uid": 0
}

TASK [module-load : Drop module persistence] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:29
skipping: [localhost] => (item=ip_vs)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "(item.state | default('present')) == 'absent'",
    "item": {
        "name": "ip_vs"
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [loadbalancer : Ensuring config directories exist] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186 `" && echo ansible-tmp-1765371679.7317421-244038-220107168112186="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmtn9n9p_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186/ /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zjouxvzdzpkohmfbmoejutjttbfkndbe ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371679.7317421-244038-220107168112186/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy"
        },
        "before": {
            "path": "/etc/kolla/haproxy"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/haproxy",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/haproxy",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494 `" && echo ansible-tmp-1765371680.0874624-244038-263046026105494="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpbo3wymyw TO /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494/ /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xjkunmpbjjqooojadaiatrbulymlozsy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371680.0874624-244038-263046026105494/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql"
        },
        "before": {
            "path": "/etc/kolla/proxysql"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/proxysql",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/proxysql",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663 `" && echo ansible-tmp-1765371680.4361262-244038-183026951980663="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpszma4tx_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663/ /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ylpkcaijgyegveyrriqanjenuzehllgx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371680.4361262-244038-183026951980663/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived"
        },
        "before": {
            "path": "/etc/kolla/keepalived"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/keepalived",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/keepalived",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [loadbalancer : Ensuring haproxy service config subdir exists] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:12
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190 `" && echo ansible-tmp-1765371680.9720757-244154-39493819381190="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfsype4mq TO /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190/ /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tsrfxgsvcciurjbsocautqihblpuyqur ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371680.9720757-244154-39493819381190/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/haproxy/services.d",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/haproxy/services.d",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [loadbalancer : Ensuring proxysql service config subdirectories exist] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:24
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977 `" && echo ansible-tmp-1765371681.5180323-244201-181832870056977="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp25hugjfj TO /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977/ /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nzkgilbglwjogzgzysfjxzjjgwtszcpl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371681.5180323-244201-181832870056977/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=users) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/proxysql/users",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": "users",
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/proxysql/users",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251 `" && echo ansible-tmp-1765371682.0747073-244201-196097034147251="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1jhmfkbb TO /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251/ /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ieljybjhwkmahxcjprakzvczrqivnomp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371682.0747073-244201-196097034147251/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=rules) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/proxysql/rules",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": "rules",
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/proxysql/rules",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [loadbalancer : Ensuring keepalived checks subdir exists] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:39
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221 `" && echo ansible-tmp-1765371682.5884814-244326-114747832291221="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd4sd57yd TO /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221/ /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-duamdlvewyelvibvpxkfzujsesbxneot ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371682.5884814-244326-114747832291221/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived/checks"
        },
        "before": {
            "path": "/etc/kolla/keepalived/checks"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/keepalived/checks",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/keepalived/checks",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [loadbalancer : Remove mariadb.cfg if proxysql enabled] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:51
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378 `" && echo ansible-tmp-1765371683.1796453-244354-12199416151378="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv_23vqwa TO /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378/ /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-apvbwiwmxcslrkdkgymgqnjnhpchtuyh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371683.1796453-244354-12199416151378/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/mariadb.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "absent",
            "unsafe_writes": false
        }
    },
    "path": "/etc/kolla/haproxy/services.d/mariadb.cfg",
    "state": "absent"
}

TASK [loadbalancer : Removing checks for services which are disabled] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:62
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "not item.value.enabled | bool or not inventory_hostname in groups[item.value.group]",
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "not item.value.enabled | bool or not inventory_hostname in groups[item.value.group]",
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key != 'keepalived'",
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234', '__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key != 'haproxy-ssh'",
    "item": {
        "key": "haproxy-ssh",
        "value": {
            "container_name": "haproxy_ssh",
            "dimensions": {},
            "enabled": false,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 2985"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234",
                "__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [loadbalancer : Copying checks for services which are enabled] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:78
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043 `" && echo ansible-tmp-1765371684.3476188-244469-215933484846043="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpje2_6n0h TO /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/ /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gvtobfneebyqnshagkoaqldazhxjxjzq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_88dovqo TO /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/ /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-caktmwpbiqqipzvxllvonslrjgxudqqc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371684.3476188-244469-215933484846043/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "34a1388b1dd13fca3c8d337296753e2b374531d3",
    "dest": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh"
        },
        "before": {
            "path": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "check_alive_haproxy.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "mode": "0770",
    "owner": "nics",
    "path": "/etc/kolla/keepalived/checks/check_alive_haproxy.sh",
    "size": 211,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759 `" && echo ansible-tmp-1765371685.2845428-244469-40491936502759="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmphljwx5bt TO /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/ /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dnuduyklxaezfpeblbzntopmnkjwxztc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpoif3xrbr TO /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/ /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iyhqqlpuojuwxxzizxlltpqzwvjmzoda ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371685.2845428-244469-40491936502759/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "48ff8bfb3fc9b91aae22eedcef8556f1c1002d0e",
    "dest": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh"
        },
        "before": {
            "path": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "check_alive_proxysql.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "mode": "0770",
    "owner": "nics",
    "path": "/etc/kolla/keepalived/checks/check_alive_proxysql.sh",
    "size": 210,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key != 'keepalived'",
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'haproxy-ssh', 'value': {'container_name': 'haproxy_ssh', 'group': 'loadbalancer', 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', '__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234', '__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 2985'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key != 'haproxy-ssh'",
    "item": {
        "key": "haproxy-ssh",
        "value": {
            "container_name": "haproxy_ssh",
            "dimensions": {},
            "enabled": false,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 2985"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/haproxy-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234",
                "__omit_place_holder__8429299f4e94525ddd1b0abc812267b531d52234"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [loadbalancer : Copying over config.json files for services] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:95
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230 `" && echo ansible-tmp-1765371686.241225-244671-279542707025230="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmvvlcl81 TO /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/ /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vxgdkjmqcxqtebhabfmyysobfeoyfxim ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmps1zpcdsw TO /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/ /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-frwnrytxvntqniywalfaiksshfzigxis ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371686.241225-244671-279542707025230/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "57347b6b4453d432f35a97a8152501044ae41a3a",
    "dest": "/etc/kolla/haproxy/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/config.json"
        },
        "before": {
            "path": "/etc/kolla/haproxy/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/config.json",
    "size": 1390,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066 `" && echo ansible-tmp-1765371687.1788445-244671-86139905655066="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp311y39ba TO /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/ /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nhnivdmmknshrrbjbglhyqundpbksaid ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_tcjlg6i TO /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/ /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rzpcdvzezzhjhotjxcrttkirvvodfbfi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371687.1788445-244671-86139905655066/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "32e455fe9af604658bd2d435452884cd4ad018b7",
    "dest": "/etc/kolla/proxysql/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/config.json"
        },
        "before": {
            "path": "/etc/kolla/proxysql/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "proxysql.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/config.json",
    "size": 846,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737 `" && echo ansible-tmp-1765371688.0020053-244671-68789505302737="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpj5gqyqk5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/ /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vpmihmcukjtsacyobwgrxxtbhtgtuiiu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp58flqoj7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/ /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vltekngnolnjcqnplqjkvvugsqnbxdxj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371688.0020053-244671-68789505302737/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "6f4ffcf840d9f7b1bdbe64b912773d4a5210437a",
    "dest": "/etc/kolla/keepalived/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived/config.json"
        },
        "before": {
            "path": "/etc/kolla/keepalived/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keepalived.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keepalived/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keepalived/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keepalived/config.json",
    "size": 467,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : Copying over haproxy.cfg] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:103
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141 `" && echo ansible-tmp-1765371688.9843354-244964-107582330210141="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxik1pxf4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/ /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-shhzprbgftjafvdwperiagbxevnqtyru ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp18uljvn2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/ /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nvcepdepjtsdcrnvfppsgwzjbagyhsrb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371688.9843354-244964-107582330210141/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_main.cfg.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "6681db6ec1c792689d535248c7f611e09532e723",
    "dest": "/etc/kolla/haproxy/haproxy.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/haproxy.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/haproxy.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_main.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/haproxy.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/haproxy.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_main.cfg.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/haproxy.cfg",
    "size": 929,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : Copying over proxysql config] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:117
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681 `" && echo ansible-tmp-1765371690.084139-245058-50259126142681="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3jn8uztc TO /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/ /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-achartkihcyoiitbhknatetejxfscrzv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpev3jwcxw TO /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/ /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mqfvrjcykqhnjorhjyjoyxruklmmtpet ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371690.084139-245058-50259126142681/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql.yaml.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "c3ea41423af847a0ecf86fa73748fa82a2dae9ee",
    "dest": "/etc/kolla/proxysql/proxysql.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/proxysql.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/proxysql.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "proxysql.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/proxysql.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/proxysql.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql.yaml.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/proxysql.yaml",
    "size": 1598,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : Copying over haproxy single external frontend config] *****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:131
skipping: [localhost] => {
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "skip_reason": "Conditional result was False"
}

TASK [loadbalancer : Copying over custom haproxy services configuration] *******
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:143
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [loadbalancer : Copying over keepalived.conf] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:155
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895 `" && echo ansible-tmp-1765371691.4464433-245177-183585038584895="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpy1unxh3u TO /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/ /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pxyatuspzqgzuthhpztuqevhgcdfzvch ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzjthnc7c TO /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/ /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-feyuvyhuydtwmiugyarswgexxrsmhvnt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371691.4464433-245177-183585038584895/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/keepalived/keepalived.conf.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "2b66a774394b00a3cdc0f64ac3657116ef44f964",
    "dest": "/etc/kolla/keepalived/keepalived.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/keepalived/keepalived.conf"
        },
        "before": {
            "path": "/etc/kolla/keepalived/keepalived.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keepalived.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keepalived/keepalived.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keepalived/keepalived.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/keepalived/keepalived.conf.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keepalived/keepalived.conf",
    "size": 460,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : include_tasks] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:169
skipping: [localhost] => {
    "changed": false,
    "false_condition": "loadbalancer_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [loadbalancer : Copying over haproxy start script] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:173
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733 `" && echo ansible-tmp-1765371692.6134753-245241-242776348472733="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3yhr7i66 TO /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/ /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-riowrziydemkueujecrrsirlpviuljzm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpboxkyqkb TO /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/ /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qgsdrrdydtvscrlbgovkbcwiifqfwrqv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371692.6134753-245241-242776348472733/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_run.sh.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "3e95bfda1743f98378a36aec037e4d01674e207c",
    "dest": "/etc/kolla/haproxy/haproxy_run.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/haproxy_run.sh"
        },
        "before": {
            "path": "/etc/kolla/haproxy/haproxy_run.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_run.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/haproxy_run.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/haproxy_run.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/haproxy/haproxy_run.sh.j2",
    "mode": "0770",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/haproxy_run.sh",
    "size": 166,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : Copying over proxysql start script] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:187
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426 `" && echo ansible-tmp-1765371693.6307058-245284-127640508956426="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptz702ttl TO /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/ /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rypofewhtrqcfphlymvyghzhashyxwel ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5_t5u7e4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/ /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lcccpgbxvkycopykfczfzwezvmvdirsp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371693.6307058-245284-127640508956426/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql_run.sh.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "b142ee971c2b812e60f6009694ec1c27035e0c70",
    "dest": "/etc/kolla/proxysql/proxysql_run.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/proxysql_run.sh"
        },
        "before": {
            "path": "/etc/kolla/proxysql/proxysql_run.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "proxysql_run.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/proxysql_run.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/proxysql_run.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/templates/proxysql/proxysql_run.sh.j2",
    "mode": "0770",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/proxysql_run.sh",
    "size": 195,
    "state": "file",
    "uid": 1000
}

TASK [loadbalancer : Copying files for haproxy-ssh] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/loadbalancer/tasks/config.yml:201
skipping: [localhost] => (item={'src': 'haproxy-ssh/sshd_config.j2', 'dest': 'sshd_config'})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service | service_enabled_and_mapped_to_host",
    "item": {
        "dest": "sshd_config",
        "src": "haproxy-ssh/sshd_config.j2"
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'src': 'haproxy-ssh/id_rsa.pub', 'dest': 'id_rsa.pub'})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service | service_enabled_and_mapped_to_host",
    "item": {
        "dest": "id_rsa.pub",
        "src": "haproxy-ssh/id_rsa.pub"
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-check-containers : loadbalancer | Check containers] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093 `" && echo ansible-tmp-1765371694.8653953-245355-19615204559093="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv3ox3_lx TO /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093/ /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hjabpfghwobhjwrciqmpugfohdvbasqh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371694.8653953-245355-19615204559093/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "labels": {},
            "name": "haproxy",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629 `" && echo ansible-tmp-1765371695.8910563-245355-245978783152629="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpls7fam92 TO /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629/ /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dmhowxhzwwzgvlbjgipcnocyylganbvw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371695.8910563-245355-245978783152629/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "labels": {},
            "name": "proxysql",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697 `" && echo ansible-tmp-1765371697.0040677-245355-89998831301697="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpyqy82rmq TO /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697/ /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kpdcfhexcrdetbgqeuemixjwrqdphgkk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371697.0040677-245355-89998831301697/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "labels": {},
            "name": "keepalived",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [include_role : aodh] *****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:153
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_aodh | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : barbican] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:158
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_barbican | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : blazar] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:163
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_blazar | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : ceph-rgw] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:168
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_ceph_rgw | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : cinder] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:173
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_cinder | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : cloudkitty] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:178
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_cloudkitty | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : cyborg] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:183
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_cyborg | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : designate] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:188
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_designate | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : etcd] *****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:193
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_etcd | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : glance] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:198
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: glance for localhost

TASK [haproxy-config : Copying over glance haproxy config] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942 `" && echo ansible-tmp-1765371699.528732-245635-127083125902942="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx4aabupt TO /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/ /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-amtqgacjeqbxbcdzwckxtjpuzvuygojn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpl1cutbfj TO /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/ /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gtwajrggoazhugixtkwbzcqjjkkbkzjb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371699.528732-245635-127083125902942/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "4c9bc1ca2226cbd5c871bdb0e4bdea48569e4282",
    "dest": "/etc/kolla/haproxy/services.d/glance-api.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/glance-api.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/glance-api.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/glance-api.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/glance-api.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/glance-api.cfg",
    "size": 442,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "glance-tls-proxy",
        "value": {
            "container_name": "glance_tls_proxy",
            "dimensions": {},
            "enabled": false,
            "group": "glance-api",
            "haproxy": {
                "glance_tls_proxy": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt",
                        ""
                    ],
                    "enabled": false,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292",
                    "tls_backend": "yes"
                },
                "glance_tls_proxy_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt",
                        ""
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292",
                    "tls_backend": "yes"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [haproxy-config : Add configuration for glance when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'glance-tls-proxy', 'value': {'container_name': 'glance_tls_proxy', 'group': 'glance-api', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'volumes': ['/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293'], 'timeout': '30'}, 'haproxy': {'glance_tls_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}, 'glance_tls_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt', ''], 'tls_backend': 'yes'}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "glance-tls-proxy",
        "value": {
            "container_name": "glance_tls_proxy",
            "dimensions": {},
            "enabled": false,
            "group": "glance-api",
            "haproxy": {
                "glance_tls_proxy": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt",
                        ""
                    ],
                    "enabled": false,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292",
                    "tls_backend": "yes"
                },
                "glance_tls_proxy_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5 ssl verify required ca-file ca-certificates.crt",
                        ""
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292",
                    "tls_backend": "yes"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl -u openstack:Bp0GPk5m2jnnrsae4nfn7JrPkJFfpMQyx9e2RSMe 192.168.0.195:9293"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/glance-tls-proxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for glance] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'glance_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "glance_api",
        "value": {
            "backend_http_extra": [
                "timeout server 6h",
                "option httpchk"
            ],
            "custom_member_list": [
                "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                ""
            ],
            "enabled": true,
            "external": false,
            "frontend_http_extra": [
                "timeout client 6h"
            ],
            "mode": "http",
            "port": "9292"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'glance_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "glance_api_external",
        "value": {
            "backend_http_extra": [
                "timeout server 6h",
                "option httpchk"
            ],
            "custom_member_list": [
                "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                ""
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "frontend_http_extra": [
                "timeout client 6h"
            ],
            "mode": "http",
            "port": "9292"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over glance ProxySQL users config] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371 `" && echo ansible-tmp-1765371701.4622185-245789-103377138221371="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkhfgpnq9 TO /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/ /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qwugyigbrhospkcnphlmusfotbhtumtr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmrza0d3u TO /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/ /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fcupybkrxcnsmwukupqabnvipdwmstzp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371701.4622185-245789-103377138221371/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "3d0cb8697c7065221a3319758b06376911e49a7b",
    "dest": "/etc/kolla/proxysql/users/glance.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/glance.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/glance.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/glance.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/glance.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/glance.yaml",
    "size": 744,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over glance ProxySQL rules config] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355 `" && echo ansible-tmp-1765371702.2523625-245831-81909938791355="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7ztegwji TO /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/ /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lvrkzfxgthksimknkicmsonucupprzzm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpl5vytqcd TO /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/ /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mxwdfcinjqepjkpeqlqtxnxqycnyniko ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371702.2523625-245831-81909938791355/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "ec3e55b9b78c8dbbd9f4204a750705f99d062c57",
    "dest": "/etc/kolla/proxysql/rules/glance.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/glance.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/glance.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/glance.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/glance.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/glance.yaml",
    "size": 614,
    "state": "file",
    "uid": 1000
}

TASK [include_role : gnocchi] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:203
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_gnocchi | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : grafana] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:208
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_grafana | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : heat] *****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:213
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: heat for localhost

TASK [haproxy-config : Copying over heat haproxy config] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076 `" && echo ansible-tmp-1765371703.5854495-245939-228180621871076="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq5p80u65 TO /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/ /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-elgfhqfxzaimrmdvxphdhajickukhmmw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpo1883ub5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/ /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rcjhltrohpcpzshncodfbrdjuujqaldu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371703.5854495-245939-228180621871076/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "21195daaee8e321ec564ceeb3fb2659b4a8f6b58",
    "dest": "/etc/kolla/haproxy/services.d/heat-api.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/heat-api.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/heat-api.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/heat-api.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/heat-api.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "heat-api",
        "value": {
            "container_name": "heat_api",
            "dimensions": {},
            "enabled": true,
            "group": "heat-api",
            "haproxy": {
                "heat_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8004",
                    "mode": "http",
                    "port": "8004",
                    "tls_backend": false
                },
                "heat_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8004",
                    "mode": "http",
                    "port": "8004",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8004"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ],
            "wsgi": "heat.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/heat-api.cfg",
    "size": 389,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345 `" && echo ansible-tmp-1765371704.3848882-245939-99654988220345="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptjz8f3qc TO /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/ /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zocmgvphnmdkucxzsuhdyncqzxjgadvf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1zyiy_29 TO /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/ /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cokfqliokrhrganmduflnrzkuggbebof ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371704.3848882-245939-99654988220345/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "73f48963528e5b1b8bc54abe9e4106da6072fca6",
    "dest": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "heat-api-cfn",
        "value": {
            "container_name": "heat_api_cfn",
            "dimensions": {},
            "enabled": true,
            "group": "heat-api-cfn",
            "haproxy": {
                "heat_api_cfn": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8000",
                    "mode": "http",
                    "port": "8000",
                    "tls_backend": false
                },
                "heat_api_cfn_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8000",
                    "mode": "http",
                    "port": "8000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ],
            "wsgi": "heat.wsgi.cfn:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/heat-api-cfn.cfg",
    "size": 401,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "heat-engine",
        "value": {
            "container_name": "heat_engine",
            "dimensions": {},
            "enabled": true,
            "group": "heat-engine",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port heat-engine 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-engine:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [haproxy-config : Add configuration for heat when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'heat-api', 'value': {'container_name': 'heat_api', 'group': 'heat-api', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8004'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.api:application', 'haproxy': {'heat_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "heat-api",
        "value": {
            "container_name": "heat_api",
            "dimensions": {},
            "enabled": true,
            "group": "heat-api",
            "haproxy": {
                "heat_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8004",
                    "mode": "http",
                    "port": "8004",
                    "tls_backend": false
                },
                "heat_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8004",
                    "mode": "http",
                    "port": "8004",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8004"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ],
            "wsgi": "heat.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'heat-api-cfn', 'value': {'container_name': 'heat_api_cfn', 'group': 'heat-api-cfn', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8000'], 'timeout': '30'}, 'wsgi': 'heat.wsgi.cfn:application', 'haproxy': {'heat_api_cfn': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'heat_api_cfn_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "heat-api-cfn",
        "value": {
            "container_name": "heat_api_cfn",
            "dimensions": {},
            "enabled": true,
            "group": "heat-api-cfn",
            "haproxy": {
                "heat_api_cfn": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8000",
                    "mode": "http",
                    "port": "8000",
                    "tls_backend": false
                },
                "heat_api_cfn_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8000",
                    "mode": "http",
                    "port": "8000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-api-cfn:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-api-cfn/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ],
            "wsgi": "heat.wsgi.cfn:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'heat-engine', 'value': {'container_name': 'heat_engine', 'group': 'heat-engine', 'enabled': True, 'image': 'quay.io/openstack.kolla/heat-engine:master-ubuntu-noble', 'volumes': ['/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port heat-engine 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "heat-engine",
        "value": {
            "container_name": "heat_engine",
            "dimensions": {},
            "enabled": true,
            "group": "heat-engine",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port heat-engine 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/heat-engine:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/heat-engine/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for heat] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'heat_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "heat_api",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "8004",
            "mode": "http",
            "port": "8004",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'heat_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8004', 'listen_port': '8004', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "heat_api_external",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "8004",
            "mode": "http",
            "port": "8004",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'heat_api_cfn', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "heat_api_cfn",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "8000",
            "mode": "http",
            "port": "8000",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'heat_api_cfn_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8000', 'listen_port': '8000', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "heat_api_cfn_external",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "8000",
            "mode": "http",
            "port": "8000",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over heat ProxySQL users config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274 `" && echo ansible-tmp-1765371706.0491219-246095-76534619756274="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7750sy_o TO /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/ /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-oblemmpcfkikhkqadteynszdpawfsaub ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjhsdxcy0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/ /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ageknjkgiskfdqmmwftdbhlzhkblizgt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371706.0491219-246095-76534619756274/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "a4be1fe7eb59b973ae0934bfba50f1f64df156bf",
    "dest": "/etc/kolla/proxysql/users/heat.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/heat.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/heat.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/heat.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/heat.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/heat.yaml",
    "size": 742,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over heat ProxySQL rules config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816 `" && echo ansible-tmp-1765371706.8505795-246180-281193673281816="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfc2a92mj TO /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/ /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-czchjahmwbvbvvkmkfohuiblltfdukkf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzvfe49nf TO /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/ /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-spixhhtppwncxnqduckytpfsgscurnda ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371706.8505795-246180-281193673281816/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "d5ed95966b215f58308ce9c5105034757ddb60af",
    "dest": "/etc/kolla/proxysql/rules/heat.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/heat.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/heat.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/heat.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/heat.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/heat.yaml",
    "size": 610,
    "state": "file",
    "uid": 1000
}

TASK [include_role : horizon] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:218
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: horizon for localhost

TASK [haproxy-config : Copying over horizon haproxy config] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350 `" && echo ansible-tmp-1765371708.0803654-246256-39680689991350="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprd0hc7u6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/ /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dhmlehqhvveccfwizucbgpwozclprkon ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpl_z3vkwr TO /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/ /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xafxqdweihdhyjjzpujxvzbudsigjqjg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371708.0803654-246256-39680689991350/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "7b76555fc02783d336933f88c4f3fe1b1dbb437e",
    "dest": "/etc/kolla/haproxy/services.d/horizon.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/horizon.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/horizon.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/horizon.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/horizon.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "horizon",
        "value": {
            "container_name": "horizon",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ENABLE_BLAZAR": "no",
                "ENABLE_CLOUDKITTY": "no",
                "ENABLE_DESIGNATE": "no",
                "ENABLE_FWAAS": "no",
                "ENABLE_HEAT": "yes",
                "ENABLE_IRONIC": "no",
                "ENABLE_MAGNUM": "no",
                "ENABLE_MANILA": "no",
                "ENABLE_MASAKARI": "no",
                "ENABLE_MISTRAL": "no",
                "ENABLE_NEUTRON_VPNAAS": "no",
                "ENABLE_OCTAVIA": "no",
                "ENABLE_TACKER": "no",
                "ENABLE_TROVE": "no",
                "ENABLE_WATCHER": "no",
                "ENABLE_ZUN": "no",
                "FORCE_GENERATE": "no"
            },
            "group": "horizon",
            "haproxy": {
                "acme_client": {
                    "custom_member_list": [],
                    "enabled": false,
                    "with_frontend": false
                },
                "horizon": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "http",
                    "port": "80",
                    "tls_backend": false
                },
                "horizon_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "http",
                    "port": "80",
                    "tls_backend": false
                },
                "horizon_external_redirect": {
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_redirect_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "redirect",
                    "port": "80"
                },
                "horizon_redirect": {
                    "enabled": false,
                    "external": false,
                    "frontend_redirect_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "redirect",
                    "port": "80"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8080"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/horizon:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro",
                "",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ],
            "wsgi": "openstack_dashboard.wsgi:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/horizon.cfg",
    "size": 412,
    "state": "file",
    "uid": 1000
}

TASK [haproxy-config : Add configuration for horizon when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'horizon', 'value': {'container_name': 'horizon', 'group': 'horizon', 'enabled': True, 'image': 'quay.io/openstack.kolla/horizon:master-ubuntu-noble', 'environment': {'ENABLE_BLAZAR': 'no', 'ENABLE_CLOUDKITTY': 'no', 'ENABLE_DESIGNATE': 'no', 'ENABLE_FWAAS': 'no', 'ENABLE_HEAT': 'yes', 'ENABLE_IRONIC': 'no', 'ENABLE_MAGNUM': 'no', 'ENABLE_MANILA': 'no', 'ENABLE_MASAKARI': 'no', 'ENABLE_MISTRAL': 'no', 'ENABLE_NEUTRON_VPNAAS': 'no', 'ENABLE_OCTAVIA': 'no', 'ENABLE_TACKER': 'no', 'ENABLE_TROVE': 'no', 'ENABLE_WATCHER': 'no', 'ENABLE_ZUN': 'no', 'FORCE_GENERATE': 'no'}, 'volumes': ['/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro', '', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8080'], 'timeout': '30'}, 'wsgi': 'openstack_dashboard.wsgi:application', 'haproxy': {'horizon': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_redirect': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'horizon_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}, 'horizon_external_redirect': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}, 'acme_client': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "horizon",
        "value": {
            "container_name": "horizon",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "ENABLE_BLAZAR": "no",
                "ENABLE_CLOUDKITTY": "no",
                "ENABLE_DESIGNATE": "no",
                "ENABLE_FWAAS": "no",
                "ENABLE_HEAT": "yes",
                "ENABLE_IRONIC": "no",
                "ENABLE_MAGNUM": "no",
                "ENABLE_MANILA": "no",
                "ENABLE_MASAKARI": "no",
                "ENABLE_MISTRAL": "no",
                "ENABLE_NEUTRON_VPNAAS": "no",
                "ENABLE_OCTAVIA": "no",
                "ENABLE_TACKER": "no",
                "ENABLE_TROVE": "no",
                "ENABLE_WATCHER": "no",
                "ENABLE_ZUN": "no",
                "FORCE_GENERATE": "no"
            },
            "group": "horizon",
            "haproxy": {
                "acme_client": {
                    "custom_member_list": [],
                    "enabled": false,
                    "with_frontend": false
                },
                "horizon": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "http",
                    "port": "80",
                    "tls_backend": false
                },
                "horizon_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "http",
                    "port": "80",
                    "tls_backend": false
                },
                "horizon_external_redirect": {
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_redirect_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "redirect",
                    "port": "80"
                },
                "horizon_redirect": {
                    "enabled": false,
                    "external": false,
                    "frontend_redirect_extra": [
                        ""
                    ],
                    "listen_port": "8080",
                    "mode": "redirect",
                    "port": "80"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8080"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/horizon:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/horizon/:/var/lib/kolla/config_files/:ro",
                "",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ],
            "wsgi": "openstack_dashboard.wsgi:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for horizon] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'horizon', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "horizon",
        "value": {
            "backend_http_extra": [
                "balance roundrobin",
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "frontend_http_extra": [
                ""
            ],
            "listen_port": "8080",
            "mode": "http",
            "port": "80",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'horizon_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': False, 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.enabled | bool",
    "item": {
        "key": "horizon_redirect",
        "value": {
            "enabled": false,
            "external": false,
            "frontend_redirect_extra": [
                ""
            ],
            "listen_port": "8080",
            "mode": "redirect",
            "port": "80"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'horizon_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_http_extra': [''], 'backend_http_extra': ['balance roundrobin', 'option httpchk'], 'tls_backend': False}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "horizon_external",
        "value": {
            "backend_http_extra": [
                "balance roundrobin",
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "frontend_http_extra": [
                ""
            ],
            "listen_port": "8080",
            "mode": "http",
            "port": "80",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'horizon_external_redirect', 'value': {'enabled': False, 'mode': 'redirect', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '80', 'listen_port': '8080', 'frontend_redirect_extra': ['']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.enabled | bool",
    "item": {
        "key": "horizon_external_redirect",
        "value": {
            "enabled": false,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "frontend_redirect_extra": [
                ""
            ],
            "listen_port": "8080",
            "mode": "redirect",
            "port": "80"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'acme_client', 'value': {'enabled': False, 'with_frontend': False, 'custom_member_list': []}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.enabled | bool",
    "item": {
        "key": "acme_client",
        "value": {
            "custom_member_list": [],
            "enabled": false,
            "with_frontend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over horizon ProxySQL users config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356 `" && echo ansible-tmp-1765371709.9024494-246310-191725345731356="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3he2fvcw TO /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/ /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bofmfgarfmycqmocjlsxseerbicherok ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpz_mz2hes TO /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/ /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rdbqszwtjjbbvehanmcbcrsothfvkxml ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371709.9024494-246310-191725345731356/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "47bd53d97152074a8c7b7eafb054906e65ea6332",
    "dest": "/etc/kolla/proxysql/users/horizon.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/horizon.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/horizon.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/horizon.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/horizon.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/horizon.yaml",
    "size": 745,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over horizon ProxySQL rules config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414 `" && echo ansible-tmp-1765371710.7174685-246384-147313138989414="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2u73jlk4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/ /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ejrfaiqhnvxsidvbllypsgqddtsipowq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpesx8o7nb TO /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/ /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gjflawbqnwmmenjdbcpkmojuwobfespj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371710.7174685-246384-147313138989414/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "370829be573bbeea32c8369b02cf23845fe25e68",
    "dest": "/etc/kolla/proxysql/rules/horizon.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/horizon.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/horizon.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/horizon.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/horizon.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/horizon.yaml",
    "size": 616,
    "state": "file",
    "uid": 1000
}

TASK [include_role : influxdb] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:223
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_influxdb | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : ironic] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:228
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_ironic | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : keystone] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:233
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: keystone for localhost

TASK [haproxy-config : Copying over keystone haproxy config] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345 `" && echo ansible-tmp-1765371712.1692748-246449-169797152499345="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpre9u7g7o TO /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/ /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-elhxsqeokqopsesccxoptizztyunycwr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_13pdzjc TO /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/ /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kqietteghjdtmaxvnqaqymoodvjesurz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371712.1692748-246449-169797152499345/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "4b1a76189463069b91337f3bda43ce1c6e9b194f",
    "dest": "/etc/kolla/haproxy/services.d/keystone.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/keystone.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/keystone.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/keystone.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/keystone.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/keystone.cfg",
    "size": 439,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "keystone-httpd",
        "value": {
            "container_name": "keystone_httpd",
            "dimensions": {},
            "enabled": false,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/httpd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [haproxy-config : Add configuration for keystone when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-httpd', 'value': {'container_name': 'keystone_httpd', 'group': 'keystone', 'enabled': False, 'image': 'quay.io/openstack.kolla/httpd:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "keystone-httpd",
        "value": {
            "container_name": "keystone_httpd",
            "dimensions": {},
            "enabled": false,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/httpd:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-httpd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for keystone] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'keystone_internal', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "keystone_internal",
        "value": {
            "backend_http_extra": [
                "balance roundrobin",
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "5000",
            "mode": "http",
            "port": "5000",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "keystone_external",
        "value": {
            "backend_http_extra": [
                "balance roundrobin",
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "5000",
            "mode": "http",
            "port": "5000",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over keystone ProxySQL users config] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401 `" && echo ansible-tmp-1765371714.0467184-246583-213774198158401="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx06csgav TO /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/ /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jvhipfufsltnauasxaluljgcrvsdxphi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwvavac64 TO /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/ /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ccemqnjycgegjbhptqantdrzydbljeow ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371714.0467184-246583-213774198158401/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "9ed2bde093d1f326a58e4706a8757ab97a904fb0",
    "dest": "/etc/kolla/proxysql/users/keystone.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/keystone.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/keystone.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/keystone.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/keystone.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/keystone.yaml",
    "size": 746,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over keystone ProxySQL rules config] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380 `" && echo ansible-tmp-1765371714.8510518-246635-179423061219380="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_yijaona TO /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/ /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qrmrwivncflbwxcqvqlwgjswewbkhcvg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpj97g3z9l TO /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/ /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hallzrwriboabeivjrtjzbtpilzjrxvz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371714.8510518-246635-179423061219380/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "55cfc809c5b16cafb35e84cf1abd558cda1ceb15",
    "dest": "/etc/kolla/proxysql/rules/keystone.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/keystone.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/keystone.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/keystone.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/keystone.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/keystone.yaml",
    "size": 618,
    "state": "file",
    "uid": 1000
}

TASK [include_role : letsencrypt] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:238
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_letsencrypt | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : magnum] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:243
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_magnum | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : manila] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:248
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_manila | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : mariadb] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:253
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: mariadb for localhost

TASK [mariadb : Ensure mysql monitor user exist] *******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/loadbalancer.yml:18
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033 `" && echo ansible-tmp-1765371716.1448076-246681-238453309249033="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptoe5b6lz TO /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033/ /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-reqgdgcieftuujwqaegoutwlschjecil ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371716.1448076-246681-238453309249033/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=localhost) => {
    "action": "mysql_user",
    "ansible_loop_var": "item",
    "changed": false,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "append_privs": false,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "localhost",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root",
            "name": "monitor",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "*.*:USAGE,REPLICATION CLIENT",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "monitor"
        }
    },
    "item": {
        "key": "0",
        "value": {
            "hosts": [
                "localhost"
            ]
        }
    },
    "msg": "unable to connect to database, check login_user and login_password are correct or /var/lib/ansible/.my.cnf has the credentials. Exception message: (1698, \"Access denied for user 'root'@'localhost'\")"
}

TASK [haproxy-config : Copying over mariadb haproxy config] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_config_install | bool",
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Add configuration for mariadb when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_config_install | bool",
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for mariadb] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'mariadb_external_lb', 'value': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_config_install | bool",
    "item": {
        "key": "mariadb_external_lb",
        "value": {
            "backend_tcp_extra": [
                "option srvtcpka",
                "timeout server 3600s"
            ],
            "custom_member_list": [
                " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                ""
            ],
            "enabled": false,
            "frontend_tcp_extra": [
                "option clitcpka",
                "timeout client 3600s"
            ],
            "listen_port": "3306",
            "mode": "tcp",
            "port": "3306"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over mariadb ProxySQL users config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289 `" && echo ansible-tmp-1765371719.2332911-246833-181505223028289="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp__nr0rr0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/ /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wtbnzokvdtoiupgqrasytdzfyghbxpie ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpf99b999k TO /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/ /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jzyrbwekhrbihkwkrtjzdrrfesjmfykx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371719.2332911-246833-181505223028289/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "47e65d0c5c4a18283002acec697c1997f0308f5c",
    "dest": "/etc/kolla/proxysql/users/mariadb.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/mariadb.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/mariadb.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/mariadb.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/mariadb.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/mariadb.yaml",
    "size": 750,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over mariadb ProxySQL rules config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
skipping: [localhost] => {
    "changed": false,
    "false_condition": "proxysql_config_rules | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : masakari] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:258
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_masakari | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : memcached] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:263
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: memcached for localhost

TASK [haproxy-config : Copying over memcached haproxy config] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962 `" && echo ansible-tmp-1765371720.5223582-246887-111178829281962="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpyigog_y1 TO /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/ /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zrjkrykfzrsxkzsaneicnrtgktkhwpiv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzm5a0k0n TO /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/ /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-aknxlkfwstnmvwbbszfbhwqvzkfyhfji ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371720.5223582-246887-111178829281962/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "adc83b19e793491b1c6ea0fd8b46cd9f32e592fc",
    "dest": "/etc/kolla/haproxy/services.d/memcached.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/memcached.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/memcached.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/memcached.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/memcached.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "memcached",
        "value": {
            "container_name": "memcached",
            "dimensions": {},
            "enabled": true,
            "group": "memcached",
            "haproxy": {
                "memcached": {
                    "active_passive": true,
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "mode": "tcp",
                    "port": "11211"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen memcached 11211"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/memcached:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/memcached.cfg",
    "size": 1,
    "state": "file",
    "uid": 1000
}

TASK [haproxy-config : Add configuration for memcached when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "memcached",
        "value": {
            "container_name": "memcached",
            "dimensions": {},
            "enabled": true,
            "group": "memcached",
            "haproxy": {
                "memcached": {
                    "active_passive": true,
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "mode": "tcp",
                    "port": "11211"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen memcached 11211"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/memcached:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for memcached] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'memcached', 'value': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.enabled | bool",
    "item": {
        "key": "memcached",
        "value": {
            "active_passive": true,
            "backend_tcp_extra": [
                "option srvtcpka",
                "timeout server 3600s"
            ],
            "enabled": false,
            "frontend_tcp_extra": [
                "option clitcpka",
                "timeout client 3600s"
            ],
            "mode": "tcp",
            "port": "11211"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over memcached ProxySQL users config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
skipping: [localhost] => {
    "changed": false,
    "false_condition": "proxysql_config_users | bool",
    "skip_reason": "Conditional result was False"
}

TASK [proxysql-config : Copying over memcached ProxySQL rules config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
skipping: [localhost] => {
    "changed": false,
    "false_condition": "proxysql_config_rules | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : mistral] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:268
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mistral | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : neutron] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:273
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: neutron for localhost

TASK [haproxy-config : Copying over neutron haproxy config] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879 `" && echo ansible-tmp-1765371723.187149-247141-96284834036879="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp84ui4_jh TO /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/ /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-woumyrbeqgtjvgezgouqmoorgqfwntku ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpech8eziy TO /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/ /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hozcaqhiuetteabqguijkyvdakxhcwvl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371723.187149-247141-96284834036879/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "39b1f044fe8abd567f5082b382edb44a97b87386",
    "dest": "/etc/kolla/haproxy/services.d/neutron-server.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/neutron-server.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/neutron-server.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/neutron-server.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/neutron-server.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "neutron-server",
        "value": {
            "container_name": "neutron_server",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-server",
            "haproxy": {
                "neutron_server": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "9696",
                    "mode": "http",
                    "port": "9696",
                    "tls_backend": false
                },
                "neutron_server_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "9696",
                    "mode": "http",
                    "port": "9696",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9696"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "neutron.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/neutron-server.cfg",
    "size": 407,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-rpc-server",
        "value": {
            "container_name": "neutron_rpc_server",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-rpc-server",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-rpc-server 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-periodic-worker",
        "value": {
            "container_name": "neutron_periodic_worker",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-periodic-worker",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-periodic-workers 3306"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-ovn-maintenance-worker",
        "value": {
            "container_name": "neutron_ovn_maintenance_worker",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-ovn-maintenance-worker",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-maintenance-worker 6641"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-openvswitch-agent",
        "value": {
            "container_name": "neutron_openvswitch_agent",
            "dimensions": {},
            "enabled": true,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-openvswitch-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-dhcp-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_dhcp_agent",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_dhcp_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "group": "neutron-dhcp-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-dhcp-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-l3-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_l3_agent",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_l3_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port 'neutron-l3-agent ' 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-sriov-agent",
        "value": {
            "container_name": "neutron_sriov_agent",
            "dimensions": {},
            "enabled": false,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-sriov-nic-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-mlnx-agent",
        "value": {
            "container_name": "neutron_mlnx_agent",
            "dimensions": {},
            "enabled": false,
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-eswitchd",
        "value": {
            "container_name": "neutron_eswitchd",
            "dimensions": {},
            "enabled": false,
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/run/libvirt:/run/libvirt:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "neutron-metadata-agent",
        "value": {
            "container_name": "neutron_metadata_agent",
            "dimensions": {},
            "enabled": true,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": "NONE",
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-ovn-metadata-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_ovn_metadata_agent",
            "dimensions": {},
            "enabled": false,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_ovn_metadata_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-metadata-agent 6640"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/openvswitch:/run/openvswitch:shared",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-bgp-dragent",
        "value": {
            "container_name": "neutron_bgp_dragent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-bgp-dragent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-bgp-dragent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-infoblox-ipam-agent",
        "value": {
            "container_name": "neutron_infoblox_ipam_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-infoblox-ipam-agent",
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-metering-agent",
        "value": {
            "container_name": "neutron_metering_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-metering-agent",
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "ironic-neutron-agent",
        "value": {
            "container_name": "ironic_neutron_agent",
            "dimensions": {},
            "enabled": false,
            "group": "ironic-neutron-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port ironic-neutron-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "neutron-ovn-agent",
        "value": {
            "container_name": "neutron_ovn_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-ovn-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-agent 6640"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [haproxy-config : Add configuration for neutron when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'neutron-server', 'value': {'container_name': 'neutron_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9696'], 'timeout': '30'}, 'wsgi': 'neutron.wsgi.api:application', 'haproxy': {'neutron_server': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}, 'neutron_server_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-server",
        "value": {
            "container_name": "neutron_server",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-server",
            "haproxy": {
                "neutron_server": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "9696",
                    "mode": "http",
                    "port": "9696",
                    "tls_backend": false
                },
                "neutron_server_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "9696",
                    "mode": "http",
                    "port": "9696",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9696"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "neutron.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-rpc-server', 'value': {'container_name': 'neutron_rpc_server', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-rpc-server', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-rpc-server 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-rpc-server",
        "value": {
            "container_name": "neutron_rpc_server",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-rpc-server",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-rpc-server 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-rpc-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-periodic-worker', 'value': {'container_name': 'neutron_periodic_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': True, 'group': 'neutron-periodic-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-periodic-workers 3306'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-periodic-worker",
        "value": {
            "container_name": "neutron_periodic_worker",
            "dimensions": {},
            "enabled": true,
            "group": "neutron-periodic-worker",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-periodic-workers 3306"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-periodic-worker/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-maintenance-worker', 'value': {'container_name': 'neutron_ovn_maintenance_worker', 'image': 'quay.io/openstack.kolla/neutron-server:master-ubuntu-noble', 'enabled': False, 'group': 'neutron-ovn-maintenance-worker', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-maintenance-worker 6641'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-ovn-maintenance-worker",
        "value": {
            "container_name": "neutron_ovn_maintenance_worker",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-ovn-maintenance-worker",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-maintenance-worker 6641"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-ovn-maintenance-worker/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-openvswitch-agent', 'value': {'container_name': 'neutron_openvswitch_agent', 'image': 'quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-openvswitch-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-openvswitch-agent",
        "value": {
            "container_name": "neutron_openvswitch_agent",
            "dimensions": {},
            "enabled": true,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-openvswitch-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-openvswitch-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-openvswitch-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-dhcp-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_dhcp_agent', 'image': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'group': 'neutron-dhcp-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-dhcp-agent 5672'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_dhcp_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-dhcp-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_dhcp_agent",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_dhcp_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "group": "neutron-dhcp-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-dhcp-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-dhcp-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-dhcp-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-l3-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_l3_agent', 'image': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_l3_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', "healthcheck_port 'neutron-l3-agent ' 5672"], 'timeout': '30'}, 'pid_mode': 'host'}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-l3-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_l3_agent",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_l3_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port 'neutron-l3-agent ' 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-l3-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-l3-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-sriov-agent', 'value': {'container_name': 'neutron_sriov_agent', 'image': 'quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-sriov-nic-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-sriov-agent",
        "value": {
            "container_name": "neutron_sriov_agent",
            "dimensions": {},
            "enabled": false,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-sriov-nic-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-sriov-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-sriov-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-mlnx-agent', 'value': {'container_name': 'neutron_mlnx_agent', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-mlnx-agent",
        "value": {
            "container_name": "neutron_mlnx_agent",
            "dimensions": {},
            "enabled": false,
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-mlnx-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-eswitchd', 'value': {'container_name': 'neutron_eswitchd', 'image': 'quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/run/libvirt:/run/libvirt:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-eswitchd",
        "value": {
            "container_name": "neutron_eswitchd",
            "dimensions": {},
            "enabled": false,
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-mlnx-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-eswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/run/libvirt:/run/libvirt:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-metadata-agent', 'value': {'container_name': 'neutron_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': True, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': 'NONE', 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-metadata-agent",
        "value": {
            "container_name": "neutron_metadata_agent",
            "dimensions": {},
            "enabled": true,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": "NONE",
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-metadata-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-metadata-agent', 'value': {'cgroupns_mode': 'host', 'container_name': 'neutron_ovn_metadata_agent', 'image': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', 'neutron_metadata_socket:/var/lib/neutron/kolla/', '/run/openvswitch:/run/openvswitch:shared', '/run/netns:/run/netns:shared', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', '/var/run/docker.sock:/var/run/docker.sock:ro', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-metadata-agent 6640'], 'timeout': '30'}, 'pid_mode': 'host', 'environment': {'KOLLA_IMAGE': 'quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble', 'KOLLA_NAME': 'neutron_ovn_metadata_agent', 'KOLLA_NEUTRON_WRAPPERS': 'true'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-ovn-metadata-agent",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "neutron_ovn_metadata_agent",
            "dimensions": {},
            "enabled": false,
            "environment": {
                "KOLLA_IMAGE": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
                "KOLLA_NAME": "neutron_ovn_metadata_agent",
                "KOLLA_NEUTRON_WRAPPERS": "true"
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-metadata-agent 6640"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metadata-agent:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-ovn-metadata-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "neutron_metadata_socket:/var/lib/neutron/kolla/",
                "/run/openvswitch:/run/openvswitch:shared",
                "/run/netns:/run/netns:shared",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                "/var/run/docker.sock:/var/run/docker.sock:ro",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-bgp-dragent', 'value': {'container_name': 'neutron_bgp_dragent', 'image': 'quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-bgp-dragent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-bgp-dragent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-bgp-dragent",
        "value": {
            "container_name": "neutron_bgp_dragent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-bgp-dragent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-bgp-dragent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-bgp-dragent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-bgp-dragent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-infoblox-ipam-agent', 'value': {'container_name': 'neutron_infoblox_ipam_agent', 'image': 'quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-infoblox-ipam-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-infoblox-ipam-agent",
        "value": {
            "container_name": "neutron_infoblox_ipam_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-infoblox-ipam-agent",
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-infoblox-ipam-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-infoblox-ipam-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-metering-agent', 'value': {'container_name': 'neutron_metering_agent', 'image': 'quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble', 'privileged': True, 'enabled': False, 'group': 'neutron-metering-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-metering-agent",
        "value": {
            "container_name": "neutron_metering_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-metering-agent",
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-metering-agent:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/neutron-metering-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'ironic-neutron-agent', 'value': {'container_name': 'ironic_neutron_agent', 'image': 'quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble', 'privileged': False, 'enabled': False, 'group': 'ironic-neutron-agent', 'host_in_groups': True, 'volumes': ['/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port ironic-neutron-agent 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "ironic-neutron-agent",
        "value": {
            "container_name": "ironic_neutron_agent",
            "dimensions": {},
            "enabled": false,
            "group": "ironic-neutron-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port ironic-neutron-agent 5672"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/ironic-neutron-agent:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/ironic-neutron-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron-ovn-agent', 'value': {'container_name': 'neutron_ovn_agent', 'group': 'neutron-ovn-agent', 'host_in_groups': True, 'enabled': False, 'image': 'quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble', 'volumes': ['/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port neutron-ovn-agent 6640'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "neutron-ovn-agent",
        "value": {
            "container_name": "neutron_ovn_agent",
            "dimensions": {},
            "enabled": false,
            "group": "neutron-ovn-agent",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port neutron-ovn-agent 6640"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/neutron-ovn-agent:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/neutron-ovn-agent/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for neutron] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'neutron_server', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "neutron_server",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "9696",
            "mode": "http",
            "port": "9696",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'neutron_server_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9696', 'listen_port': '9696', 'backend_http_extra': ['option httpchk'], 'tls_backend': False}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "neutron_server_external",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "9696",
            "mode": "http",
            "port": "9696",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over neutron ProxySQL users config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308 `" && echo ansible-tmp-1765371726.5280848-247407-131286019075308="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpcs9bmgbj TO /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/ /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fpoklxpxkifrrckmybhmppktksvxltec ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwjoaqfu7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/ /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dgippxhthbnwgbiohojxjbercgkgmzlc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371726.5280848-247407-131286019075308/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7c1d6308c1d6d27c0b0605ae42e56bb6b2ebbbaf",
    "dest": "/etc/kolla/proxysql/users/neutron.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/neutron.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/neutron.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/neutron.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/neutron.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/neutron.yaml",
    "size": 745,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over neutron ProxySQL rules config] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939 `" && echo ansible-tmp-1765371727.4387476-247505-140433630339939="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4t9t91js TO /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/ /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-anummikrtnutijfcwypfewwrdskhbfes ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpb9hl6kji TO /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/ /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zfhzlykooibbyxoeyvoffukhksekovnw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371727.4387476-247505-140433630339939/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "156880d64b3b19976adf423b95bacf4bc2b571f9",
    "dest": "/etc/kolla/proxysql/rules/neutron.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/neutron.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/neutron.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/neutron.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/neutron.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/neutron.yaml",
    "size": 616,
    "state": "file",
    "uid": 1000
}

TASK [include_role : placement] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:278
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: placement for localhost

TASK [haproxy-config : Copying over placement haproxy config] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980 `" && echo ansible-tmp-1765371728.7731388-247565-239654014360980="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5_pg9kyo TO /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/ /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-acvpostumemamnyoblqeowgeuctaojue ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpr_r1dt4s TO /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/ /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nxlhbrvnwidgombytixdblgzwbhcxira ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371728.7731388-247565-239654014360980/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "90e902a0d99a25c764014361511a62109c0adc25",
    "dest": "/etc/kolla/haproxy/services.d/placement-api.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/placement-api.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/placement-api.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/placement-api.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/placement-api.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/placement-api.cfg",
    "size": 410,
    "state": "file",
    "uid": 1000
}

TASK [haproxy-config : Add configuration for placement when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for placement] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'placement_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "placement_api",
        "value": {
            "backend_http_extra": [
                "option httpchk GET /"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "8780",
            "mode": "http",
            "port": "8780",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'placement_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "placement_api_external",
        "value": {
            "backend_http_extra": [
                "option httpchk GET /"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "8780",
            "mode": "http",
            "port": "8780",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over placement ProxySQL users config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497 `" && echo ansible-tmp-1765371730.1920424-247711-207580687012497="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmplclqbbel TO /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/ /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ykhpzcpnqfdbocsgeffcihoovxajtxnk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0uy_51ns TO /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/ /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-impbewwhckgpohompyysamwphjjbkqlj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371730.1920424-247711-207580687012497/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "923ade82577475f4c2fee21451c55623db054491",
    "dest": "/etc/kolla/proxysql/users/placement.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/placement.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/placement.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/placement.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/placement.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/placement.yaml",
    "size": 747,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over placement ProxySQL rules config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920 `" && echo ansible-tmp-1765371730.956799-247772-133730939294920="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6_w_qnuc TO /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/ /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-yqcyjtdmdifdgaamuztqtqvyahcubzol ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp96k0nbcb TO /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/ /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nemogsytpagqwwvmyfzqvuqmomphpdsv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371730.956799-247772-133730939294920/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "cebc322a0f0e78f0af9aaf1982c3832878f8fa31",
    "dest": "/etc/kolla/proxysql/rules/placement.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/placement.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/placement.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/placement.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/placement.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/placement.yaml",
    "size": 620,
    "state": "file",
    "uid": 1000
}

TASK [include_role : nova] *****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:282
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: nova for localhost

TASK [haproxy-config : Copying over nova haproxy config] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623 `" && echo ansible-tmp-1765371732.4247086-247834-25673690605623="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpddaa6sid TO /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/ /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-psgguupctewmqrzvfktvqsclvdwjwppa ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpovmj1gxf TO /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/ /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bqcuzfwojpmexbjxfmnydfpcrznklwhf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371732.4247086-247834-25673690605623/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "ab9eb530a5e5035b88e907c8515849087f50dd83",
    "dest": "/etc/kolla/haproxy/services.d/nova-api.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/nova-api.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/nova-api.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/nova-api.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/nova-api.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/nova-api.cfg",
    "size": 389,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317 `" && echo ansible-tmp-1765371733.2302067-247834-135559414314317="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5ee3a4t7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/ /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kfexcpygynimvgrpflotkqokbnwcernj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpf_r_92e4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/ /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dufzgpselicadewapjqtcskyndpjgjqp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371733.2302067-247834-135559414314317/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "66ae8180382d11b7d52f5d37d465173e55573b29",
    "dest": "/etc/kolla/haproxy/services.d/nova-metadata.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/nova-metadata.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/nova-metadata.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/nova-metadata.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/nova-metadata.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/nova-metadata.cfg",
    "size": 404,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.haproxy is defined",
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "nova-super-conductor",
        "value": {
            "container_name": "nova_super_conductor",
            "dimensions": {},
            "enabled": false,
            "group": "nova-super-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [haproxy-config : Add configuration for nova when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-super-conductor', 'value': {'container_name': 'nova_super_conductor', 'group': 'nova-super-conductor', 'enabled': False, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-super-conductor",
        "value": {
            "container_name": "nova_super_conductor",
            "dimensions": {},
            "enabled": false,
            "group": "nova-super-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-super-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for nova] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'nova_api', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "nova_api",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "8774",
            "mode": "http",
            "port": "8774",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova_api_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "nova_api_external",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "8774",
            "mode": "http",
            "port": "8774",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova_metadata', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "nova_metadata",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "8775",
            "mode": "http",
            "port": "8775",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova_metadata_external', 'value': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.enabled | bool",
    "item": {
        "key": "nova_metadata_external",
        "value": {
            "backend_http_extra": [
                "option httpchk"
            ],
            "enabled": "no",
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "8775",
            "mode": "http",
            "port": "8775",
            "tls_backend": false
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over nova ProxySQL users config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275 `" && echo ansible-tmp-1765371734.9950712-248019-204153447663275="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi3irjxpd TO /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/ /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jgfuishdttromsgwzehgxwmtcwrnobmy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp52yeqfnm TO /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/ /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-upxarbfuazcwydyrkcrhwaqjffipjasb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371734.9950712-248019-204153447663275/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7a6e0b68bce4f2076c5833f2d83b1022d1291850",
    "dest": "/etc/kolla/proxysql/users/nova.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/nova.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/nova.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/nova.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/nova.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/nova.yaml",
    "size": 746,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over nova ProxySQL rules config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548 `" && echo ansible-tmp-1765371735.8191392-248061-75890653608548="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5zp7lu85 TO /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/ /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zunvqzhuoieiifsisyzgmuhopndxmlfm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpl9gr3_gg TO /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/ /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kyhsviealymcrftzqhqhmzgvxiqbkppv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371735.8191392-248061-75890653608548/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "c0e2c4d58ea3b0f749d65d2bc56f99bd0f831338",
    "dest": "/etc/kolla/proxysql/rules/nova.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/nova.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/nova.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/nova.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/nova.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/nova.yaml",
    "size": 618,
    "state": "file",
    "uid": 1000
}

TASK [include_role : nova-cell] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:289
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml
included: nova-cell for localhost

TASK [nova-cell : Configure loadbalancer for nova-novncproxy] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml:5
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-novncproxy)

TASK [haproxy-config : Copying over nova-cell:nova-novncproxy haproxy config] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199 `" && echo ansible-tmp-1765371737.443213-248208-142994695295199="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpf0104swb TO /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/ /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ihknyrjffzwpwbawdhxyzvnvutvnzkqd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7msyreli TO /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/ /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fkvvmywgpmihpugptzkitlbruaxcajvi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371737.443213-248208-142994695295199/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "69cf017b94eb7fc6b6ba3118dcca5cd1010a5e20",
    "dest": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "enabled": true,
            "group": "nova-novncproxy",
            "haproxy": {
                "nova_novncproxy": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "6080",
                    "mode": "http",
                    "port": "6080"
                },
                "nova_novncproxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6080",
                    "mode": "http",
                    "port": "6080"
                }
            }
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/nova-novncproxy.cfg",
    "size": 413,
    "state": "file",
    "uid": 1000
}

TASK [haproxy-config : Add configuration for nova-cell:nova-novncproxy when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'group': 'nova-novncproxy', 'enabled': True, 'haproxy': {'nova_novncproxy': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_novncproxy_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "enabled": true,
            "group": "nova-novncproxy",
            "haproxy": {
                "nova_novncproxy": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "6080",
                    "mode": "http",
                    "port": "6080"
                },
                "nova_novncproxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6080",
                    "mode": "http",
                    "port": "6080"
                }
            }
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for nova-cell:nova-novncproxy] *****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'nova_novncproxy', 'value': {'enabled': True, 'mode': 'http', 'external': False, 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "nova_novncproxy",
        "value": {
            "backend_http_extra": [
                "timeout tunnel 1h"
            ],
            "enabled": true,
            "external": false,
            "listen_port": "6080",
            "mode": "http",
            "port": "6080"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova_novncproxy_external', 'value': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6080', 'listen_port': '6080', 'backend_http_extra': ['timeout tunnel 1h']}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "enable_external_api_firewalld | bool",
    "item": {
        "key": "nova_novncproxy_external",
        "value": {
            "backend_http_extra": [
                "timeout tunnel 1h"
            ],
            "enabled": true,
            "external": true,
            "external_fqdn": "192.168.0.201",
            "listen_port": "6080",
            "mode": "http",
            "port": "6080"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779 `" && echo ansible-tmp-1765371739.0645013-248281-273181046870779="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp32ce9mj4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/ /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dnujnblylbufwmzonjpbarktxmycqdgr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqf0808kv TO /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/ /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dqfjtnhuejafoageavjcvyspajyslqaj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371739.0645013-248281-273181046870779/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7efb329e879b047e04468d9b13f01d164e5a08e6",
    "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "size": 742,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260 `" && echo ansible-tmp-1765371740.0272546-248323-139455694562260="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpu9pxpv2t TO /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/ /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mxolmdthpgzdqpnunktodwinzytxrezm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_0pcl0r6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/ /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dfkokgwoyvqigxyyfkdtljxhpdzmfymt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371740.0272546-248323-139455694562260/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "cc7cc2d9228cb9441b9bdab0ca0cf9118f61dce7",
    "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "size": 616,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Configure loadbalancer for nova-spicehtml5proxy] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml:5
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-spicehtml5proxy)

TASK [haproxy-config : Copying over nova-cell:nova-spicehtml5proxy haproxy config] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "nova-spicehtml5proxy",
        "value": {
            "enabled": false,
            "group": "nova-spicehtml5proxy",
            "haproxy": {
                "nova_spicehtml5proxy": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": false,
                    "external": false,
                    "listen_port": "6082",
                    "mode": "http",
                    "port": "6082"
                },
                "nova_spicehtml5proxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6082",
                    "mode": "http",
                    "port": "6082"
                }
            }
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Add configuration for nova-cell:nova-spicehtml5proxy when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'nova-spicehtml5proxy', 'value': {'group': 'nova-spicehtml5proxy', 'enabled': False, 'haproxy': {'nova_spicehtml5proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}, 'nova_spicehtml5proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6082', 'listen_port': '6082', 'backend_http_extra': ['timeout tunnel 1h']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-spicehtml5proxy",
        "value": {
            "enabled": false,
            "group": "nova-spicehtml5proxy",
            "haproxy": {
                "nova_spicehtml5proxy": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": false,
                    "external": false,
                    "listen_port": "6082",
                    "mode": "http",
                    "port": "6082"
                },
                "nova_spicehtml5proxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 1h"
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6082",
                    "mode": "http",
                    "port": "6082"
                }
            }
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for nova-cell:nova-spicehtml5proxy] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443 `" && echo ansible-tmp-1765371742.167624-248434-192979406965443="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpuze8pcyw TO /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/ /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pxxvjmlnzvsdzhufcbyuottjxbinegkv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx7ongoxk TO /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/ /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xexhcyarsfgwxhicvdoqplxraggivoel ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371742.167624-248434-192979406965443/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7efb329e879b047e04468d9b13f01d164e5a08e6",
    "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "size": 742,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716 `" && echo ansible-tmp-1765371743.0938535-248520-6763035513716="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwie2zl65 TO /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/ /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ffyhvgelzkmfshhwffyzusmynrdikcgl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpksvbltd2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/ /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zvtxkwyhlvbzyrkyjypssrejlwaecjom ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371743.0938535-248520-6763035513716/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "cc7cc2d9228cb9441b9bdab0ca0cf9118f61dce7",
    "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "size": 616,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Configure loadbalancer for nova-serialproxy] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml:5
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml for localhost => (item=nova-serialproxy)

TASK [haproxy-config : Copying over nova-cell:nova-serialproxy haproxy config] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service.enabled | bool",
    "item": {
        "key": "nova-serialproxy",
        "value": {
            "enabled": false,
            "group": "nova-serialproxy",
            "haproxy": {
                "nova_serialconsole_proxy": {
                    "backend_http_extra": [
                        "timeout tunnel 10m"
                    ],
                    "enabled": false,
                    "external": false,
                    "listen_port": "6083",
                    "mode": "http",
                    "port": "6083"
                },
                "nova_serialconsole_proxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 10m"
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6083",
                    "mode": "http",
                    "port": "6083"
                }
            }
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Add configuration for nova-cell:nova-serialproxy when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'nova-serialproxy', 'value': {'group': 'nova-serialproxy', 'enabled': False, 'haproxy': {'nova_serialconsole_proxy': {'enabled': False, 'mode': 'http', 'external': False, 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}, 'nova_serialconsole_proxy_external': {'enabled': False, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '6083', 'listen_port': '6083', 'backend_http_extra': ['timeout tunnel 10m']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "nova-serialproxy",
        "value": {
            "enabled": false,
            "group": "nova-serialproxy",
            "haproxy": {
                "nova_serialconsole_proxy": {
                    "backend_http_extra": [
                        "timeout tunnel 10m"
                    ],
                    "enabled": false,
                    "external": false,
                    "listen_port": "6083",
                    "mode": "http",
                    "port": "6083"
                },
                "nova_serialconsole_proxy_external": {
                    "backend_http_extra": [
                        "timeout tunnel 10m"
                    ],
                    "enabled": false,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "6083",
                    "mode": "http",
                    "port": "6083"
                }
            }
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for nova-cell:nova-serialproxy] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [proxysql-config : Copying over nova-cell ProxySQL users config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169 `" && echo ansible-tmp-1765371745.1157346-248596-259323819707169="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpimxjk7vf TO /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/ /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zjmybptqhxeqzbvljushbiyjrvacsume ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3a_wu2gl TO /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/ /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-thdzqxwcmhiopgxymdivughdhkvqxtnn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371745.1157346-248596-259323819707169/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7efb329e879b047e04468d9b13f01d164e5a08e6",
    "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "users.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/users/nova-cell.yaml",
    "size": 742,
    "state": "file",
    "uid": 1000
}

TASK [proxysql-config : Copying over nova-cell ProxySQL rules config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027 `" && echo ansible-tmp-1765371746.0523272-248638-96891296985027="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2k0xmqnz TO /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/ /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jzszobrlvgtsmgcwontziljxwboiwkxq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkrzdx8eb TO /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/ /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vdmogsaaewbyyevuaybvoxoqpqlqacvb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371746.0523272-248638-96891296985027/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "cc7cc2d9228cb9441b9bdab0ca0cf9118f61dce7",
    "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "diff": {
        "after": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        },
        "before": {
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rules.yaml.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/proxysql/rules/nova-cell.yaml",
    "size": 616,
    "state": "file",
    "uid": 1000
}

TASK [include_role : octavia] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:296
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_octavia | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : opensearch] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:301
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_opensearch | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : prometheus] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:306
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_prometheus | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : rabbitmq] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:311
redirecting (type: modules) ansible.builtin.firewalld to ansible.posix.firewalld
included: rabbitmq for localhost

TASK [haproxy-config : Copying over rabbitmq haproxy config] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047 `" && echo ansible-tmp-1765371747.5423594-248717-167529410314047="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpy1795kxu TO /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/ /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mqcduszwxcemafwbfpruwlecqmvdvrjn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_lgx3uxh TO /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/ /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qlyituzxdnvyransynjgcjsghfabdfpu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371747.5423594-248717-167529410314047/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "6ffa5f9deea6ddcd40b28e33c9655d42c672b173",
    "dest": "/etc/kolla/haproxy/services.d/rabbitmq.cfg",
    "diff": {
        "after": {
            "path": "/etc/kolla/haproxy/services.d/rabbitmq.cfg"
        },
        "before": {
            "path": "/etc/kolla/haproxy/services.d/rabbitmq.cfg"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "haproxy_single_service_split.cfg.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/haproxy/services.d/rabbitmq.cfg",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/haproxy/services.d/rabbitmq.cfg",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": null,
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": null,
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": null,
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/haproxy/services.d/rabbitmq.cfg",
    "size": 405,
    "state": "file",
    "uid": 1000
}

TASK [haproxy-config : Add configuration for rabbitmq when using single external frontend] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:23
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': None, 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': None, 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "haproxy_single_external_frontend | bool",
    "item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": null,
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": null,
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": null,
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [haproxy-config : Configuring firewall for rabbitmq] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/haproxy-config/tasks/main.yml:51
skipping: [localhost] => (item={'key': 'rabbitmq_management', 'value': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.value.external | default('false') | bool",
    "item": {
        "key": "rabbitmq_management",
        "value": {
            "enabled": "yes",
            "host_group": "rabbitmq",
            "mode": "http",
            "port": "15672"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [proxysql-config : Copying over rabbitmq ProxySQL users config] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:2
skipping: [localhost] => {
    "changed": false,
    "false_condition": "proxysql_config_users | bool",
    "skip_reason": "Conditional result was False"
}

TASK [proxysql-config : Copying over rabbitmq ProxySQL rules config] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/proxysql-config/tasks/main.yml:11
skipping: [localhost] => {
    "changed": false,
    "false_condition": "proxysql_config_rules | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : skyline] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:319
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_skyline | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : tacker] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:324
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_tacker | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : trove] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:329
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_trove | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : watcher] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:334
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_watcher | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : zun] ******************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:339
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_zun | bool",
    "skip_reason": "Conditional result was False"
}

TASK [include_role : loadbalancer] *********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/site.yml:346
included: loadbalancer for localhost

TASK [service-check-containers : loadbalancer | Check containers] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359 `" && echo ansible-tmp-1765371749.8355346-248800-156478570825359="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpt0w81ev5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359/ /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-stavluetteqotqgedffvykxuhkagrogu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371749.8355346-248800-156478570825359/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "labels": {},
            "name": "haproxy",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811 `" && echo ansible-tmp-1765371750.8177855-248800-207510967540811="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9rr8s4q0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811/ /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dpnfvuykiplvappipggvhlexvgpacayv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371750.8177855-248800-207510967540811/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "labels": {},
            "name": "proxysql",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165 `" && echo ansible-tmp-1765371751.8268423-248800-88810947374165="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp81t9izzb TO /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165/ /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mthzbequgjzemyntixxqktneqxahxguz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371751.8268423-248800-88810947374165/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "labels": {},
            "name": "keepalived",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : loadbalancer | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'haproxy', 'value': {'container_name': 'haproxy', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/haproxy:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'letsencrypt_certificates:/etc/haproxy/certificates'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:61313'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "haproxy",
        "value": {
            "container_name": "haproxy",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:61313"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/haproxy:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/haproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "letsencrypt_certificates:/etc/haproxy/certificates"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'proxysql', 'value': {'container_name': 'proxysql', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/proxysql:master-ubuntu-noble', 'privileged': False, 'volumes': ['/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'proxysql:/var/lib/proxysql/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen proxysql 6032'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "proxysql",
        "value": {
            "container_name": "proxysql",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen proxysql 6032"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/proxysql:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/proxysql/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "proxysql:/var/lib/proxysql/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keepalived', 'value': {'container_name': 'keepalived', 'group': 'loadbalancer', 'enabled': True, 'image': 'quay.io/openstack.kolla/keepalived:master-ubuntu-noble', 'privileged': True, 'volumes': ['/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'haproxy_socket:/var/lib/kolla/haproxy/', 'proxysql_socket:/var/lib/kolla/proxysql/'], 'dimensions': {}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "keepalived",
        "value": {
            "container_name": "keepalived",
            "dimensions": {},
            "enabled": true,
            "group": "loadbalancer",
            "image": "quay.io/openstack.kolla/keepalived:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/keepalived/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "haproxy_socket:/var/lib/kolla/haproxy/",
                "proxysql_socket:/var/lib/kolla/proxysql/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

PLAY [Apply role opensearch] ***************************************************
skipping: no hosts matched

PLAY [Apply role letsencrypt] **************************************************
skipping: no hosts matched

PLAY [Apply role collectd] *****************************************************
skipping: no hosts matched

PLAY [Apply role influxdb] *****************************************************
skipping: no hosts matched

PLAY [Apply role telegraf] *****************************************************
skipping: no hosts matched

PLAY [Apply role valkey] *******************************************************
skipping: no hosts matched

PLAY [Apply role mariadb] ******************************************************

TASK [mariadb : Group MariaDB hosts based on shards] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/main.yml:2
creating host via 'add_host': hostname=localhost
ok: [localhost] => (item=localhost) => {
    "add_host": {
        "groups": [
            "mariadb_shard_0"
        ],
        "host_name": "localhost",
        "host_vars": {}
    },
    "ansible_loop_var": "item",
    "changed": false,
    "item": "localhost"
}

TASK [mariadb : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/main.yml:9
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/check.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/deploy.yml for localhost

TASK [mariadb : Ensuring config directories exist] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718 `" && echo ansible-tmp-1765371753.7758746-249069-160904490139718="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpa4qxdt06 TO /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718/ /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ykcnhbrbygjxvspjhpvfntyancvnciqp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371753.7758746-249069-160904490139718/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/mariadb"
        },
        "before": {
            "path": "/etc/kolla/mariadb"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/mariadb",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/mariadb",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [mariadb : Ensuring database backup config directory exists] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mariabackup | bool",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Copying over my.cnf for mariabackup] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:24
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mariabackup | bool",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Copying over config.json files for services] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:39
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683 `" && echo ansible-tmp-1765371754.3986168-249116-64926160912683="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2r64bhfj TO /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/ /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hddvvuvsqcjwrfjadlskiwpalrlefmjo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpb8nemuw8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/ /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mplziwsnraaxsenfxefhflscrpjlboes ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371754.3986168-249116-64926160912683/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "4d477cacfde08916bbaaa1251e5ee4533e0070b6",
    "dest": "/etc/kolla/mariadb/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/mariadb/config.json"
        },
        "before": {
            "path": "/etc/kolla/mariadb/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "mariadb.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/mariadb/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/mariadb/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/mariadb/config.json",
    "size": 749,
    "state": "file",
    "uid": 1000
}

TASK [mariadb : Copying over config.json files for mariabackup] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:47
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mariabackup | bool",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Copying over galera.cnf] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:59
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549 `" && echo ansible-tmp-1765371755.364338-249199-209137606263549="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmplyj7b1nu TO /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/ /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xjcxjvpaamxtircypaapvkvhbqfjdnul ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpdh59k9ea TO /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/ /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lfqlanzszvsmguluzesbydfpxdfcbkys ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371755.364338-249199-209137606263549/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "60185945ea6b4f708c98e0aec585726d1eed1d05",
    "dest": "/etc/kolla/mariadb/galera.cnf",
    "diff": {
        "after": {
            "path": "/etc/kolla/mariadb/galera.cnf"
        },
        "before": {
            "path": "/etc/kolla/mariadb/galera.cnf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/mariadb/galera.cnf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/mariadb/galera.cnf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/templates/galera.cnf.j2",
                "/etc/kolla/config/galera.cnf",
                "/etc/kolla/config/mariadb/localhost/galera.cnf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpdv2iltam/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/mariadb/galera.cnf",
    "size": 1146,
    "state": "file",
    "uid": 1000
}

TASK [mariadb : Copying over healthcheck.cnf] **********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:73
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873 `" && echo ansible-tmp-1765371756.3241887-249249-247814687972873="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpoiudk47e TO /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/ /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fulmsbwvhjznlmxkpuhvylswxtjtidzj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpeelv1fpd TO /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/ /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fbhypvfwikcwbbiuzbswpumuyorxklip ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371756.3241887-249249-247814687972873/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "11c1f928207024d731ff8d908adf71a24c4e7b95",
    "dest": "/etc/kolla/mariadb/healthcheck.cnf",
    "diff": {
        "after": {
            "path": "/etc/kolla/mariadb/healthcheck.cnf"
        },
        "before": {
            "path": "/etc/kolla/mariadb/healthcheck.cnf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/mariadb/healthcheck.cnf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/mariadb/healthcheck.cnf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/templates/healthcheck.cnf.j2",
                "/etc/kolla/config/healthcheck.cnf",
                "/etc/kolla/config/mariadb/localhost/healthcheck.cnf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkenga1ak/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/mariadb/healthcheck.cnf",
    "size": 85,
    "state": "file",
    "uid": 1000
}

TASK [mariadb : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/config.yml:89
skipping: [localhost] => {
    "changed": false,
    "false_condition": "mariadb_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [service-check-containers : mariadb | Check containers] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730 `" && echo ansible-tmp-1765371757.3016262-249310-107189892369730="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpbvh9dk8y TO /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730/ /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nuwavurpsavoudrjoejwksqzavumgtkv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371757.3016262-249310-107189892369730/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "labels": {},
            "name": "mariadb",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : mariadb | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [mariadb : Checking for mariadb cluster] **********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:2
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Cleaning up temp file on localhost] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:7
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [mariadb : Stop MariaDB containers] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:21
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Run MariaDB wsrep recovery] ************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:31
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Copying MariaDB log file to /tmp] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:47
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Get MariaDB wsrep recovery seqno] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:54
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Removing MariaDB log file from /tmp] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:60
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Registering MariaDB seqno variable] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:68
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Comparing seqno value on all mariadb hosts] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:73
skipping: [localhost] => (item=localhost)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "migration_flag is defined",
    "item": "localhost",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [mariadb : Writing hostname of host with the largest seqno to temp file] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:85
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Registering mariadb_recover_inventory_name from temp file] *****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:95
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Store bootstrap and master hostnames into facts] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:100
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Set grastate.dat file from MariaDB container in bootstrap host] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:104
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Refresh galera.cnf to set first MariaDB container as primary] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:117
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Starting first MariaDB container] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:133
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Wait for first MariaDB container] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:151
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Wait for MariaDB to become operational] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:166
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Restart slave MariaDB container(s)] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:186
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "migration_flag is defined",
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [mariadb : Wait for slave MariaDB] ****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:202
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Unset pc.bootstrap for primary MariaDB galera.cnf for next restart] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:217
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Restart master MariaDB container(s)] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:234
skipping: [localhost] => (item={'key': 'mariadb', 'value': {'container_name': 'mariadb', 'group': 'mariadb_shard_0', 'enabled': True, 'image': 'quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble', 'volumes': ['/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'mariadb:/var/lib/mysql', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online'], 'timeout': '30'}, 'haproxy': {'mariadb_external_lb': {'enabled': False, 'mode': 'tcp', 'port': '3306', 'listen_port': '3306', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'custom_member_list': [' server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "migration_flag is defined",
    "item": {
        "key": "mariadb",
        "value": {
            "container_name": "mariadb",
            "dimensions": {},
            "enabled": true,
            "group": "mariadb_shard_0",
            "haproxy": {
                "mariadb_external_lb": {
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "custom_member_list": [
                        " server localhost localhost:3306 check port 3306 inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "listen_port": "3306",
                    "mode": "tcp",
                    "port": "3306"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "mariadb:/var/lib/mysql",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [mariadb : Wait for MariaDB] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/recover_cluster.yml:250
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [service-check : mariadb | Get container facts] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:3
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:26
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/check.yml:6
skipping: [localhost] => {
    "changed": false,
    "false_condition": "migration_flag is defined",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Create MariaDB volume] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340 `" && echo ansible-tmp-1765371761.0361648-249705-240247865719340="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpbns0cfql TO /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340/ /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ezrguzqldzykuocitjbcarlapdutovfd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371761.0361648-249705-240247865719340/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "create_volume",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "labels": {},
            "name": "mariadb",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false
        }
    },
    "result": false
}

TASK [mariadb : Divide hosts by their MariaDB volume availability] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:11
ok: [localhost] => {
    "add_group": "mariadb_shard_0_had_volume_True",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [mariadb : Establish whether the cluster has already existed] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:16
ok: [localhost] => {
    "ansible_facts": {
        "mariadb_cluster_exists": true
    },
    "changed": false
}

TASK [mariadb : Check MariaDB service port liveness] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:22
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388 `" && echo ansible-tmp-1765371762.2160268-249814-124036360352388="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/wait_for.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3kjif7tr TO /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388/AnsiballZ_wait_for.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388/ /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388/AnsiballZ_wait_for.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388/AnsiballZ_wait_for.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371762.2160268-249814-124036360352388/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "elapsed": 0,
    "invocation": {
        "module_args": {
            "active_connection_states": [
                "ESTABLISHED",
                "FIN_WAIT1",
                "FIN_WAIT2",
                "SYN_RECV",
                "SYN_SENT",
                "TIME_WAIT"
            ],
            "connect_timeout": 1,
            "delay": 0,
            "exclude_hosts": null,
            "host": "192.168.0.195",
            "msg": null,
            "path": null,
            "port": 3306,
            "search_regex": "MariaDB",
            "sleep": 1,
            "state": "started",
            "timeout": 10
        }
    },
    "match_groupdict": {},
    "match_groups": [],
    "path": null,
    "port": 3306,
    "search_regex": "MariaDB",
    "state": "started"
}

TASK [mariadb : Divide hosts by their MariaDB service port liveness] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:32
ok: [localhost] => {
    "add_group": "mariadb_shard_0_port_alive_True",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [mariadb : Fail on existing but stopped cluster] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:37
skipping: [localhost] => {
    "changed": false,
    "false_condition": "groups[mariadb_shard_group] | length > 1",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Check MariaDB service WSREP sync status] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:50
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976 `" && echo ansible-tmp-1765371763.2137537-249962-206348735369976="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2a0ns8r8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976/ /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-setmmyfkalmieocnxojwmcxiqfvxxrew ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371763.2137537-249962-206348735369976/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_query",
    "changed": false,
    "executed_queries": [
        "SHOW STATUS LIKE \"wsrep_local_state_comment\""
    ],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "login_db": "mysql",
            "login_host": "192.168.0.195",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root",
            "named_args": null,
            "positional_args": null,
            "query": "SHOW STATUS LIKE \"wsrep_local_state_comment\"",
            "single_transaction": false
        }
    },
    "query_result": [
        [
            {
                "Value": "Synced",
                "Variable_name": "wsrep_local_state_comment"
            }
        ]
    ],
    "rowcount": [
        1
    ]
}

TASK [mariadb : Extract MariaDB service WSREP sync status] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:65
ok: [localhost] => {
    "ansible_facts": {
        "mariadb_sync_status": "Synced"
    },
    "changed": false
}

TASK [mariadb : Divide hosts by their MariaDB service WSREP sync status] *******
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:69
ok: [localhost] => {
    "add_group": "mariadb_shard_0_sync_status_Synced",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [mariadb : Fail when MariaDB services are not synced across the whole cluster] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/lookup_cluster.yml:74
skipping: [localhost] => {
    "changed": false,
    "false_condition": "groups[mariadb_shard_group + '_sync_status_Synced'] is not defined or groups[mariadb_shard_group + '_port_alive_True'] | sort != groups[mariadb_shard_group + '_sync_status_Synced'] | sort",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/bootstrap.yml:4
skipping: [localhost] => {
    "changed": false,
    "false_condition": "not mariadb_cluster_exists",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : include_tasks] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/bootstrap.yml:9
skipping: [localhost] => {
    "changed": false,
    "false_condition": "mariadb_recover | default(False)",
    "skip_reason": "Conditional result was False"
}

PLAY [Restart mariadb services] ************************************************
skipping: no hosts matched

PLAY [Start mariadb services] **************************************************
skipping: no hosts matched

PLAY [Restart bootstrap mariadb service] ***************************************
skipping: no hosts matched

PLAY [Apply mariadb post-configuration] ****************************************

TASK [Include mariadb post-deploy.yml] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/mariadb.yml:82
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/register.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/check.yml
included: mariadb for localhost

TASK [mariadb : Creating shard root mysql user] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/register.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278 `" && echo ansible-tmp-1765371766.2666328-250171-232809104767278="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpc16zpupb TO /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278/ /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cvmqgxnqctpsnwadpomwxflxuiloxkpb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371766.2666328-250171-232809104767278/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_user",
    "changed": false,
    "invocation": {
        "module_args": {
            "append_privs": false,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "192.168.0.195",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root",
            "name": "root_shard_0",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "*.*:ALL,GRANT",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "root_shard_0"
        }
    },
    "msg": "User unchanged",
    "user": "root_shard_0"
}

TASK [mariadb : Creating mysql monitor user] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/register.yml:20
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767 `" && echo ansible-tmp-1765371768.755091-250348-217392630589767="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6wfew7k7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767/ /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-oxmnwdsqeiuxjfvoqdeselaoqwgzkoxo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371768.755091-250348-217392630589767/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "action": "mysql_user",
    "changed": true,
    "invocation": {
        "module_args": {
            "append_privs": false,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "192.168.0.195",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root",
            "name": "monitor",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "*.*:USAGE,REPLICATION CLIENT",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "monitor"
        }
    },
    "msg": "Privileges updated",
    "user": "monitor"
}

TASK [mariadb : Creating database backup user and setting permissions] *********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/register.yml:38
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mariabackup | bool",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Granting permissions on Mariabackup database to backup user] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/register.yml:58
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_mariabackup | bool",
    "skip_reason": "Conditional result was False"
}

TASK [service-check : mariadb | Get container facts] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968 `" && echo ansible-tmp-1765371771.4272056-250475-261751768992968="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container_facts.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpinmoyt7y TO /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968/AnsiballZ_kolla_container_facts.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968/ /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968/AnsiballZ_kolla_container_facts.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-npzyzmhgtdybsvfflavwjoobzzzkwcnh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968/AnsiballZ_kolla_container_facts.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371771.4272056-250475-261751768992968/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "containers": {
        "mariadb": {
            "AppArmorProfile": "docker-default",
            "Args": [
                "--",
                "kolla_start"
            ],
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "kolla_start"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "dumb-init",
                    "--"
                ],
                "Env": [
                    "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                    "KOLLA_SERVICE_NAME=mariadb",
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL=",
                    "MARIADB_VERSION=11.4"
                ],
                "Healthcheck": {
                    "Interval": 30000000000,
                    "Retries": 3,
                    "StartPeriod": 5000000000,
                    "Test": [
                        "CMD-SHELL",
                        "/usr/bin/healthcheck.sh --defaults-file /etc/mysql/healthcheck.cnf --connect --galera_online"
                    ],
                    "Timeout": 30000000000
                },
                "Hostname": "nics-VMware20-1",
                "Image": "quay.io/openstack.kolla/mariadb-server:master-ubuntu-noble",
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "mariadb-server",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                },
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "mysql",
                "Volumes": {
                    "/etc/localtime": {},
                    "/etc/timezone": {},
                    "/var/lib/kolla/config_files/": {},
                    "/var/lib/mysql": {},
                    "/var/log/kolla/": {}
                },
                "WorkingDir": ""
            },
            "Created": "2025-12-10T11:56:55.870545248Z",
            "Driver": "overlay2",
            "ExecIDs": null,
            "GraphDriver": {
                "Data": {
                    "ID": "c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c",
                    "LowerDir": "/var/lib/docker/overlay2/08429abc48f76670a15b4fcce3808b414991a9f5b842f9401efac59a9f6f715b-init/diff:/var/lib/docker/overlay2/5b09d6feeee0c8dd97cee4a5e5dab9772e263091380b2063478fbdedbce4bc7d/diff:/var/lib/docker/overlay2/a97a13a18c8eb4ba0c240b13a6fdceab47d16b3dac5c845fd58d8f5b33a20668/diff:/var/lib/docker/overlay2/fe6d2c06586067c9e16810e2cc78bffe2cab0cede132e7ccb8399386f9a57788/diff:/var/lib/docker/overlay2/e5f260f067b9c409d129c253497694c3cec35c5b5dcc11ead4bb322781d0c51f/diff:/var/lib/docker/overlay2/1e2ea693ff609660f6616bcf546c2a7f2093abeb66ec6d3b4f15c552b2909090/diff:/var/lib/docker/overlay2/bbe561e56689b616e72733f53c92339d01596cb266de38ba59a7717ae4e4a341/diff:/var/lib/docker/overlay2/3d5fdc4dcb2ceb66bb6b24019b5de7423867d577e081a674ed8ed2985680e1ed/diff:/var/lib/docker/overlay2/3e16f57773d6c348207476b83c595dd1b135a7a335e2339f01c8d445a0215802/diff:/var/lib/docker/overlay2/2551ed637628a24e188f6df0af49bedd7eb9801f48c5e57a8c74e0ff763b35f4/diff:/var/lib/docker/overlay2/075b3118d15e5da57874c69d057f97dcfdeca4c88b0dfd59d9615b29b9d3e1b7/diff:/var/lib/docker/overlay2/98e9864ce93870a62cadfd06fd3881ae74981bd61e05df779f0674bc3bb3061f/diff:/var/lib/docker/overlay2/001a92cf5d6afbdc79e6d8b3bc5317da91ce1453d6aadf2bfb4f7fd254050e8b/diff:/var/lib/docker/overlay2/1604567a607ad340ca8d2a0eaa5c3659165064a5516a49495b011a547edbc079/diff:/var/lib/docker/overlay2/4496e14e827fbd4634a35e8d6c16b379454fe712abc09ce29fbfcd622e630e76/diff:/var/lib/docker/overlay2/174f6b76ae2bd1497853714dc78c05d126ff4679d6cdf51f2c1c7ed418c93556/diff:/var/lib/docker/overlay2/c18f45b2f8e2681deeeb1fce34fbfd2c56f32b926584098b8ba1f139d083cc50/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/08429abc48f76670a15b4fcce3808b414991a9f5b842f9401efac59a9f6f715b/merged",
                    "UpperDir": "/var/lib/docker/overlay2/08429abc48f76670a15b4fcce3808b414991a9f5b842f9401efac59a9f6f715b/diff",
                    "WorkDir": "/var/lib/docker/overlay2/08429abc48f76670a15b4fcce3808b414991a9f5b842f9401efac59a9f6f715b/work"
                },
                "Name": "overlay2"
            },
            "HostConfig": {
                "AutoRemove": false,
                "Binds": [
                    "/etc/kolla/mariadb/:/var/lib/kolla/config_files/:ro",
                    "/etc/localtime:/etc/localtime:ro",
                    "/etc/timezone:/etc/timezone:ro",
                    "mariadb:/var/lib/mysql:rw",
                    "kolla_logs:/var/log/kolla/:rw"
                ],
                "BlkioDeviceReadBps": null,
                "BlkioDeviceReadIOps": null,
                "BlkioDeviceWriteBps": null,
                "BlkioDeviceWriteIOps": null,
                "BlkioWeight": 0,
                "BlkioWeightDevice": null,
                "CapAdd": null,
                "CapDrop": null,
                "Cgroup": "",
                "CgroupParent": "",
                "CgroupnsMode": "private",
                "ConsoleSize": [
                    0,
                    0
                ],
                "ContainerIDFile": "",
                "CpuCount": 0,
                "CpuPercent": 0,
                "CpuPeriod": 0,
                "CpuQuota": 0,
                "CpuRealtimePeriod": 0,
                "CpuRealtimeRuntime": 0,
                "CpuShares": 0,
                "CpusetCpus": "",
                "CpusetMems": "",
                "DeviceCgroupRules": null,
                "DeviceRequests": null,
                "Devices": null,
                "Dns": null,
                "DnsOptions": null,
                "DnsSearch": null,
                "ExtraHosts": null,
                "GroupAdd": null,
                "IOMaximumBandwidth": 0,
                "IOMaximumIOps": 0,
                "IpcMode": "private",
                "Isolation": "",
                "Links": null,
                "LogConfig": {
                    "Config": {
                        "max-file": "5",
                        "max-size": "50m"
                    },
                    "Type": "json-file"
                },
                "MaskedPaths": [
                    "/proc/acpi",
                    "/proc/asound",
                    "/proc/interrupts",
                    "/proc/kcore",
                    "/proc/keys",
                    "/proc/latency_stats",
                    "/proc/sched_debug",
                    "/proc/scsi",
                    "/proc/timer_list",
                    "/proc/timer_stats",
                    "/sys/devices/virtual/powercap",
                    "/sys/firmware"
                ],
                "Memory": 0,
                "MemoryReservation": 0,
                "MemorySwap": 0,
                "MemorySwappiness": null,
                "NanoCpus": 0,
                "NetworkMode": "host",
                "OomKillDisable": null,
                "OomScoreAdj": 0,
                "PidMode": "",
                "PidsLimit": null,
                "PortBindings": {},
                "Privileged": false,
                "PublishAllPorts": false,
                "ReadonlyPaths": [
                    "/proc/bus",
                    "/proc/fs",
                    "/proc/irq",
                    "/proc/sys",
                    "/proc/sysrq-trigger"
                ],
                "ReadonlyRootfs": false,
                "RestartPolicy": {
                    "MaximumRetryCount": 0,
                    "Name": "no"
                },
                "Runtime": "runc",
                "SecurityOpt": [],
                "ShmSize": 67108864,
                "UTSMode": "",
                "Ulimits": null,
                "UsernsMode": "",
                "VolumeDriver": "",
                "VolumesFrom": null
            },
            "HostnamePath": "/var/lib/docker/containers/c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c/hostname",
            "HostsPath": "/var/lib/docker/containers/c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c/hosts",
            "Id": "c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c",
            "Image": "sha256:ddcf6504aeee8be348bf47ea3fffbd226fda4621115833ca2837cd1e1ed2df69",
            "LogPath": "/var/lib/docker/containers/c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c/c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c-json.log",
            "MountLabel": "",
            "Mounts": [
                {
                    "Destination": "/var/lib/mysql",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "mariadb",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/mariadb/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/log/kolla",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "kolla_logs",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/lib/kolla/config_files",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/kolla/mariadb",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/localtime",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/localtime",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/timezone",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/timezone",
                    "Type": "bind"
                }
            ],
            "Name": "/mariadb",
            "NetworkSettings": {
                "Networks": {
                    "host": {
                        "Aliases": null,
                        "DNSNames": null,
                        "DriverOpts": null,
                        "EndpointID": "00eca8016c6921dc32978cddb5db26ffb432c146ea83eca5597dace110d05e2a",
                        "Gateway": "",
                        "GlobalIPv6Address": "",
                        "GlobalIPv6PrefixLen": 0,
                        "GwPriority": 0,
                        "IPAMConfig": null,
                        "IPAddress": "",
                        "IPPrefixLen": 0,
                        "IPv6Gateway": "",
                        "Links": null,
                        "MacAddress": "",
                        "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                    }
                },
                "Ports": {},
                "SandboxID": "2368361909e1d8decd719936d94fa304179f542a323eb7720fb87ab1e283ca42",
                "SandboxKey": "/var/run/docker/netns/default"
            },
            "Path": "dumb-init",
            "Platform": "linux",
            "ProcessLabel": "",
            "ResolvConfPath": "/var/lib/docker/containers/c676ad88f61f614c16782d8d59c487115cc00990870a76bade333185b58aee1c/resolv.conf",
            "RestartCount": 0,
            "State": {
                "Dead": false,
                "Error": "",
                "ExitCode": 0,
                "FinishedAt": "0001-01-01T00:00:00Z",
                "Health": {
                    "FailingStreak": 0,
                    "Status": "healthy"
                },
                "OOMKilled": false,
                "Paused": false,
                "Pid": 59736,
                "Restarting": false,
                "Running": true,
                "StartedAt": "2025-12-10T11:56:56.738238578Z",
                "Status": "running"
            }
        }
    },
    "invocation": {
        "module_args": {
            "action": "get_containers",
            "api_version": "auto",
            "args": {
                "get_all_containers": false
            },
            "container_engine": "docker",
            "name": [
                "mariadb"
            ]
        }
    },
    "result": false
}

TASK [service-check : mariadb | Fail if containers are missing or not running] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "missing_containers | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [service-check : mariadb | Fail if containers are unhealthy] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check/tasks/main.yml:26
skipping: [localhost] => {
    "changed": false,
    "false_condition": "unhealthy_containers | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [mariadb : Wait for MariaDB service to be ready through VIP] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/mariadb/tasks/check.yml:6
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634 `" && echo ansible-tmp-1765371772.870379-250575-230379594651634="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpdf9mdyn6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634/ /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pobdghqbkkoftykfifencqgdykpuuqcx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371772.870379-250575-230379594651634/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_query",
    "attempts": 1,
    "changed": false,
    "executed_queries": [
        "SHOW DATABASES;"
    ],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "login_db": null,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "named_args": null,
            "positional_args": null,
            "query": "SHOW DATABASES;",
            "single_transaction": false
        }
    },
    "query_result": [
        [
            {
                "Database": "glance"
            },
            {
                "Database": "information_schema"
            },
            {
                "Database": "keystone"
            },
            {
                "Database": "mysql"
            },
            {
                "Database": "nova"
            },
            {
                "Database": "nova_api"
            },
            {
                "Database": "nova_cell0"
            },
            {
                "Database": "performance_schema"
            },
            {
                "Database": "placement"
            },
            {
                "Database": "sys"
            }
        ]
    ],
    "rowcount": [
        10
    ]
}

TASK [Include mariadb post-upgrade.yml] ****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/mariadb.yml:88
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_action == 'upgrade'",
    "skip_reason": "Conditional result was False"
}

PLAY [Apply role memcached] ****************************************************

TASK [memcached : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/check-containers.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/deploy.yml for localhost

TASK [memcached : Ensuring config directories exist] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602 `" && echo ansible-tmp-1765371775.410749-250687-140927850387602="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp96wdqtwa TO /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602/ /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ozdvixxiohpasgykkdzeallbanrbkonl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371775.410749-250687-140927850387602/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=memcached) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/memcached"
        },
        "before": {
            "path": "/etc/kolla/memcached"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/memcached",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": "memcached",
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/memcached",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [memcached : Copying over config.json files for services] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/memcached/tasks/config.yml:13
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369 `" && echo ansible-tmp-1765371775.8756948-250716-262163213247369="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8y5mfbk2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/ /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dnrbxucgbpidswoxkexbqqwuueoiywfz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_r8gua7i TO /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/ /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hpmohhqafcrhasvhxisbsdaweulteiah ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371775.8756948-250716-262163213247369/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=memcached) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "54f4054e3706e74ebf957231788de6cc50ef230f",
    "dest": "/etc/kolla/memcached/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/memcached/config.json"
        },
        "before": {
            "path": "/etc/kolla/memcached/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "memcached.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/memcached/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/memcached/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "memcached",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/memcached/config.json",
    "size": 113,
    "state": "file",
    "uid": 1000
}

TASK [service-check-containers : memcached | Check containers] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000 `" && echo ansible-tmp-1765371776.7443373-250786-166187498885000="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2lf0lfkv TO /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000/ /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vypfiwvifdnvhowqhdrsdilnswfsuohy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371776.7443373-250786-166187498885000/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen memcached 11211"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/memcached:master-ubuntu-noble",
            "labels": {},
            "name": "memcached",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro"
            ]
        }
    },
    "item": {
        "key": "memcached",
        "value": {
            "container_name": "memcached",
            "dimensions": {},
            "enabled": true,
            "group": "memcached",
            "haproxy": {
                "memcached": {
                    "active_passive": true,
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "mode": "tcp",
                    "port": "11211"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen memcached 11211"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/memcached:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : memcached | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'memcached', 'value': {'container_name': 'memcached', 'image': 'quay.io/openstack.kolla/memcached:master-ubuntu-noble', 'enabled': True, 'group': 'memcached', 'volumes': ['/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen memcached 11211'], 'timeout': '30'}, 'haproxy': {'memcached': {'enabled': False, 'mode': 'tcp', 'port': '11211', 'frontend_tcp_extra': ['option clitcpka', 'timeout client 3600s'], 'backend_tcp_extra': ['option srvtcpka', 'timeout server 3600s'], 'active_passive': True}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "memcached",
        "value": {
            "container_name": "memcached",
            "dimensions": {},
            "enabled": true,
            "group": "memcached",
            "haproxy": {
                "memcached": {
                    "active_passive": true,
                    "backend_tcp_extra": [
                        "option srvtcpka",
                        "timeout server 3600s"
                    ],
                    "enabled": false,
                    "frontend_tcp_extra": [
                        "option clitcpka",
                        "timeout client 3600s"
                    ],
                    "mode": "tcp",
                    "port": "11211"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen memcached 11211"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/memcached:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/memcached/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

PLAY [Apply role prometheus] ***************************************************
skipping: no hosts matched

PLAY [Apply role prometheus-node-exporters] ************************************
skipping: no hosts matched

PLAY [Apply role iscsi] ********************************************************
skipping: no hosts matched

PLAY [Apply role multipathd] ***************************************************
skipping: no hosts matched

PLAY [Apply role rabbitmq] *****************************************************

TASK [rabbitmq : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/bootstrap.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/deploy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743 `" && echo ansible-tmp-1765371778.2397783-250861-204264334503743="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container_facts.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq9b0h6di TO /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743/AnsiballZ_kolla_container_facts.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743/ /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743/AnsiballZ_kolla_container_facts.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ndhdryvmthazglcoamudidggnzjveoqz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743/AnsiballZ_kolla_container_facts.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371778.2397783-250861-204264334503743/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "containers": {
        "rabbitmq": {
            "AppArmorProfile": "docker-default",
            "Args": [
                "--single-child",
                "--",
                "kolla_start"
            ],
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "kolla_start"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "dumb-init",
                    "--single-child",
                    "--"
                ],
                "Env": [
                    "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                    "RABBITMQ_CLUSTER_COOKIE=SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                    "RABBITMQ_LOG_DIR=/var/log/kolla/rabbitmq",
                    "KOLLA_SERVICE_NAME=rabbitmq",
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL="
                ],
                "Healthcheck": {
                    "Interval": 30000000000,
                    "Retries": 3,
                    "StartPeriod": 5000000000,
                    "Test": [
                        "CMD-SHELL",
                        "healthcheck_rabbitmq"
                    ],
                    "Timeout": 30000000000
                },
                "Hostname": "nics-VMware20-1",
                "Image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "rabbitmq",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                },
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "rabbitmq",
                "Volumes": {
                    "/etc/localtime": {},
                    "/etc/timezone": {},
                    "/var/lib/kolla/config_files/": {},
                    "/var/lib/rabbitmq/": {},
                    "/var/log/kolla/": {}
                },
                "WorkingDir": ""
            },
            "Created": "2025-12-10T11:57:44.059398863Z",
            "Driver": "overlay2",
            "ExecIDs": null,
            "GraphDriver": {
                "Data": {
                    "ID": "fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986",
                    "LowerDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c-init/diff:/var/lib/docker/overlay2/76d740905ba43ed4f1c4a7c0924deb47c1e93512a975c6a95eeada385903ac4c/diff:/var/lib/docker/overlay2/0c5a86523223e58a34bbb68175330838f41fa2c9b3d62d161c1032601b2a7293/diff:/var/lib/docker/overlay2/c8dbcca2500b1fe3f883ea3acf190d93e5440f9ce0de34124b9e3a1d2e5faf34/diff:/var/lib/docker/overlay2/285818adf49edb822533ff37fca91fcb07d2049a478cf4fa59cbe6d2da9997f8/diff:/var/lib/docker/overlay2/f2de1677424d1c067e4ed6569a3afa340ea7153e268666f8607d756060aaca35/diff:/var/lib/docker/overlay2/abe190e48193a93e463382ac72c196fbbb616767cb68892320df2fb44ac69e60/diff:/var/lib/docker/overlay2/49c45f94b161ca3491499c5f338c801fbad07dc37424d988365c6c01f38a830c/diff:/var/lib/docker/overlay2/549e20a195fb2eb4d998137b9230c7a3254d9c381c101d6a11dced13c6b9be9d/diff:/var/lib/docker/overlay2/f8dcd0f022236190cec8cb365e85e322573e54468fd39a7e224d585cb90827af/diff:/var/lib/docker/overlay2/010268ce0fbc141d02a927dc5c9fe8e1996c443f7d9ab27691426862b6b8b735/diff:/var/lib/docker/overlay2/606e3ef7b5787331390c6a9fe6b1d9c3e2f58798c5435a1b6b9ba5d755a18d22/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/merged",
                    "UpperDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/diff",
                    "WorkDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/work"
                },
                "Name": "overlay2"
            },
            "HostConfig": {
                "AutoRemove": false,
                "Binds": [
                    "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                    "/etc/localtime:/etc/localtime:ro",
                    "/etc/timezone:/etc/timezone:ro",
                    "rabbitmq:/var/lib/rabbitmq/:rw",
                    "kolla_logs:/var/log/kolla/:rw"
                ],
                "BlkioDeviceReadBps": null,
                "BlkioDeviceReadIOps": null,
                "BlkioDeviceWriteBps": null,
                "BlkioDeviceWriteIOps": null,
                "BlkioWeight": 0,
                "BlkioWeightDevice": null,
                "CapAdd": null,
                "CapDrop": null,
                "Cgroup": "",
                "CgroupParent": "",
                "CgroupnsMode": "private",
                "ConsoleSize": [
                    0,
                    0
                ],
                "ContainerIDFile": "",
                "CpuCount": 0,
                "CpuPercent": 0,
                "CpuPeriod": 0,
                "CpuQuota": 0,
                "CpuRealtimePeriod": 0,
                "CpuRealtimeRuntime": 0,
                "CpuShares": 0,
                "CpusetCpus": "",
                "CpusetMems": "",
                "DeviceCgroupRules": null,
                "DeviceRequests": null,
                "Devices": null,
                "Dns": null,
                "DnsOptions": null,
                "DnsSearch": null,
                "ExtraHosts": null,
                "GroupAdd": null,
                "IOMaximumBandwidth": 0,
                "IOMaximumIOps": 0,
                "IpcMode": "private",
                "Isolation": "",
                "Links": null,
                "LogConfig": {
                    "Config": {
                        "max-file": "5",
                        "max-size": "50m"
                    },
                    "Type": "json-file"
                },
                "MaskedPaths": [
                    "/proc/acpi",
                    "/proc/asound",
                    "/proc/interrupts",
                    "/proc/kcore",
                    "/proc/keys",
                    "/proc/latency_stats",
                    "/proc/sched_debug",
                    "/proc/scsi",
                    "/proc/timer_list",
                    "/proc/timer_stats",
                    "/sys/devices/virtual/powercap",
                    "/sys/firmware"
                ],
                "Memory": 0,
                "MemoryReservation": 0,
                "MemorySwap": 0,
                "MemorySwappiness": null,
                "NanoCpus": 0,
                "NetworkMode": "host",
                "OomKillDisable": null,
                "OomScoreAdj": 0,
                "PidMode": "",
                "PidsLimit": null,
                "PortBindings": {},
                "Privileged": false,
                "PublishAllPorts": false,
                "ReadonlyPaths": [
                    "/proc/bus",
                    "/proc/fs",
                    "/proc/irq",
                    "/proc/sys",
                    "/proc/sysrq-trigger"
                ],
                "ReadonlyRootfs": false,
                "RestartPolicy": {
                    "MaximumRetryCount": 0,
                    "Name": "no"
                },
                "Runtime": "runc",
                "SecurityOpt": [],
                "ShmSize": 67108864,
                "UTSMode": "",
                "Ulimits": null,
                "UsernsMode": "",
                "VolumeDriver": "",
                "VolumesFrom": null
            },
            "HostnamePath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/hostname",
            "HostsPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/hosts",
            "Id": "fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986",
            "Image": "sha256:6292873e4ae3f73832a8b800960a182ab2a559b73725d222cd2b638a0ae9d23b",
            "LogPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986-json.log",
            "MountLabel": "",
            "Mounts": [
                {
                    "Destination": "/var/lib/kolla/config_files",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/kolla/rabbitmq",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/localtime",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/localtime",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/timezone",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/timezone",
                    "Type": "bind"
                },
                {
                    "Destination": "/var/lib/rabbitmq",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "rabbitmq",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/rabbitmq/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/log/kolla",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "kolla_logs",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                    "Type": "volume"
                }
            ],
            "Name": "/rabbitmq",
            "NetworkSettings": {
                "Networks": {
                    "host": {
                        "Aliases": null,
                        "DNSNames": null,
                        "DriverOpts": null,
                        "EndpointID": "e83cf09d7c10b5eaf38d0a1bc6303ea05baaa705139a46a4e316d9cefa556e51",
                        "Gateway": "",
                        "GlobalIPv6Address": "",
                        "GlobalIPv6PrefixLen": 0,
                        "GwPriority": 0,
                        "IPAMConfig": null,
                        "IPAddress": "",
                        "IPPrefixLen": 0,
                        "IPv6Gateway": "",
                        "Links": null,
                        "MacAddress": "",
                        "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                    }
                },
                "Ports": {},
                "SandboxID": "05489fa4175a3d07c18eefd863952f0199b5933ef1065d76573442660158b425",
                "SandboxKey": "/var/run/docker/netns/default"
            },
            "Path": "dumb-init",
            "Platform": "linux",
            "ProcessLabel": "",
            "ResolvConfPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/resolv.conf",
            "RestartCount": 0,
            "State": {
                "Dead": false,
                "Error": "",
                "ExitCode": 0,
                "FinishedAt": "0001-01-01T00:00:00Z",
                "Health": {
                    "FailingStreak": 0,
                    "Status": "healthy"
                },
                "OOMKilled": false,
                "Paused": false,
                "Pid": 62481,
                "Restarting": false,
                "Running": true,
                "StartedAt": "2025-12-10T11:57:44.920869447Z",
                "Status": "running"
            }
        }
    },
    "invocation": {
        "module_args": {
            "action": "get_containers",
            "api_version": "auto",
            "args": {
                "get_all_containers": false
            },
            "container_engine": "docker",
            "name": [
                "rabbitmq"
            ]
        }
    },
    "result": false
}

TASK [rabbitmq : Get current RabbitMQ version] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml:20
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642 `" && echo ansible-tmp-1765371779.2292848-250927-187119806586642="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmposbiwjm2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642/ /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-yrywgtfsftcrwhkzkcbavgrdbicnnwrb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371779.2292848-250927-187119806586642/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "rabbitmq",
        "rabbitmqctl",
        "--version"
    ],
    "delta": "0:00:01.245138",
    "end": "2025-12-10 14:03:00.763951",
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec rabbitmq rabbitmqctl --version",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:02:59.518813",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "4.1.5",
    "stdout_lines": [
        "4.1.5"
    ]
}

TASK [rabbitmq : Get new RabbitMQ version] *************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml:26
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633 `" && echo ansible-tmp-1765371780.9843569-251044-231159394481633="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1zapm87c TO /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633/ /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uiuagcrejbhoalnbvquebjusyqxerlha ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371780.9843569-251044-231159394481633/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "rabbitmqctl --version",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "rabbitmq-version-check"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "labels": {},
            "name": "rabbitmq_version_check",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "",
    "stderr_lines": [],
    "stdout": "4.1.5\n",
    "stdout_lines": [
        "4.1.5"
    ]
}

TASK [rabbitmq : Check if running RabbitMQ is at most one version behind] ******
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml:53
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [rabbitmq : Catch when RabbitMQ is being downgraded] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/version-check.yml:75
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [rabbitmq : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/deploy.yml:4
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml for localhost

TASK [rabbitmq : Get container facts] ******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505 `" && echo ansible-tmp-1765371783.9271734-251302-59172923259505="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container_facts.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpg519oyt_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505/AnsiballZ_kolla_container_facts.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505/ /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505/AnsiballZ_kolla_container_facts.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xjodrgkwvlajtuvktzqnizzmhgadxung ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505/AnsiballZ_kolla_container_facts.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371783.9271734-251302-59172923259505/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "containers": {
        "rabbitmq": {
            "AppArmorProfile": "docker-default",
            "Args": [
                "--single-child",
                "--",
                "kolla_start"
            ],
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "kolla_start"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "dumb-init",
                    "--single-child",
                    "--"
                ],
                "Env": [
                    "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                    "RABBITMQ_CLUSTER_COOKIE=SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                    "RABBITMQ_LOG_DIR=/var/log/kolla/rabbitmq",
                    "KOLLA_SERVICE_NAME=rabbitmq",
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL="
                ],
                "Healthcheck": {
                    "Interval": 30000000000,
                    "Retries": 3,
                    "StartPeriod": 5000000000,
                    "Test": [
                        "CMD-SHELL",
                        "healthcheck_rabbitmq"
                    ],
                    "Timeout": 30000000000
                },
                "Hostname": "nics-VMware20-1",
                "Image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "rabbitmq",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                },
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "rabbitmq",
                "Volumes": {
                    "/etc/localtime": {},
                    "/etc/timezone": {},
                    "/var/lib/kolla/config_files/": {},
                    "/var/lib/rabbitmq/": {},
                    "/var/log/kolla/": {}
                },
                "WorkingDir": ""
            },
            "Created": "2025-12-10T11:57:44.059398863Z",
            "Driver": "overlay2",
            "ExecIDs": null,
            "GraphDriver": {
                "Data": {
                    "ID": "fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986",
                    "LowerDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c-init/diff:/var/lib/docker/overlay2/76d740905ba43ed4f1c4a7c0924deb47c1e93512a975c6a95eeada385903ac4c/diff:/var/lib/docker/overlay2/0c5a86523223e58a34bbb68175330838f41fa2c9b3d62d161c1032601b2a7293/diff:/var/lib/docker/overlay2/c8dbcca2500b1fe3f883ea3acf190d93e5440f9ce0de34124b9e3a1d2e5faf34/diff:/var/lib/docker/overlay2/285818adf49edb822533ff37fca91fcb07d2049a478cf4fa59cbe6d2da9997f8/diff:/var/lib/docker/overlay2/f2de1677424d1c067e4ed6569a3afa340ea7153e268666f8607d756060aaca35/diff:/var/lib/docker/overlay2/abe190e48193a93e463382ac72c196fbbb616767cb68892320df2fb44ac69e60/diff:/var/lib/docker/overlay2/49c45f94b161ca3491499c5f338c801fbad07dc37424d988365c6c01f38a830c/diff:/var/lib/docker/overlay2/549e20a195fb2eb4d998137b9230c7a3254d9c381c101d6a11dced13c6b9be9d/diff:/var/lib/docker/overlay2/f8dcd0f022236190cec8cb365e85e322573e54468fd39a7e224d585cb90827af/diff:/var/lib/docker/overlay2/010268ce0fbc141d02a927dc5c9fe8e1996c443f7d9ab27691426862b6b8b735/diff:/var/lib/docker/overlay2/606e3ef7b5787331390c6a9fe6b1d9c3e2f58798c5435a1b6b9ba5d755a18d22/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/merged",
                    "UpperDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/diff",
                    "WorkDir": "/var/lib/docker/overlay2/9eaa34b1d0687d66ae8852323323d09811a693ac36c90ee72f6868a311b8276c/work"
                },
                "Name": "overlay2"
            },
            "HostConfig": {
                "AutoRemove": false,
                "Binds": [
                    "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                    "/etc/localtime:/etc/localtime:ro",
                    "/etc/timezone:/etc/timezone:ro",
                    "rabbitmq:/var/lib/rabbitmq/:rw",
                    "kolla_logs:/var/log/kolla/:rw"
                ],
                "BlkioDeviceReadBps": null,
                "BlkioDeviceReadIOps": null,
                "BlkioDeviceWriteBps": null,
                "BlkioDeviceWriteIOps": null,
                "BlkioWeight": 0,
                "BlkioWeightDevice": null,
                "CapAdd": null,
                "CapDrop": null,
                "Cgroup": "",
                "CgroupParent": "",
                "CgroupnsMode": "private",
                "ConsoleSize": [
                    0,
                    0
                ],
                "ContainerIDFile": "",
                "CpuCount": 0,
                "CpuPercent": 0,
                "CpuPeriod": 0,
                "CpuQuota": 0,
                "CpuRealtimePeriod": 0,
                "CpuRealtimeRuntime": 0,
                "CpuShares": 0,
                "CpusetCpus": "",
                "CpusetMems": "",
                "DeviceCgroupRules": null,
                "DeviceRequests": null,
                "Devices": null,
                "Dns": null,
                "DnsOptions": null,
                "DnsSearch": null,
                "ExtraHosts": null,
                "GroupAdd": null,
                "IOMaximumBandwidth": 0,
                "IOMaximumIOps": 0,
                "IpcMode": "private",
                "Isolation": "",
                "Links": null,
                "LogConfig": {
                    "Config": {
                        "max-file": "5",
                        "max-size": "50m"
                    },
                    "Type": "json-file"
                },
                "MaskedPaths": [
                    "/proc/acpi",
                    "/proc/asound",
                    "/proc/interrupts",
                    "/proc/kcore",
                    "/proc/keys",
                    "/proc/latency_stats",
                    "/proc/sched_debug",
                    "/proc/scsi",
                    "/proc/timer_list",
                    "/proc/timer_stats",
                    "/sys/devices/virtual/powercap",
                    "/sys/firmware"
                ],
                "Memory": 0,
                "MemoryReservation": 0,
                "MemorySwap": 0,
                "MemorySwappiness": null,
                "NanoCpus": 0,
                "NetworkMode": "host",
                "OomKillDisable": null,
                "OomScoreAdj": 0,
                "PidMode": "",
                "PidsLimit": null,
                "PortBindings": {},
                "Privileged": false,
                "PublishAllPorts": false,
                "ReadonlyPaths": [
                    "/proc/bus",
                    "/proc/fs",
                    "/proc/irq",
                    "/proc/sys",
                    "/proc/sysrq-trigger"
                ],
                "ReadonlyRootfs": false,
                "RestartPolicy": {
                    "MaximumRetryCount": 0,
                    "Name": "no"
                },
                "Runtime": "runc",
                "SecurityOpt": [],
                "ShmSize": 67108864,
                "UTSMode": "",
                "Ulimits": null,
                "UsernsMode": "",
                "VolumeDriver": "",
                "VolumesFrom": null
            },
            "HostnamePath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/hostname",
            "HostsPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/hosts",
            "Id": "fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986",
            "Image": "sha256:6292873e4ae3f73832a8b800960a182ab2a559b73725d222cd2b638a0ae9d23b",
            "LogPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986-json.log",
            "MountLabel": "",
            "Mounts": [
                {
                    "Destination": "/var/lib/kolla/config_files",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/kolla/rabbitmq",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/localtime",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/localtime",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/timezone",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/timezone",
                    "Type": "bind"
                },
                {
                    "Destination": "/var/lib/rabbitmq",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "rabbitmq",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/rabbitmq/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/log/kolla",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "kolla_logs",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                    "Type": "volume"
                }
            ],
            "Name": "/rabbitmq",
            "NetworkSettings": {
                "Networks": {
                    "host": {
                        "Aliases": null,
                        "DNSNames": null,
                        "DriverOpts": null,
                        "EndpointID": "e83cf09d7c10b5eaf38d0a1bc6303ea05baaa705139a46a4e316d9cefa556e51",
                        "Gateway": "",
                        "GlobalIPv6Address": "",
                        "GlobalIPv6PrefixLen": 0,
                        "GwPriority": 0,
                        "IPAMConfig": null,
                        "IPAddress": "",
                        "IPPrefixLen": 0,
                        "IPv6Gateway": "",
                        "Links": null,
                        "MacAddress": "",
                        "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                    }
                },
                "Ports": {},
                "SandboxID": "05489fa4175a3d07c18eefd863952f0199b5933ef1065d76573442660158b425",
                "SandboxKey": "/var/run/docker/netns/default"
            },
            "Path": "dumb-init",
            "Platform": "linux",
            "ProcessLabel": "",
            "ResolvConfPath": "/var/lib/docker/containers/fcbca5a5049fd572d4d7be3bec2a4c707f8e5237741ca43b800dae310ba22986/resolv.conf",
            "RestartCount": 0,
            "State": {
                "Dead": false,
                "Error": "",
                "ExitCode": 0,
                "FinishedAt": "0001-01-01T00:00:00Z",
                "Health": {
                    "FailingStreak": 0,
                    "Status": "healthy"
                },
                "OOMKilled": false,
                "Paused": false,
                "Pid": 62481,
                "Restarting": false,
                "Running": true,
                "StartedAt": "2025-12-10T11:57:44.920869447Z",
                "Status": "running"
            }
        }
    },
    "invocation": {
        "module_args": {
            "action": "get_containers",
            "api_version": "auto",
            "args": {
                "get_all_containers": false
            },
            "container_engine": "docker",
            "name": [
                "rabbitmq"
            ]
        }
    },
    "result": false
}

TASK [rabbitmq : List RabbitMQ policies] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443 `" && echo ansible-tmp-1765371784.9741263-251348-59020032272443="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpeo8y8zfu TO /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443/ /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vbgxnkqmbzhijrdwkippwpmruuybcfgv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371784.9741263-251348-59020032272443/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "rabbitmq",
        "rabbitmqctl",
        "list_policies",
        "--silent"
    ],
    "delta": "0:00:01.191064",
    "end": "2025-12-10 14:03:06.490335",
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec rabbitmq rabbitmqctl list_policies --silent",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:03:05.299271",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "",
    "stdout_lines": []
}

TASK [rabbitmq : Remove ha-all policy from RabbitMQ] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml:25
skipping: [localhost] => {
    "changed": false,
    "false_condition": "'ha-all' in rabbitmq_policies.stdout",
    "skip_reason": "Conditional result was False"
}

TASK [rabbitmq : Ensuring config directories exist] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531 `" && echo ansible-tmp-1765371786.8376656-251511-271594609066531="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwfun9lvq TO /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531/ /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-blhftznribomcecmhpbozutotfebyeft ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371786.8376656-251511-271594609066531/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/rabbitmq",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": "rabbitmq",
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/rabbitmq",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [rabbitmq : Copying over config.json files for services] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:12
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971 `" && echo ansible-tmp-1765371787.3424113-251539-62952013474971="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpil5ivt_i TO /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/ /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pvsafmrrxpxytgyuntmxajshbhthfiek ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpp2t7tnsi TO /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/ /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kykbizmsisvsngvkqdshaoqytqtkjxvf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371787.3424113-251539-62952013474971/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "3ec804b73f757fcd16ab3c9867bdb84239cedff0",
    "dest": "/etc/kolla/rabbitmq/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/config.json"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rabbitmq.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": "rabbitmq",
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/config.json",
    "size": 1581,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over rabbitmq-env.conf] *******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:20
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862 `" && echo ansible-tmp-1765371788.151612-251600-119091157094862="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpem85z6q6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/ /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uoscdkxvwhlzksfudzkrsynjnekdnndx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpyd3jwc4g TO /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/ /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lbkgwiqlefbhmsbdowqdnjpnnukjwnjj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371788.151612-251600-119091157094862/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "2c14b65ac58aeadff5c221cacbcf65397573f535",
    "dest": "/etc/kolla/rabbitmq/rabbitmq-env.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/rabbitmq-env.conf"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/rabbitmq-env.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rabbitmq-env.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/rabbitmq-env.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/rabbitmq-env.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/rabbitmq-env.conf",
    "size": 424,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over rabbitmq.conf] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:34
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574 `" && echo ansible-tmp-1765371789.0784857-251673-50848624834574="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpgff8d03l TO /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/ /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rvwlixeloisuzjawluhltchhkyqtnvxb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzuifc2ql TO /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/ /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zuhdxffirlynugspuetlxfrbujarnofg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371789.0784857-251673-50848624834574/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq.conf.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "ac31a6f20ffd696a04ddc450a7ab18684f0c6622",
    "dest": "/etc/kolla/rabbitmq/rabbitmq.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/rabbitmq.conf"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/rabbitmq.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "rabbitmq.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/rabbitmq.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/rabbitmq.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/rabbitmq.conf.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/rabbitmq.conf",
    "size": 524,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over erl_inetrc] **************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:48
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035 `" && echo ansible-tmp-1765371790.0110471-251777-257957256061035="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp11hidgyx TO /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/ /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jnfvnorraeshsvfmvhfkgbpmgtnythdq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxc02vpi_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/ /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-edxxohqsojgiinhjlkpsrxlteitjmvph ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371790.0110471-251777-257957256061035/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/erl_inetrc.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "adc83b19e793491b1c6ea0fd8b46cd9f32e592fc",
    "dest": "/etc/kolla/rabbitmq/erl_inetrc",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/erl_inetrc"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/erl_inetrc"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "erl_inetrc.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/erl_inetrc",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/erl_inetrc",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/erl_inetrc.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/erl_inetrc",
    "size": 1,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over advanced.config] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:62
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759 `" && echo ansible-tmp-1765371790.7880166-251855-254306585289759="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqwmbq4__ TO /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/ /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ypbeymndhggsiigeuytipmyvbqvrkywv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmppdcf69v1 TO /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/ /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rtjusczokknofkpinuddbhzpajdmhhmd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371790.7880166-251855-254306585289759/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/advanced.config.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "f9286656284341ed38811fb7bc8ed34901b32721",
    "dest": "/etc/kolla/rabbitmq/advanced.config",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/advanced.config"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/advanced.config"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "advanced.config.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/advanced.config",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/advanced.config",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/advanced.config.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/advanced.config",
    "size": 140,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over definitions.json] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:76
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957 `" && echo ansible-tmp-1765371791.6168156-251910-277350684366957="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpegtuzfu8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/ /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cokclxnecpunolyxbjohmlcytfsfoxih ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7up1siwy TO /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/ /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-afgrwulitlxzdndvnmhvaaqjnfbhousv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371791.6168156-251910-277350684366957/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/definitions.json.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "9e120e51ab95122d676c32ad6d18916392fb4194",
    "dest": "/etc/kolla/rabbitmq/definitions.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/definitions.json"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/definitions.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "definitions.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/definitions.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/definitions.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/definitions.json.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/definitions.json",
    "size": 292,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : Copying over enabled_plugins] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:90
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349 `" && echo ansible-tmp-1765371792.4181662-251969-11757108399349="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9qobu01x TO /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/ /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gicvqufzkpaybouyepgswzqolohplgqf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxwxv3q4g TO /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/ /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jpmuiivxkbfqlqocjsktyzxecgmrrnfm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371792.4181662-251969-11757108399349/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/enabled_plugins.j2) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "5513484669adbdca60563f2ebe967b0aaa294ae4",
    "dest": "/etc/kolla/rabbitmq/enabled_plugins",
    "diff": {
        "after": {
            "path": "/etc/kolla/rabbitmq/enabled_plugins"
        },
        "before": {
            "path": "/etc/kolla/rabbitmq/enabled_plugins"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "enabled_plugins.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/rabbitmq/enabled_plugins",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/rabbitmq/enabled_plugins",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/templates/enabled_plugins.j2",
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/rabbitmq/enabled_plugins",
    "size": 23,
    "state": "file",
    "uid": 1000
}

TASK [rabbitmq : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/config.yml:104
skipping: [localhost] => {
    "changed": false,
    "false_condition": "rabbitmq_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [service-check-containers : rabbitmq | Check containers] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911 `" && echo ansible-tmp-1765371793.3808138-252063-177698306940911="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp50jvy9rd TO /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911/ /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iweihaumrihfuzjxnkozpemykupwmiyc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371793.3808138-252063-177698306940911/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "labels": {},
            "name": "rabbitmq",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": "rabbitmq",
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : rabbitmq | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'rabbitmq', 'value': {'container_name': 'rabbitmq', 'group': 'rabbitmq', 'enabled': True, 'image': 'quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble', 'bootstrap_environment': {'KOLLA_BOOTSTRAP': None, 'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'environment': {'KOLLA_CONFIG_STRATEGY': 'COPY_ALWAYS', 'RABBITMQ_CLUSTER_COOKIE': 'SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z', 'RABBITMQ_LOG_DIR': '/var/log/kolla/rabbitmq'}, 'volumes': ['/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'rabbitmq:/var/lib/rabbitmq/', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_rabbitmq'], 'timeout': '30'}, 'haproxy': {'rabbitmq_management': {'enabled': 'yes', 'mode': 'http', 'port': '15672', 'host_group': 'rabbitmq'}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "rabbitmq",
        "value": {
            "bootstrap_environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "container_name": "rabbitmq",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "RABBITMQ_CLUSTER_COOKIE": "SWhx1NmKGuZamTRPlqShGTMgmN2bBsXc26Wo9U6z",
                "RABBITMQ_LOG_DIR": "/var/log/kolla/rabbitmq"
            },
            "group": "rabbitmq",
            "haproxy": {
                "rabbitmq_management": {
                    "enabled": "yes",
                    "host_group": "rabbitmq",
                    "mode": "http",
                    "port": "15672"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_rabbitmq"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/rabbitmq:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/rabbitmq/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "rabbitmq:/var/lib/rabbitmq/",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [rabbitmq : Creating rabbitmq volume] *************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943 `" && echo ansible-tmp-1765371794.6823444-252150-27278232265943="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8i98ypyn TO /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943/ /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qsukxwvyfkojznasdqrsonjcaojhytzq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371794.6823444-252150-27278232265943/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "create_volume",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "labels": {},
            "name": "rabbitmq",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false
        }
    },
    "result": false
}

TASK [rabbitmq : Running RabbitMQ bootstrap container] *************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/bootstrap.yml:10
skipping: [localhost] => {
    "changed": false,
    "false_condition": "rabbitmq_volume is changed",
    "skip_reason": "Conditional result was False"
}

PLAY [Restart rabbitmq services] ***********************************************
skipping: no hosts matched

PLAY [Apply rabbitmq post-configuration] ***************************************

TASK [Include rabbitmq post-deploy.yml] ****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/rabbitmq.yml:63
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/feature-flags.yml
included: rabbitmq for localhost

TASK [rabbitmq : Enable all stable feature flags] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/rabbitmq/tasks/feature-flags.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609 `" && echo ansible-tmp-1765371795.8341324-252253-71740897335609="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmcqtt9at TO /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609/ /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jtgyxanhymipexjqwegwjrwdwlpqcxtf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371795.8341324-252253-71740897335609/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "rabbitmq",
        "rabbitmqctl",
        "enable_feature_flag",
        "all"
    ],
    "delta": "0:00:01.368400",
    "end": "2025-12-10 14:03:17.665087",
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec rabbitmq rabbitmqctl enable_feature_flag all",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:03:16.296687",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Enabling all feature flags ...",
    "stdout_lines": [
        "Enabling all feature flags ..."
    ]
}

PLAY [Apply role etcd] *********************************************************
skipping: no hosts matched

PLAY [Apply role keystone] *****************************************************

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/register.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml for localhost

TASK [keystone : Ensuring config directories exist] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188 `" && echo ansible-tmp-1765371798.2694094-252562-10044335006188="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfnzgmtb9 TO /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188/ /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ajolxakvkzcctddhykbpexovupbhvhxj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371798.2694094-252562-10044335006188/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone"
        },
        "before": {
            "path": "/etc/kolla/keystone"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/keystone",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/keystone",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344 `" && echo ansible-tmp-1765371798.6739995-252562-188229512730344="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2q27sug3 TO /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344/ /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dehtwhnlaskygxbmduxwelxfsqfkzbsd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371798.6739995-252562-188229512730344/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/keystone-fernet",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/keystone-fernet",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245 `" && echo ansible-tmp-1765371799.1033437-252562-119606006049245="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq1zyio0b TO /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245/ /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-leywljcwweumgxzbzyltnkljheyzhhka ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371799.1033437-252562-119606006049245/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-ssh"
        },
        "before": {
            "path": "/etc/kolla/keystone-ssh"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/keystone-ssh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/keystone-ssh",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [keystone : Check if policies shall be overwritten] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [keystone : Set keystone policy file] *************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:24
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_policy.results | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Check if Keystone domain-specific config is supplied] *********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:31
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583 `" && echo ansible-tmp-1765371799.875359-252751-199536224367583="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptqflon1t TO /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583/ /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371799.875359-252751-199536224367583/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_mime": true,
            "path": "/etc/kolla/config/keystone/domains"
        }
    },
    "stat": {
        "exists": false
    }
}

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:38
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Copying over config.json files for services] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:42
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506 `" && echo ansible-tmp-1765371800.704448-252817-211565615274506="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfs9yy5z2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/ /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ysijwczpgsxjhmvkyextvrqlpqecpovd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmg4jwxct TO /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/ /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dunequxqqbfmphbnrkozwnrsroxkikeq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371800.704448-252817-211565615274506/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "d7383696ad5fa83d69202a8902de68d05558982f",
    "dest": "/etc/kolla/keystone/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone/config.json"
        },
        "before": {
            "path": "/etc/kolla/keystone/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keystone.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone/config.json",
    "size": 1666,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396 `" && echo ansible-tmp-1765371801.4914985-252817-200946429226396="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9_adac69 TO /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/ /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bczvxjjhnnuvvofpclzzlkonwnlsqwnw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpt3u7i1tu TO /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/ /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-afkrxewcgeihdocmyvvdimrmoctahcps ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371801.4914985-252817-200946429226396/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "bdebf3b39ca9e2064e8429dc7c4f82090fbc45a1",
    "dest": "/etc/kolla/keystone-fernet/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/config.json"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keystone-fernet.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/config.json",
    "size": 1791,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650 `" && echo ansible-tmp-1765371802.3052256-252817-126396013352650="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpj0uq_6oh TO /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/ /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kenlhckhpamhophtlloqbuqwhcacehmu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpb3yjt8fv TO /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/ /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cskkezteqvbeokgwboqmrodxpppmlgoy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371802.3052256-252817-126396013352650/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "242021c29c9d7b7295c04c7e1db3b00a86335e77",
    "dest": "/etc/kolla/keystone-ssh/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-ssh/config.json"
        },
        "before": {
            "path": "/etc/kolla/keystone-ssh/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keystone-ssh.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-ssh/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-ssh/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-ssh/config.json",
    "size": 625,
    "state": "file",
    "uid": 1000
}

TASK [keystone : Copying over keystone.conf] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:50
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904 `" && echo ansible-tmp-1765371803.3675742-253125-70770689416904="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp45qn56jp TO /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/ /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qflnbxtoulodcotoktjhrakflgjymdcw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpripw1vgx TO /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/ /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ybvlyorbbrcjqdgsegzhkiaowgcmahqa ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371803.3675742-253125-70770689416904/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "e3418a1c9f1626f7cfc4b4abd783c923eed6c3e6",
    "dest": "/etc/kolla/keystone/keystone.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone/keystone.conf"
        },
        "before": {
            "path": "/etc/kolla/keystone/keystone.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone/keystone.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone/keystone.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/keystone.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/keystone.conf",
                "/etc/kolla/config/keystone/keystone.conf",
                "/etc/kolla/config/keystone/localhost/keystone.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpa81dijs1/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone/keystone.conf",
    "size": 1001,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525 `" && echo ansible-tmp-1765371804.3047237-253125-236016187700525="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq3skp8_2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/ /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qxunofeugwpjdlraxlxmithwhpycfixh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd3gzhkk0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/ /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-opfbywzevrlefwiypvnijspbczumwmip ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371804.3047237-253125-236016187700525/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "2f501519b6aecf4ad67b5caf0241d7ea1715847d",
    "dest": "/etc/kolla/keystone-fernet/keystone.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/keystone.conf"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/keystone.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/keystone.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/keystone.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/keystone.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/keystone.conf",
                "/etc/kolla/config/keystone/keystone-fernet.conf",
                "/etc/kolla/config/keystone/localhost/keystone.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpsy6y28lv/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/keystone.conf",
    "size": 1002,
    "state": "file",
    "uid": 1000
}
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key in [ \"keystone\", \"keystone-fernet\" ]",
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Copying keystone-startup script for keystone] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:67
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186 `" && echo ansible-tmp-1765371805.588117-253238-120874808123186="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpa8byr748 TO /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/ /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-trzneyelkifhzihcyxeuwfxojgbcybht ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi0v8qdfe TO /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/ /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dwrqomcsnuvtqgrgsvipdheseuddviqx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371805.588117-253238-120874808123186/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "1a3d5e6d37fec818411a57fec7a5320fa5f3bc9c",
    "dest": "/etc/kolla/keystone/keystone-startup.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone/keystone-startup.sh"
        },
        "before": {
            "path": "/etc/kolla/keystone/keystone-startup.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "keystone-startup.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone/keystone-startup.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone/keystone-startup.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone/keystone-startup.sh",
    "size": 574,
    "state": "file",
    "uid": 1000
}

TASK [keystone : Create Keystone domain-specific config directory] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:77
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_domain_directory.stat.exists",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Get file list in custom domains folder] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:89
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_domain_directory.stat.exists",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Copying Keystone Domain specific settings] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:98
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [keystone : Copying over existing policy file] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:112
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "keystone_policy_file is defined",
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "keystone_policy_file is defined",
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key in [ \"keystone\", \"keystone-fernet\" ]",
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:123
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_enable_federation_openid | bool",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Copying over wsgi-keystone.conf] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:127
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/wsgi-keystone.conf.j2)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "keystone_wsgi_provider == \"apache\"",
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/wsgi-keystone.conf.j2",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [Configure uWSGI for Keystone] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:143
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over keystone uWSGI config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-uwsgi-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615 `" && echo ansible-tmp-1765371807.7969556-253334-207657678868615="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjsr2x3q2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/ /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dbmfbjfvselvkejukqipxxchebonrmhh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx0xn6ddq TO /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/ /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-snxrbqsugrkxnxnvxfrenarkepagwihe ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371807.7969556-253334-207657678868615/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "0d5baf0a9be5b9dd395305c891228d54f7b402c1",
    "dest": "/etc/kolla/keystone/keystone-uwsgi.ini",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone/keystone-uwsgi.ini"
        },
        "before": {
            "path": "/etc/kolla/keystone/keystone-uwsgi.ini"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "uwsgi.ini.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone/keystone-uwsgi.ini",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone/keystone-uwsgi.ini",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone/keystone-uwsgi.ini",
    "size": 626,
    "state": "file",
    "uid": 1000
}

TASK [keystone : Copying over httpd-keystone.conf] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:165
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/httpd-keystone.conf.j2)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service | service_enabled_and_mapped_to_host",
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/templates/httpd-keystone.conf.j2",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [keystone : Checking whether keystone-paste.ini file exists] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:181
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794 `" && echo ansible-tmp-1765371809.4255137-253407-11833408206794="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpeqlwsvpj TO /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794/ /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371809.4255137-253407-11833408206794/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_mime": true,
            "path": "/etc/kolla/config/keystone/keystone-paste.ini"
        }
    },
    "stat": {
        "exists": false
    }
}

TASK [keystone : Copying over keystone-paste.ini] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:191
skipping: [localhost] => {
    "changed": false,
    "false_condition": "check_keystone_paste_ini.stat.exists",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Generate the required cron jobs for the node] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:203
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338 `" && echo ansible-tmp-1765371810.1246023-253434-78751000208338="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpc8f27qum TO /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338/ /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371810.1246023-253434-78751000208338/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "/home/nics/openstack_venv/bin/python",
        "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/files/fernet_rotate_cron_generator.py",
        "-t",
        "4320",
        "-i",
        "0",
        "-n",
        "1"
    ],
    "delta": "0:00:00.048898",
    "end": "2025-12-10 14:03:30.468406",
    "invocation": {
        "module_args": {
            "_raw_params": "/home/nics/openstack_venv/bin/python /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/files/fernet_rotate_cron_generator.py -t 4320 -i 0 -n 1\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:03:30.419508",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "{\"cron_jobs\": [{\"min\": 0, \"hour\": 0, \"day\": 0}, {\"min\": 0, \"hour\": 0, \"day\": 3}], \"failed\": false, \"changed\": false}",
    "stdout_lines": [
        "{\"cron_jobs\": [{\"min\": 0, \"hour\": 0, \"day\": 0}, {\"min\": 0, \"hour\": 0, \"day\": 3}], \"failed\": false, \"changed\": false}"
    ]
}

TASK [keystone : Set fact with the generated cron jobs for building the crontab later] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:215
ok: [localhost] => {
    "ansible_facts": {
        "cron_jobs": [
            {
                "day": 0,
                "hour": 0,
                "min": 0
            },
            {
                "day": 3,
                "hour": 0,
                "min": 0
            }
        ]
    },
    "changed": false
}

TASK [keystone : Copying files for keystone-fernet] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:220
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068 `" && echo ansible-tmp-1765371810.910952-253471-194761057510068="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqf0cvifa TO /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/ /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dhxitagoavnltbpsdrzpjskpnwmnfdbl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4vdbkvtt TO /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/ /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jikwbtkrvpncfyugavtbromppeoddztv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371810.910952-253471-194761057510068/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'crontab.j2', 'dest': 'crontab'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "c35457021232ff7544b011e05b3cddd64bf3b284",
    "dest": "/etc/kolla/keystone-fernet/crontab",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/crontab"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/crontab"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "crontab.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/crontab",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/crontab",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "crontab",
        "src": "crontab.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/crontab",
    "size": 116,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287 `" && echo ansible-tmp-1765371811.7768147-253471-189342624089287="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkawlt37g TO /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/ /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-neereozfdmknrcfrukixyhfrcvaiwmab ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6q82y7eo TO /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/ /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-urjgnocnpbjssjvokrvkiakrtpxnckju ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371811.7768147-253471-189342624089287/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'fernet-rotate.sh.j2', 'dest': 'fernet-rotate.sh'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "8bb1309479600c09d62dde0d9f3a152399d234a1",
    "dest": "/etc/kolla/keystone-fernet/fernet-rotate.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/fernet-rotate.sh"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/fernet-rotate.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fernet-rotate.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/fernet-rotate.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/fernet-rotate.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "fernet-rotate.sh",
        "src": "fernet-rotate.sh.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/fernet-rotate.sh",
    "size": 193,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055 `" && echo ansible-tmp-1765371812.5906758-253471-126897071512055="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpw9cpjwd8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/ /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xocdvbycrzsuyfyvyjdaepxkadnozsrz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8ty27rad TO /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/ /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ecfsoxxqsyxcazjljhfhwvtwygxjssvg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371812.5906758-253471-126897071512055/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'fernet-node-sync.sh.j2', 'dest': 'fernet-node-sync.sh'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "175ab1a82cbec4a4327b45756bfb54d633b1b449",
    "dest": "/etc/kolla/keystone-fernet/fernet-node-sync.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/fernet-node-sync.sh"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/fernet-node-sync.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fernet-node-sync.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/fernet-node-sync.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/fernet-node-sync.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "fernet-node-sync.sh",
        "src": "fernet-node-sync.sh.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/fernet-node-sync.sh",
    "size": 824,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978 `" && echo ansible-tmp-1765371813.4306843-253471-265189000588978="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpn8dcb2t2 TO /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/ /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ctuohstpdyncahzpbuygsajypfkldrzg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx9pqmuf9 TO /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/ /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ahsemnjwinftewswshbvbpfhqpamuyic ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371813.4306843-253471-265189000588978/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'fernet-push.sh.j2', 'dest': 'fernet-push.sh'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "549580f3a3ba7e9a0404cb134aea9ed921508e6e",
    "dest": "/etc/kolla/keystone-fernet/fernet-push.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/fernet-push.sh"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/fernet-push.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fernet-push.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/fernet-push.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/fernet-push.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "fernet-push.sh",
        "src": "fernet-push.sh.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/fernet-push.sh",
    "size": 247,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774 `" && echo ansible-tmp-1765371814.2919269-253471-167702813058774="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_a9zirnj TO /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/ /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kbspwucbemehflfblqhdulkpkepglmqc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmps5vpx6d7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/ /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fdbwbknrjxktnkndlvggymmlrkgzrpfg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371814.2919269-253471-167702813058774/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'fernet-healthcheck.sh.j2', 'dest': 'fernet-healthcheck.sh'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "22ff21c5dae0d56b7b502267554e490358ba481f",
    "dest": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "fernet-healthcheck.sh.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "fernet-healthcheck.sh",
        "src": "fernet-healthcheck.sh.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/fernet-healthcheck.sh",
    "size": 129,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207 `" && echo ansible-tmp-1765371815.2150989-253471-224264740685207="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6wr8iiib TO /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/ /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xfzrlcvryyvqychbzlourdukviigqgcl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7z7abdcg TO /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/ /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wortbazromviebxyumhgutipzzifcqdw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371815.2150989-253471-224264740685207/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "a965705a9e31760c6290ee93e9826c596bc8f496",
    "dest": "/etc/kolla/keystone-fernet/id_rsa",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/id_rsa"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/id_rsa"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "id_rsa",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/id_rsa",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/id_rsa",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "id_rsa",
        "src": "id_rsa"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/id_rsa",
    "size": 3272,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874 `" && echo ansible-tmp-1765371816.0795364-253471-164918235096874="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfk87jeio TO /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/ /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nrksvajjdcejloxytvevrptrgdnfjcxl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9whamph4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/ /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jagxjuzlcvdfjpqscjjpivksiurmygwg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371816.0795364-253471-164918235096874/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "fec4cb810039347549252f3408ad960ae3791230",
    "dest": "/etc/kolla/keystone-fernet/ssh_config",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-fernet/ssh_config"
        },
        "before": {
            "path": "/etc/kolla/keystone-fernet/ssh_config"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "ssh_config.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-fernet/ssh_config",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-fernet/ssh_config",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "ssh_config",
        "src": "ssh_config.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-fernet/ssh_config",
    "size": 77,
    "state": "file",
    "uid": 1000
}

TASK [keystone : Copying files for keystone-ssh] *******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/config.yml:239
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148 `" && echo ansible-tmp-1765371817.1163504-253929-165673861833148="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7wbpluv4 TO /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/ /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-aanoinxwrwhvqchtixhgxmxteuwzsjba ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmyafot03 TO /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/ /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uqpykiqocjfoewoyxtgfpumcvbvpxuvr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371817.1163504-253929-165673861833148/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "aa54ad130c813e05ffc68146973f05eb4724455d",
    "dest": "/etc/kolla/keystone-ssh/sshd_config",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-ssh/sshd_config"
        },
        "before": {
            "path": "/etc/kolla/keystone-ssh/sshd_config"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "sshd_config.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-ssh/sshd_config",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-ssh/sshd_config",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "sshd_config",
        "src": "sshd_config.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-ssh/sshd_config",
    "size": 74,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846 `" && echo ansible-tmp-1765371817.9607735-253929-18747032843846="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1ovo4bro TO /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/ /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ugcnovwdirsldqdiqbwterladlebaweo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq74ewvnp TO /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/ /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zmieymbllqezltruhpdlytndgviojbdx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371817.9607735-253929-18747032843846/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "73e4eb923c1849a77a7fa5c54e66db5651c1a92c",
    "dest": "/etc/kolla/keystone-ssh/id_rsa.pub",
    "diff": {
        "after": {
            "path": "/etc/kolla/keystone-ssh/id_rsa.pub"
        },
        "before": {
            "path": "/etc/kolla/keystone-ssh/id_rsa.pub"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "id_rsa.pub",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/keystone-ssh/id_rsa.pub",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/keystone-ssh/id_rsa.pub",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "id_rsa.pub",
        "src": "id_rsa.pub"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/keystone-ssh/id_rsa.pub",
    "size": 725,
    "state": "file",
    "uid": 1000
}

TASK [service-check-containers : keystone | Check containers] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022 `" && echo ansible-tmp-1765371818.9502761-254032-235146327780022="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpcy42khtm TO /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022/ /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cymttpsxoealujmmdgagpxixymbvbtsc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371818.9502761-254032-235146327780022/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "labels": {},
            "name": "keystone",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394 `" && echo ansible-tmp-1765371820.0047586-254032-68833071691394="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_n7qo5zq TO /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394/ /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ucxiurkcxnxzefcqwspwhltwbcfakrei ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371820.0047586-254032-68833071691394/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "labels": {},
            "name": "keystone_fernet",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910 `" && echo ansible-tmp-1765371821.022668-254032-68818762643910="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpw1p1qzig TO /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910/ /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fikjanymihphujhsgudseflokoyjjtdt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371821.022668-254032-68818762643910/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "labels": {},
            "name": "keystone_ssh",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : keystone | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'keystone', 'value': {'container_name': 'keystone', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:5000'], 'timeout': '30'}, 'wsgi': 'keystone.wsgi.api:application', 'haproxy': {'keystone_internal': {'enabled': True, 'mode': 'http', 'external': False, 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}, 'keystone_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'tls_backend': False, 'port': '5000', 'listen_port': '5000', 'backend_http_extra': ['balance roundrobin', 'option httpchk']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "keystone",
        "value": {
            "container_name": "keystone",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "haproxy": {
                "keystone_external": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                },
                "keystone_internal": {
                    "backend_http_extra": [
                        "balance roundrobin",
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "5000",
                    "mode": "http",
                    "port": "5000",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:5000"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ],
            "wsgi": "keystone.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-fernet', 'value': {'container_name': 'keystone_fernet', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', '/usr/bin/fernet-healthcheck.sh'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "keystone-fernet",
        "value": {
            "container_name": "keystone_fernet",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "/usr/bin/fernet-healthcheck.sh"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'keystone-ssh', 'value': {'container_name': 'keystone_ssh', 'group': 'keystone', 'enabled': True, 'image': 'quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble', 'volumes': ['/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', 'keystone_fernet_tokens:/etc/keystone/fernet-keys'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8023'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "keystone-ssh",
        "value": {
            "container_name": "keystone_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "keystone",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8023"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/keystone-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/keystone-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml:6
skipping: [localhost] => {
    "changed": false,
    "false_condition": "keystone_dev_mode | bool",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Creating keystone database] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423 `" && echo ansible-tmp-1765371822.6405156-254361-188830472948423="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1pw5rymz TO /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423/ /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qsscxqrcvyidppllrrloplimgfxfgyum ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371822.6405156-254361-188830472948423/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_db",
    "changed": false,
    "db": "keystone",
    "db_list": [
        "keystone"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "keystone"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    }
}

TASK [keystone : Creating Keystone database user and setting permissions] ******
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258 `" && echo ansible-tmp-1765371825.1043706-254516-198727765492258="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp30v9gn2d TO /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258/ /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-phevkbevstokivykwkgekwopfgocclnt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371825.1043706-254516-198727765492258/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_user",
    "changed": false,
    "invocation": {
        "module_args": {
            "append_privs": true,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "name": "keystone",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "keystone.*:ALL",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "keystone"
        }
    },
    "msg": "User unchanged",
    "user": "keystone"
}

TASK [keystone : Checking for any running keystone_fernet containers] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895 `" && echo ansible-tmp-1765371827.5486288-254689-254539081924895="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container_facts.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4frnl7do TO /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895/AnsiballZ_kolla_container_facts.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895/ /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895/AnsiballZ_kolla_container_facts.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-acfrohqwqdygfwhenuhutedlhowrpfgp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895/AnsiballZ_kolla_container_facts.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371827.5486288-254689-254539081924895/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "containers": {
        "keystone_fernet": {
            "AppArmorProfile": "docker-default",
            "Args": [
                "--single-child",
                "--",
                "kolla_start"
            ],
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "kolla_start"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "dumb-init",
                    "--single-child",
                    "--"
                ],
                "Env": [
                    "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                    "KOLLA_SERVICE_NAME=keystone-fernet",
                    "PATH=/var/lib/kolla/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL="
                ],
                "Healthcheck": {
                    "Interval": 30000000000,
                    "Retries": 3,
                    "StartPeriod": 5000000000,
                    "Test": [
                        "CMD-SHELL",
                        "/usr/bin/fernet-healthcheck.sh"
                    ],
                    "Timeout": 30000000000
                },
                "Hostname": "nics-VMware20-1",
                "Image": "quay.io/openstack.kolla/keystone-fernet:master-ubuntu-noble",
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "keystone-fernet",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                },
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "",
                "Volumes": {
                    "/etc/keystone/fernet-keys": {},
                    "/etc/localtime": {},
                    "/etc/timezone": {},
                    "/var/lib/kolla/config_files/": {},
                    "/var/log/kolla/": {}
                },
                "WorkingDir": ""
            },
            "Created": "2025-12-10T11:59:29.240948602Z",
            "Driver": "overlay2",
            "ExecIDs": null,
            "GraphDriver": {
                "Data": {
                    "ID": "b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5",
                    "LowerDir": "/var/lib/docker/overlay2/2340b78f2fe40850285fbb477265d7a2d160482310115cf6b9662c24338866cf-init/diff:/var/lib/docker/overlay2/eebf2626d0edcbcfbe1a8e03932d8b0b5dbef7a82718ffbcf5c3bb85e8d5fe06/diff:/var/lib/docker/overlay2/ada29ab5298a8c0c377c0ce2189eddd6fc9d63597ea552816e9d05c98d523b6f/diff:/var/lib/docker/overlay2/017bf335ec0d6e8e024e858c9507ff827ce2dfa7e63645b239c293c35e53855f/diff:/var/lib/docker/overlay2/a2f9a5a4e23299f7f23d71992bf059bf9f0e599bb68455f83f1e2607772b8536/diff:/var/lib/docker/overlay2/6393cdd51bbfc66b2b2154a55048ff390788cfe7da7a25478488e11741eefc63/diff:/var/lib/docker/overlay2/e65ee659dc728ec59e2bd19bcce61517b58beffc7b0617b53f6184c17047635c/diff:/var/lib/docker/overlay2/2afd1c6443a6f2407eef8277a7d36192c17dffc0f538d1452f1cd1b314c602f1/diff:/var/lib/docker/overlay2/cce71d76489eff9c78c09066c52b1e6763464c12cf09a311fed07213eaae583c/diff:/var/lib/docker/overlay2/a01f79c1775374aca1b328c393bdf719e5ad2caecfe78c5d21b2e1fc8be37d6e/diff:/var/lib/docker/overlay2/4999c6b6a0c813b1fdf1db768b04cefeb21bb0ca79ea0e1d66892a3c13e9365a/diff:/var/lib/docker/overlay2/0469ebbf6da4b6df46ae1fe627ffa2c74171e4135f2ca0aaede7c77215ff9018/diff:/var/lib/docker/overlay2/1b14efdc9c1c50fc2adeba5ee60e79543fd8c309e504680c994d909a2a0ede87/diff:/var/lib/docker/overlay2/3be326433cff9431ae051c00a74e5597b8d8036aa06c4ee03fd537056b5bc54a/diff:/var/lib/docker/overlay2/393c87ba176b1d8194a92105d1b51eb3a540709fac517ef10f697099eb5358a6/diff:/var/lib/docker/overlay2/1d27868beaf84f6fb476db6d379ea0031e603a931e00a0e31ea2091f3de69d17/diff:/var/lib/docker/overlay2/da1028d097d617fa21062862a224391799d0cec78eceaa116f1307391d6c52d0/diff:/var/lib/docker/overlay2/c91318cd5a38671732f9a86a2967ac4eb321a418324c0291cbe4ad70dbff0dde/diff:/var/lib/docker/overlay2/e3af9f4eb6d7802cb9370383da3c67b7ff9b0fd05ad87d644234b533363f7a15/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/2340b78f2fe40850285fbb477265d7a2d160482310115cf6b9662c24338866cf/merged",
                    "UpperDir": "/var/lib/docker/overlay2/2340b78f2fe40850285fbb477265d7a2d160482310115cf6b9662c24338866cf/diff",
                    "WorkDir": "/var/lib/docker/overlay2/2340b78f2fe40850285fbb477265d7a2d160482310115cf6b9662c24338866cf/work"
                },
                "Name": "overlay2"
            },
            "HostConfig": {
                "AutoRemove": false,
                "Binds": [
                    "/etc/kolla/keystone-fernet/:/var/lib/kolla/config_files/:ro",
                    "/etc/localtime:/etc/localtime:ro",
                    "/etc/timezone:/etc/timezone:ro",
                    "kolla_logs:/var/log/kolla/:rw",
                    "keystone_fernet_tokens:/etc/keystone/fernet-keys:rw"
                ],
                "BlkioDeviceReadBps": null,
                "BlkioDeviceReadIOps": null,
                "BlkioDeviceWriteBps": null,
                "BlkioDeviceWriteIOps": null,
                "BlkioWeight": 0,
                "BlkioWeightDevice": null,
                "CapAdd": null,
                "CapDrop": null,
                "Cgroup": "",
                "CgroupParent": "",
                "CgroupnsMode": "private",
                "ConsoleSize": [
                    0,
                    0
                ],
                "ContainerIDFile": "",
                "CpuCount": 0,
                "CpuPercent": 0,
                "CpuPeriod": 0,
                "CpuQuota": 0,
                "CpuRealtimePeriod": 0,
                "CpuRealtimeRuntime": 0,
                "CpuShares": 0,
                "CpusetCpus": "",
                "CpusetMems": "",
                "DeviceCgroupRules": null,
                "DeviceRequests": null,
                "Devices": null,
                "Dns": null,
                "DnsOptions": null,
                "DnsSearch": null,
                "ExtraHosts": null,
                "GroupAdd": null,
                "IOMaximumBandwidth": 0,
                "IOMaximumIOps": 0,
                "IpcMode": "private",
                "Isolation": "",
                "Links": null,
                "LogConfig": {
                    "Config": {
                        "max-file": "5",
                        "max-size": "50m"
                    },
                    "Type": "json-file"
                },
                "MaskedPaths": [
                    "/proc/acpi",
                    "/proc/asound",
                    "/proc/interrupts",
                    "/proc/kcore",
                    "/proc/keys",
                    "/proc/latency_stats",
                    "/proc/sched_debug",
                    "/proc/scsi",
                    "/proc/timer_list",
                    "/proc/timer_stats",
                    "/sys/devices/virtual/powercap",
                    "/sys/firmware"
                ],
                "Memory": 0,
                "MemoryReservation": 0,
                "MemorySwap": 0,
                "MemorySwappiness": null,
                "NanoCpus": 0,
                "NetworkMode": "host",
                "OomKillDisable": null,
                "OomScoreAdj": 0,
                "PidMode": "",
                "PidsLimit": null,
                "PortBindings": {},
                "Privileged": false,
                "PublishAllPorts": false,
                "ReadonlyPaths": [
                    "/proc/bus",
                    "/proc/fs",
                    "/proc/irq",
                    "/proc/sys",
                    "/proc/sysrq-trigger"
                ],
                "ReadonlyRootfs": false,
                "RestartPolicy": {
                    "MaximumRetryCount": 0,
                    "Name": "no"
                },
                "Runtime": "runc",
                "SecurityOpt": [],
                "ShmSize": 67108864,
                "UTSMode": "",
                "Ulimits": null,
                "UsernsMode": "",
                "VolumeDriver": "",
                "VolumesFrom": null
            },
            "HostnamePath": "/var/lib/docker/containers/b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5/hostname",
            "HostsPath": "/var/lib/docker/containers/b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5/hosts",
            "Id": "b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5",
            "Image": "sha256:6f26775a23abaac1adf3b718899efefa5db551dfb96c2ba71d9f5e96f4da415c",
            "LogPath": "/var/lib/docker/containers/b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5/b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5-json.log",
            "MountLabel": "",
            "Mounts": [
                {
                    "Destination": "/etc/keystone/fernet-keys",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "keystone_fernet_tokens",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/keystone_fernet_tokens/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/lib/kolla/config_files",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/kolla/keystone-fernet",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/localtime",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/localtime",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/timezone",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/timezone",
                    "Type": "bind"
                },
                {
                    "Destination": "/var/log/kolla",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "kolla_logs",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                    "Type": "volume"
                }
            ],
            "Name": "/keystone_fernet",
            "NetworkSettings": {
                "Networks": {
                    "host": {
                        "Aliases": null,
                        "DNSNames": null,
                        "DriverOpts": null,
                        "EndpointID": "993b9911130183e22cc3dc04f0cc49b8e48dd7a19a0debdc8aa4f9197bb1088f",
                        "Gateway": "",
                        "GlobalIPv6Address": "",
                        "GlobalIPv6PrefixLen": 0,
                        "GwPriority": 0,
                        "IPAMConfig": null,
                        "IPAddress": "",
                        "IPPrefixLen": 0,
                        "IPv6Gateway": "",
                        "Links": null,
                        "MacAddress": "",
                        "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                    }
                },
                "Ports": {},
                "SandboxID": "99139a324a26f4a7cacfa0dfdfa5dd5a38630956e7ef9b29f27e478735295f17",
                "SandboxKey": "/var/run/docker/netns/default"
            },
            "Path": "dumb-init",
            "Platform": "linux",
            "ProcessLabel": "",
            "ResolvConfPath": "/var/lib/docker/containers/b8fe48aaf59d0a705f286446d9618aef00beac07382ec264ed43e92a504143c5/resolv.conf",
            "RestartCount": 0,
            "State": {
                "Dead": false,
                "Error": "",
                "ExitCode": 0,
                "FinishedAt": "2025-12-10T12:21:57.264197245Z",
                "Health": {
                    "FailingStreak": 0,
                    "Status": "healthy"
                },
                "OOMKilled": false,
                "Paused": false,
                "Pid": 137750,
                "Restarting": false,
                "Running": true,
                "StartedAt": "2025-12-10T12:21:57.473000801Z",
                "Status": "running"
            }
        }
    },
    "invocation": {
        "module_args": {
            "action": "get_containers",
            "api_version": "auto",
            "args": {
                "get_all_containers": false
            },
            "container_engine": "docker",
            "name": [
                "keystone_fernet"
            ]
        }
    },
    "result": false
}

TASK [keystone : Group nodes where keystone_fernet is running] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml:16
ok: [localhost] => {
    "add_group": "keystone_fernet_running_True",
    "changed": false,
    "parent_groups": [
        "all"
    ]
}

TASK [keystone : Fail if any hosts need bootstrapping and not all hosts targeted] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml:23
skipping: [localhost] => {
    "changed": false,
    "false_condition": "groups['keystone_fernet_running_True'] is not defined",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Running Keystone bootstrap container] *************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml:34
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988 `" && echo ansible-tmp-1765371829.0311642-254736-255097436652988="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpamxjcpr8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988/ /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-aftbynfitkcdphbgujjidevwttlxmwti ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371829.0311642-254736-255097436652988/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "bootstrap-keystone"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/keystone:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "bootstrap_keystone",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/keystone/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "keystone_fernet_tokens:/etc/keystone/fernet-keys"
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "+ sudo -E kolla_set_configs\n2025-12-10 14:03:50.416 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:03:50.416 INFO Validating config file\n2025-12-10 14:03:50.416 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:03:50.419 INFO Copying service configuration files\n2025-12-10 14:03:50.419 INFO Copying /var/lib/kolla/config_files/keystone-startup.sh to /usr/bin/keystone-startup.sh\n2025-12-10 14:03:50.424 INFO Setting permission for /usr/bin/keystone-startup.sh\n2025-12-10 14:03:50.424 INFO Copying /var/lib/kolla/config_files/keystone.conf to /etc/keystone/keystone.conf\n2025-12-10 14:03:50.424 INFO Setting permission for /etc/keystone/keystone.conf\n2025-12-10 14:03:50.424 INFO Copying /var/lib/kolla/config_files/keystone-uwsgi.ini to /etc/keystone/keystone-api-uwsgi.ini\n2025-12-10 14:03:50.425 INFO Setting permission for /etc/keystone/keystone-api-uwsgi.ini\n2025-12-10 14:03:50.425 INFO Writing out command to execute\n2025-12-10 14:03:50.425 INFO Setting permission for /var/log/kolla\n2025-12-10 14:03:50.425 INFO Setting permission for /var/log/kolla/keystone/keystone.log\n2025-12-10 14:03:50.426 INFO Setting permission for /etc/keystone/fernet-keys\n++ cat /run_command\n+ CMD=/usr/bin/keystone-startup.sh\n+ ARGS=\n+ sudo kolla_copy_cacerts\n+ sudo kolla_install_projects\n+ [[ ! -n '' ]]\n+ . kolla_extend_start\n++ KEYSTONE_LOG_DIR=/var/log/kolla/keystone\n++ [[ ! -d /var/log/kolla/keystone ]]\n+++ stat -c %U:%G /var/log/kolla/keystone\n++ [[ keystone:kolla != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\o\\l\\l\\a ]]\n++ '[' '!' -f /var/log/kolla/keystone/keystone.log ']'\n+++ stat -c %U:%G /var/log/kolla/keystone/keystone.log\n++ [[ keystone:keystone != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\e\\y\\s\\t\\o\\n\\e ]]\n+++ stat -c %a /var/log/kolla/keystone\n++ [[ 2755 != \\7\\5\\5 ]]\n++ chmod 755 /var/log/kolla/keystone\n++ EXTRA_KEYSTONE_MANAGE_ARGS=\n++ [[ -n '' ]]\n++ [[ -n '' ]]\n++ [[ -n 0 ]]\n++ sudo -H -u keystone keystone-manage db_sync\n2025-12-10 14:03:53.101 22 INFO alembic.runtime.migration [-] Context impl MySQLImpl.\n2025-12-10 14:03:53.102 22 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.\n++ exit 0\n",
    "stderr_lines": [
        "+ sudo -E kolla_set_configs",
        "2025-12-10 14:03:50.416 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:03:50.416 INFO Validating config file",
        "2025-12-10 14:03:50.416 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:03:50.419 INFO Copying service configuration files",
        "2025-12-10 14:03:50.419 INFO Copying /var/lib/kolla/config_files/keystone-startup.sh to /usr/bin/keystone-startup.sh",
        "2025-12-10 14:03:50.424 INFO Setting permission for /usr/bin/keystone-startup.sh",
        "2025-12-10 14:03:50.424 INFO Copying /var/lib/kolla/config_files/keystone.conf to /etc/keystone/keystone.conf",
        "2025-12-10 14:03:50.424 INFO Setting permission for /etc/keystone/keystone.conf",
        "2025-12-10 14:03:50.424 INFO Copying /var/lib/kolla/config_files/keystone-uwsgi.ini to /etc/keystone/keystone-api-uwsgi.ini",
        "2025-12-10 14:03:50.425 INFO Setting permission for /etc/keystone/keystone-api-uwsgi.ini",
        "2025-12-10 14:03:50.425 INFO Writing out command to execute",
        "2025-12-10 14:03:50.425 INFO Setting permission for /var/log/kolla",
        "2025-12-10 14:03:50.425 INFO Setting permission for /var/log/kolla/keystone/keystone.log",
        "2025-12-10 14:03:50.426 INFO Setting permission for /etc/keystone/fernet-keys",
        "++ cat /run_command",
        "+ CMD=/usr/bin/keystone-startup.sh",
        "+ ARGS=",
        "+ sudo kolla_copy_cacerts",
        "+ sudo kolla_install_projects",
        "+ [[ ! -n '' ]]",
        "+ . kolla_extend_start",
        "++ KEYSTONE_LOG_DIR=/var/log/kolla/keystone",
        "++ [[ ! -d /var/log/kolla/keystone ]]",
        "+++ stat -c %U:%G /var/log/kolla/keystone",
        "++ [[ keystone:kolla != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\o\\l\\l\\a ]]",
        "++ '[' '!' -f /var/log/kolla/keystone/keystone.log ']'",
        "+++ stat -c %U:%G /var/log/kolla/keystone/keystone.log",
        "++ [[ keystone:keystone != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\e\\y\\s\\t\\o\\n\\e ]]",
        "+++ stat -c %a /var/log/kolla/keystone",
        "++ [[ 2755 != \\7\\5\\5 ]]",
        "++ chmod 755 /var/log/kolla/keystone",
        "++ EXTRA_KEYSTONE_MANAGE_ARGS=",
        "++ [[ -n '' ]]",
        "++ [[ -n '' ]]",
        "++ [[ -n 0 ]]",
        "++ sudo -H -u keystone keystone-manage db_sync",
        "2025-12-10 14:03:53.101 22 INFO alembic.runtime.migration [-] Context impl MySQLImpl.",
        "2025-12-10 14:03:53.102 22 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.",
        "++ exit 0"
    ],
    "stdout": "",
    "stdout_lines": []
}

TASK [keystone : Running Keystone fernet bootstrap container] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/bootstrap_service.yml:53
skipping: [localhost] => {
    "changed": false,
    "false_condition": "groups['keystone_fernet_running_True'] is not defined",
    "skip_reason": "Conditional result was False"
}

TASK [keystone : Flush handlers] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml:12
META: triggered running handlers for localhost

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml:15
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/distribute_fernet.yml for localhost

TASK [keystone : Waiting for Keystone SSH port to be UP] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/distribute_fernet.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369 `" && echo ansible-tmp-1765371834.2900429-255175-89149129829369="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/wait_for.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_2vh6ny5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369/AnsiballZ_wait_for.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369/ /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369/AnsiballZ_wait_for.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369/AnsiballZ_wait_for.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371834.2900429-255175-89149129829369/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "elapsed": 0,
    "invocation": {
        "module_args": {
            "active_connection_states": [
                "ESTABLISHED",
                "FIN_WAIT1",
                "FIN_WAIT2",
                "SYN_RECV",
                "SYN_SENT",
                "TIME_WAIT"
            ],
            "connect_timeout": 1,
            "delay": 0,
            "exclude_hosts": null,
            "host": "192.168.0.195",
            "msg": null,
            "path": null,
            "port": 8023,
            "search_regex": null,
            "sleep": 1,
            "state": "started",
            "timeout": 300
        }
    },
    "match_groupdict": {},
    "match_groups": [],
    "path": null,
    "port": 8023,
    "search_regex": null,
    "state": "started"
}

TASK [keystone : Run key distribution] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/distribute_fernet.yml:12
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939 `" && echo ansible-tmp-1765371835.2424128-255212-64032274751939="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpf0cf3tm_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939/ /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-msqixjfgbcmkfowyykizvaofhturfhmq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371835.2424128-255212-64032274751939/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": [
        "docker",
        "exec",
        "-t",
        "keystone_fernet",
        "/usr/bin/fernet-push.sh"
    ],
    "delta": "0:00:00.125188",
    "end": "2025-12-10 14:03:55.709732",
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec -t keystone_fernet /usr/bin/fernet-push.sh",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:03:55.584544",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "No additional keystone-server where fernet keys could be rsynced.",
    "stdout_lines": [
        "No additional keystone-server where fernet keys could be rsynced."
    ]
}

TASK [keystone : Creating admin project, user, role, service, and endpoint] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/register.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462 `" && echo ansible-tmp-1765371835.994113-255324-208329804158462="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxyvse_fc TO /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462/ /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-byzpvpgzqzahjghxerzjrlqwpuhaexaq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371835.994113-255324-208329804158462/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => (item=RegionOne) => {
    "ansible_loop_var": "item",
    "changed": true,
    "cmd": [
        "docker",
        "exec",
        "keystone",
        "kolla_keystone_bootstrap",
        "admin",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "admin",
        "admin",
        "http://192.168.0.201:5000",
        "http://192.168.0.201:5000",
        "RegionOne"
    ],
    "delta": "0:00:04.292769",
    "end": "2025-12-10 14:04:00.740214",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec keystone kolla_keystone_bootstrap admin M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A admin admin http://192.168.0.201:5000 http://192.168.0.201:5000 RegionOne\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "item": "RegionOne",
    "msg": "",
    "rc": 0,
    "start": "2025-12-10 14:03:56.447445",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "{\"failed\": false, \"changed\": true}",
    "stdout_lines": [
        "{\"failed\": false, \"changed\": true}"
    ]
}

TASK [service-ks-register : keystone | Creating/deleting services] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712 `" && echo ansible-tmp-1765371840.975572-255650-188605028331712="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpey2m34ln TO /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712/ /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cfgoahtgotvebrlyeduwnfokdbqyarzb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371840.975572-255650-188605028331712/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=keystone (identity)) => {
    "action": "openstack.cloud.catalog_service",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": "Openstack Identity Service",
            "interface": "internal",
            "is_enabled": null,
            "name": "keystone",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service_type": "identity",
            "state": "present",
            "timeout": 180,
            "type": "identity",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "description": "Openstack Identity Service",
        "endpoints": [
            {
                "interface": "internal",
                "url": "http://192.168.0.201:5000"
            },
            {
                "interface": "public",
                "url": "http://192.168.0.201:5000"
            }
        ],
        "name": "keystone",
        "type": "identity"
    },
    "service": {
        "description": "Openstack Identity Service",
        "id": "f96907532edb46b9899320fcace88acb",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/services/f96907532edb46b9899320fcace88acb"
        },
        "name": "keystone",
        "type": "identity"
    }
}

TASK [service-ks-register : keystone | Creating/deleting endpoints] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:25
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538 `" && echo ansible-tmp-1765371844.5049896-255832-249992515876538="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp03a8rqz_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538/ /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tcebrketkbuwwwioguvbxuqqmyuzvadg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371844.5049896-255832-249992515876538/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=keystone -> http://192.168.0.201:5000 -> internal) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "4bdbde3b5123467a9f85d445f83840d9",
        "interface": "internal",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/4bdbde3b5123467a9f85d445f83840d9"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "f96907532edb46b9899320fcace88acb",
        "url": "http://192.168.0.201:5000"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "internal",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "keystone",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:5000",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Openstack Identity Service",
            "name": "keystone",
            "type": "identity"
        },
        {
            "interface": "internal",
            "url": "http://192.168.0.201:5000"
        }
    ]
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196 `" && echo ansible-tmp-1765371847.7080848-255832-60872799026196="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpotfwqslx TO /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196/ /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qgygwaqmwjeycbblfdbsdgqosxksatil ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371847.7080848-255832-60872799026196/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=keystone -> http://192.168.0.201:5000 -> public) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "9852cde873fb4253a4d54147d2015c62",
        "interface": "public",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/9852cde873fb4253a4d54147d2015c62"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "f96907532edb46b9899320fcace88acb",
        "url": "http://192.168.0.201:5000"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "public",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "keystone",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:5000",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Openstack Identity Service",
            "name": "keystone",
            "type": "identity"
        },
        {
            "interface": "public",
            "url": "http://192.168.0.201:5000"
        }
    ]
}

TASK [service-ks-register : keystone | Creating projects] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:50
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [service-ks-register : keystone | Creating/deleting users] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:67
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [service-ks-register : keystone | Creating roles] *************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:93
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [service-ks-register : keystone | Granting/revoking user roles] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:109
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [keystone : Creating default user role] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/register.yml:21
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590 `" && echo ansible-tmp-1765371851.2075636-256237-209077425393590="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp78x24g6d TO /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590/ /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dyeacbkdvejsrkzexrzoenjteqbhulmc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371851.2075636-256237-209077425393590/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "openstack.cloud.identity_role",
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain_id": null,
            "endpoint_type": "internal",
            "interface": "internal",
            "name": "member",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "role": {
        "description": null,
        "domain_id": null,
        "id": "d5fed0101a384e8db7d2eb15212883d0",
        "links": {
            "self": "http://192.168.0.201:5000/v3/roles/d5fed0101a384e8db7d2eb15212883d0"
        },
        "name": "member",
        "options": {
            "immutable": true
        }
    }
}

TASK [keystone : include_tasks] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/keystone/tasks/deploy.yml:19
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_keystone_federation | bool",
    "skip_reason": "Conditional result was False"
}

PLAY [Apply role ceph-rgw] *****************************************************
skipping: no hosts matched

PLAY [Apply role glance] *******************************************************

TASK [glance : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/register.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap_service.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/deploy.yml for localhost

TASK [service-ks-register : glance | Creating/deleting services] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714 `" && echo ansible-tmp-1765371855.1226504-256461-272189814906714="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpe_opmpt7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714/ /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vwmuzzepwudwirtbvfhafmtipielqkvp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371855.1226504-256461-272189814906714/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=glance (image)) => {
    "action": "openstack.cloud.catalog_service",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": "Openstack Image",
            "interface": "internal",
            "is_enabled": null,
            "name": "glance",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service_type": "image",
            "state": "present",
            "timeout": 180,
            "type": "image",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "description": "Openstack Image",
        "endpoints": [
            {
                "interface": "internal",
                "url": "http://192.168.0.201:9292"
            },
            {
                "interface": "public",
                "url": "http://192.168.0.201:9292"
            }
        ],
        "name": "glance",
        "type": "image"
    },
    "service": {
        "description": "Openstack Image",
        "id": "8a6ea72c13d947139e6edccf4e187849",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/services/8a6ea72c13d947139e6edccf4e187849"
        },
        "name": "glance",
        "type": "image"
    }
}

TASK [service-ks-register : glance | Creating/deleting endpoints] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:25
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424 `" && echo ansible-tmp-1765371858.5182452-256651-2602297885424="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpywoz5ia3 TO /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424/ /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ultevxjahzizlvqwuvfchclmpebtlqqi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371858.5182452-256651-2602297885424/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=glance -> http://192.168.0.201:9292 -> internal) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "46c274619dfb4b35b45beca05f13553d",
        "interface": "internal",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/46c274619dfb4b35b45beca05f13553d"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "8a6ea72c13d947139e6edccf4e187849",
        "url": "http://192.168.0.201:9292"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "internal",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "glance",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:9292",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Openstack Image",
            "name": "glance",
            "type": "image"
        },
        {
            "interface": "internal",
            "url": "http://192.168.0.201:9292"
        }
    ]
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926 `" && echo ansible-tmp-1765371861.7726977-256651-150354563077926="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3ewqe0og TO /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926/ /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ckloavjiyzydfziyvlwqobqbuwqppsjx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371861.7726977-256651-150354563077926/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=glance -> http://192.168.0.201:9292 -> public) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "7571dc0326ee4ca88e95fa471126c8b8",
        "interface": "public",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/7571dc0326ee4ca88e95fa471126c8b8"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "8a6ea72c13d947139e6edccf4e187849",
        "url": "http://192.168.0.201:9292"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "public",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "glance",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:9292",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Openstack Image",
            "name": "glance",
            "type": "image"
        },
        {
            "interface": "public",
            "url": "http://192.168.0.201:9292"
        }
    ]
}

TASK [service-ks-register : glance | Creating projects] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:50
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691 `" && echo ansible-tmp-1765371865.0123763-257031-264617823919691="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzy915hye TO /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691/ /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lxfnhxrjxskrmelolbagwihazybcnzsl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371865.0123763-257031-264617823919691/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=service) => {
    "action": "openstack.cloud.project",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain": "default",
            "extra_specs": null,
            "interface": "internal",
            "is_enabled": null,
            "name": "service",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "service",
    "project": {
        "description": "",
        "domain_id": "default",
        "id": "3e1d884058424621b0335f6a041c2d4a",
        "is_domain": false,
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/projects/3e1d884058424621b0335f6a041c2d4a"
        },
        "name": "service",
        "options": {},
        "parent_id": "default",
        "tags": []
    }
}

TASK [service-ks-register : glance | Creating/deleting users] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:67
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657 `" && echo ansible-tmp-1765371868.2956867-257176-20708809679657="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmn5frejb TO /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657/ /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ulfqgxvmarrtcwzntdifffqmgmgnrmyp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371868.2956867-257176-20708809679657/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => (item=glance -> service) => {
    "action": "openstack.cloud.identity_user",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": true,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "default_project": "service",
            "description": null,
            "domain": "default",
            "email": null,
            "interface": "internal",
            "is_enabled": true,
            "name": "glance",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "update_password": "always",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "d5YfFqBtrC67badXljpcOGyYHdQal5nRK8hYMTYH",
        "project": "service",
        "role": "admin",
        "user": "glance"
    },
    "user": {
        "default_project_id": "3e1d884058424621b0335f6a041c2d4a",
        "description": null,
        "domain_id": "default",
        "email": null,
        "id": "2f982e3e12434f65a00ae6cb849f55d2",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/users/2f982e3e12434f65a00ae6cb849f55d2"
        },
        "name": "glance",
        "options": {},
        "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
        "password_expires_at": null
    },
    "warnings": [
        "Module did not set no_log for update_password"
    ]
}

TASK [service-ks-register : glance | Creating roles] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:93
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858 `" && echo ansible-tmp-1765371872.9746475-257562-176874162102858="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpoc1lfrap TO /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858/ /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jixyjeubqcesyyaifqwtohagevlomwvi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371872.9746475-257562-176874162102858/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=admin) => {
    "action": "openstack.cloud.identity_role",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain_id": null,
            "interface": "internal",
            "name": "admin",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "admin",
    "role": {
        "description": null,
        "domain_id": null,
        "id": "5c609e9185ea4b52b7299d27240aebd9",
        "links": {
            "self": "http://192.168.0.201:5000/v3/roles/5c609e9185ea4b52b7299d27240aebd9"
        },
        "name": "admin",
        "options": {
            "immutable": true
        }
    }
}

TASK [service-ks-register : glance | Granting/revoking user roles] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:109
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704 `" && echo ansible-tmp-1765371876.4608574-257890-81073374473704="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpbu363o88 TO /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704/ /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bpunpzibzfgkxxzzhjbonwaoyddgnddt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371876.4608574-257890-81073374473704/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=glance -> service -> admin) => {
    "action": "openstack.cloud.role_assignment",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "domain": null,
            "group": null,
            "group_domain": null,
            "interface": "internal",
            "project": "service",
            "project_domain": null,
            "region_name": "RegionOne",
            "role": "admin",
            "role_domain": null,
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "system": null,
            "timeout": 180,
            "user": "glance",
            "user_domain": null,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "d5YfFqBtrC67badXljpcOGyYHdQal5nRK8hYMTYH",
        "project": "service",
        "role": "admin",
        "user": "glance"
    }
}

TASK [glance : Ensuring config directories exist] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003 `" && echo ansible-tmp-1765371880.4193618-258098-35275819304003="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_7nr5eae TO /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003/ /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uvxrswowzhorupfyzfrmulpbodvnfjqd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371880.4193618-258098-35275819304003/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/glance-api"
        },
        "before": {
            "path": "/etc/kolla/glance-api"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/glance-api",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/glance-api",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [glance : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_backend_ceph | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Check if policies shall be overwritten] *************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:16
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [glance : Set glance policy file] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:28
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_policy.results | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [glance : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:35
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Creating TLS backend PEM File] **********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:39
skipping: [localhost] => {
    "changed": false,
    "false_condition": "service | service_enabled_and_mapped_to_host",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Copying over config.json files for services] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:51
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347 `" && echo ansible-tmp-1765371882.2783039-258211-234600374773347="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpewv70v0n TO /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/ /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bsdkmchiwwfaasgdbagwfjqjpblbbvzg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpuxo00aln TO /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/ /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jxrihoezcfbcagxnmwsesedtgbbffvoo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371882.2783039-258211-234600374773347/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "68b7e7e8e64478aa815a290fdd59aabb2cb0d119",
    "dest": "/etc/kolla/glance-api/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/glance-api/config.json"
        },
        "before": {
            "path": "/etc/kolla/glance-api/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "glance-api.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/glance-api/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/glance-api/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/glance-api/config.json",
    "size": 543,
    "state": "file",
    "uid": 1000
}

TASK [glance : Copying over glance-api.conf] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:59
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709 `" && echo ansible-tmp-1765371883.5236783-258317-102034576141709="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6d6fyze7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/ /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-upwzzpjfcpszvqnyalliwaibibcqeizn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3kl1qy6o TO /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/ /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pwqiktsbrljhhkgqgcnwwgzsgkrpfjbj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371883.5236783-258317-102034576141709/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "2724060ad70c6f6d0d12de08cea21a73d772aaac",
    "dest": "/etc/kolla/glance-api/glance-api.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/glance-api/glance-api.conf"
        },
        "before": {
            "path": "/etc/kolla/glance-api/glance-api.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/glance-api/glance-api.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/glance-api/glance-api.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/templates/glance-api.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/glance.conf",
                "/etc/kolla/config/glance/glance-api.conf",
                "/etc/kolla/config/glance/localhost/glance-api.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmppdtsv3_l/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/glance-api/glance-api.conf",
    "size": 1757,
    "state": "file",
    "uid": 1000
}

TASK [glance : Copying over glance-cache.conf for glance_api] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:74
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_glance_image_cache | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Copying over glance-image-import.conf] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:90
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_enable_interoperable_image_import | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Copying over property-protections-rules.conf] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:102
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_enable_property_protection | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Copying over existing policy file] ******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:114
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_policy_file is defined",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Copying over glance-haproxy-tls.cfg] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/config.yml:126
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/templates/glance-tls-proxy.cfg.j2)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "service | service_enabled_and_mapped_to_host",
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/templates/glance-tls-proxy.cfg.j2",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-check-containers : glance | Check containers] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073 `" && echo ansible-tmp-1765371887.0405402-258437-95046492818073="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi4xtz518 TO /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073/ /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vpktuyomictuksnghtqzkxjoxyzztyzu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371887.0405402-258437-95046492818073/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "labels": {},
            "name": "glance_api",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : glance | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'glance-api', 'value': {'container_name': 'glance_api', 'group': 'glance-api', 'host_in_groups': True, 'enabled': True, 'image': 'quay.io/openstack.kolla/glance-api:master-ubuntu-noble', 'environment': {'http_proxy': '', 'https_proxy': '', 'no_proxy': 'localhost,127.0.0.1,192.168.0.195,192.168.0.201'}, 'privileged': False, 'volumes': ['/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'glance:/var/lib/glance/', '', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:9292'], 'timeout': '30'}, 'haproxy': {'glance_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}, 'glance_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '9292', 'frontend_http_extra': ['timeout client 6h'], 'backend_http_extra': ['timeout server 6h', 'option httpchk'], 'custom_member_list': ['server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5', '']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "glance-api",
        "value": {
            "container_name": "glance_api",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": "localhost,127.0.0.1,192.168.0.195,192.168.0.201"
            },
            "group": "glance-api",
            "haproxy": {
                "glance_api": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": false,
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                },
                "glance_api_external": {
                    "backend_http_extra": [
                        "timeout server 6h",
                        "option httpchk"
                    ],
                    "custom_member_list": [
                        "server nics-VMware20-1 192.168.0.195:9292 check inter 2000 rise 2 fall 5",
                        ""
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "frontend_http_extra": [
                        "timeout client 6h"
                    ],
                    "mode": "http",
                    "port": "9292"
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:9292"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "privileged": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [glance : include_tasks] **************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/deploy.yml:8
skipping: [localhost] => {
    "changed": false,
    "false_condition": "glance_dev_mode | bool",
    "skip_reason": "Conditional result was False"
}

TASK [glance : Creating Glance database] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132 `" && echo ansible-tmp-1765371888.7470064-258550-229189648918132="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd88gma_y TO /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132/ /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uytefxoolwaqsxfsgfsqfqaionkadnnz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371888.7470064-258550-229189648918132/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_db",
    "changed": false,
    "db": "glance",
    "db_list": [
        "glance"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "glance"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    }
}

TASK [glance : Creating Glance database user and setting permissions] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294 `" && echo ansible-tmp-1765371891.338574-258686-222842907747294="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp723683av TO /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294/ /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fkwmacsahqmvmdcexkcshzrolwylieit ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371891.338574-258686-222842907747294/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_user",
    "changed": false,
    "invocation": {
        "module_args": {
            "append_privs": true,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "name": "glance",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "glance.*:ALL",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "glance"
        }
    },
    "msg": "User unchanged",
    "user": "glance"
}

TASK [glance : Enable log_bin_trust_function_creators function] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap_service.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889 `" && echo ansible-tmp-1765371894.040555-258879-92639508056889="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9kax0rrl TO /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889/ /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xdpcxkscxrgohxljehvpxgihdymkzvfo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371894.040555-258879-92639508056889/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "action": "mysql_variables",
    "changed": true,
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "mode": "global",
            "value": "1",
            "variable": "log_bin_trust_function_creators"
        }
    },
    "msg": "Variable change succeeded prev_value=OFF",
    "queries": [
        "SET GLOBAL `log_bin_trust_function_creators` = 1"
    ]
}

TASK [glance : Running Glance bootstrap container] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap_service.yml:20
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384 `" && echo ansible-tmp-1765371897.6236362-258998-30188687983384="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpshxkuj42 TO /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384/ /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-azrlupkbsablmkqydjztosassxdxrodi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371897.6236362-258998-30188687983384/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "bootstrap-glance"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/glance-api:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "bootstrap_glance",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/glance-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "glance:/var/lib/glance/",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm"
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "+ sudo -E kolla_set_configs\n2025-12-10 14:04:58.863 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:04:58.863 INFO Validating config file\n2025-12-10 14:04:58.863 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:04:58.866 INFO Copying /etc/glance/glance-api.conf to /etc/kolla/defaults/etc/glance/glance-api.conf\n2025-12-10 14:04:58.867 INFO Copying permissions from /etc/glance/glance-api.conf onto /etc/kolla/defaults/etc/glance/glance-api.conf\n2025-12-10 14:04:58.867 INFO Copying service configuration files\n2025-12-10 14:04:58.867 INFO Deleting /etc/glance/glance-api.conf\n2025-12-10 14:04:58.869 INFO Copying /var/lib/kolla/config_files/glance-api.conf to /etc/glance/glance-api.conf\n2025-12-10 14:04:58.870 INFO Setting permission for /etc/glance/glance-api.conf\n2025-12-10 14:04:58.870 INFO Writing out command to execute\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/tasks_work_dir\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/images\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/staging\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache/python-entrypoints\n2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache/python-entrypoints/0c243f36db49f3c7758c2c869d7b6f5b8cb1c21f70c8bd476e7a74560018d5fc\n2025-12-10 14:04:58.872 INFO Setting permission for /var/log/kolla/glance\n2025-12-10 14:04:58.872 INFO Setting permission for /var/log/kolla/glance/glance-api.log\n++ cat /run_command\n+ CMD=glance-api\n+ ARGS=\n+ sudo kolla_copy_cacerts\n+ sudo kolla_install_projects\n+ [[ ! -n '' ]]\n+ . kolla_extend_start\n++ [[ ! -d /var/log/kolla/glance ]]\n+++ stat -c %a /var/log/kolla/glance\n++ [[ 2755 != \\7\\5\\5 ]]\n++ chmod 755 /var/log/kolla/glance\n++ . /usr/local/bin/kolla_glance_extend_start\n+++ [[ -n 0 ]]\n+++ glance-manage db_sync\n2025-12-10 14:05:00.490 19 INFO alembic.runtime.migration [-] Context impl MySQLImpl.\n2025-12-10 14:05:00.491 19 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.\n+++ glance-manage db_load_metadefs\n2025-12-10 14:05:02.530 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::OperatingSystem. It already exists in the database.\n2025-12-10 14:05:02.534 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Quota. It already exists in the database.\n2025-12-10 14:05:02.535 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMware. It already exists in the database.\n2025-12-10 14:05:02.537 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Glance::CommonImageProperties. It already exists in the database.\n2025-12-10 14:05:02.538 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Cinder::Volumetype. It already exists in the database.\n2025-12-10 14:05:02.539 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMwareQuotaFlavor. It already exists in the database.\n2025-12-10 14:05:02.541 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VirtCPUTopology. It already exists in the database.\n2025-12-10 14:05:02.542 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VTPM. It already exists in the database.\n2025-12-10 14:05:02.543 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::XenAPI. It already exists in the database.\n2025-12-10 14:05:02.545 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::StorageAllocationSettingData. It already exists in the database.\n2025-12-10 14:05:02.546 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::ProcessorAllocationSettingData. It already exists in the database.\n2025-12-10 14:05:02.547 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::InstanceData. It already exists in the database.\n2025-12-10 14:05:02.549 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::WebServers. It already exists in the database.\n2025-12-10 14:05:02.550 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateIoOpsFilter. It already exists in the database.\n2025-12-10 14:05:02.551 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::RandomNumberGenerator. It already exists in the database.\n2025-12-10 14:05:02.553 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::CPUMode. It already exists in the database.\n2025-12-10 14:05:02.554 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::LibvirtImage. It already exists in the database.\n2025-12-10 14:05:02.556 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Glance::Signatures. It already exists in the database.\n2025-12-10 14:05:02.557 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::DBMS. It already exists in the database.\n2025-12-10 14:05:02.558 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Watchdog. It already exists in the database.\n2025-12-10 14:05:02.560 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Hypervisor. It already exists in the database.\n2025-12-10 14:05:02.561 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::CPUPinning. It already exists in the database.\n2025-12-10 14:05:02.562 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::GuestShutdownBehavior. It already exists in the database.\n2025-12-10 14:05:02.564 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateNumInstancesFilter. It already exists in the database.\n2025-12-10 14:05:02.565 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::HostCapabilities. It already exists in the database.\n2025-12-10 14:05:02.566 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateDiskFilter. It already exists in the database.\n2025-12-10 14:05:02.568 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::TPM. It already exists in the database.\n2025-12-10 14:05:02.569 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::VirtualSystemSettingData. It already exists in the database.\n2025-12-10 14:05:02.570 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::GuestMemoryBacking. It already exists in the database.\n2025-12-10 14:05:02.572 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::ResourceAllocationSettingData. It already exists in the database.\n2025-12-10 14:05:02.573 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::Runtimes. It already exists in the database.\n2025-12-10 14:05:02.574 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Libvirt. It already exists in the database.\n2025-12-10 14:05:02.576 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMwareFlavor. It already exists in the database.\n2025-12-10 14:05:02.576 20 INFO glance.db.sqlalchemy.metadata [-] Metadata loading finished\n+++ exit 0\n",
    "stderr_lines": [
        "+ sudo -E kolla_set_configs",
        "2025-12-10 14:04:58.863 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:04:58.863 INFO Validating config file",
        "2025-12-10 14:04:58.863 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:04:58.866 INFO Copying /etc/glance/glance-api.conf to /etc/kolla/defaults/etc/glance/glance-api.conf",
        "2025-12-10 14:04:58.867 INFO Copying permissions from /etc/glance/glance-api.conf onto /etc/kolla/defaults/etc/glance/glance-api.conf",
        "2025-12-10 14:04:58.867 INFO Copying service configuration files",
        "2025-12-10 14:04:58.867 INFO Deleting /etc/glance/glance-api.conf",
        "2025-12-10 14:04:58.869 INFO Copying /var/lib/kolla/config_files/glance-api.conf to /etc/glance/glance-api.conf",
        "2025-12-10 14:04:58.870 INFO Setting permission for /etc/glance/glance-api.conf",
        "2025-12-10 14:04:58.870 INFO Writing out command to execute",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/tasks_work_dir",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/images",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/staging",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache/python-entrypoints",
        "2025-12-10 14:04:58.871 INFO Setting permission for /var/lib/glance/.cache/python-entrypoints/0c243f36db49f3c7758c2c869d7b6f5b8cb1c21f70c8bd476e7a74560018d5fc",
        "2025-12-10 14:04:58.872 INFO Setting permission for /var/log/kolla/glance",
        "2025-12-10 14:04:58.872 INFO Setting permission for /var/log/kolla/glance/glance-api.log",
        "++ cat /run_command",
        "+ CMD=glance-api",
        "+ ARGS=",
        "+ sudo kolla_copy_cacerts",
        "+ sudo kolla_install_projects",
        "+ [[ ! -n '' ]]",
        "+ . kolla_extend_start",
        "++ [[ ! -d /var/log/kolla/glance ]]",
        "+++ stat -c %a /var/log/kolla/glance",
        "++ [[ 2755 != \\7\\5\\5 ]]",
        "++ chmod 755 /var/log/kolla/glance",
        "++ . /usr/local/bin/kolla_glance_extend_start",
        "+++ [[ -n 0 ]]",
        "+++ glance-manage db_sync",
        "2025-12-10 14:05:00.490 19 INFO alembic.runtime.migration [-] Context impl MySQLImpl.",
        "2025-12-10 14:05:00.491 19 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.",
        "+++ glance-manage db_load_metadefs",
        "2025-12-10 14:05:02.530 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::OperatingSystem. It already exists in the database.",
        "2025-12-10 14:05:02.534 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Quota. It already exists in the database.",
        "2025-12-10 14:05:02.535 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMware. It already exists in the database.",
        "2025-12-10 14:05:02.537 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Glance::CommonImageProperties. It already exists in the database.",
        "2025-12-10 14:05:02.538 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Cinder::Volumetype. It already exists in the database.",
        "2025-12-10 14:05:02.539 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMwareQuotaFlavor. It already exists in the database.",
        "2025-12-10 14:05:02.541 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VirtCPUTopology. It already exists in the database.",
        "2025-12-10 14:05:02.542 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VTPM. It already exists in the database.",
        "2025-12-10 14:05:02.543 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::XenAPI. It already exists in the database.",
        "2025-12-10 14:05:02.545 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::StorageAllocationSettingData. It already exists in the database.",
        "2025-12-10 14:05:02.546 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::ProcessorAllocationSettingData. It already exists in the database.",
        "2025-12-10 14:05:02.547 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::InstanceData. It already exists in the database.",
        "2025-12-10 14:05:02.549 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::WebServers. It already exists in the database.",
        "2025-12-10 14:05:02.550 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateIoOpsFilter. It already exists in the database.",
        "2025-12-10 14:05:02.551 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::RandomNumberGenerator. It already exists in the database.",
        "2025-12-10 14:05:02.553 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::CPUMode. It already exists in the database.",
        "2025-12-10 14:05:02.554 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::LibvirtImage. It already exists in the database.",
        "2025-12-10 14:05:02.556 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Glance::Signatures. It already exists in the database.",
        "2025-12-10 14:05:02.557 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::DBMS. It already exists in the database.",
        "2025-12-10 14:05:02.558 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Watchdog. It already exists in the database.",
        "2025-12-10 14:05:02.560 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Hypervisor. It already exists in the database.",
        "2025-12-10 14:05:02.561 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::CPUPinning. It already exists in the database.",
        "2025-12-10 14:05:02.562 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::GuestShutdownBehavior. It already exists in the database.",
        "2025-12-10 14:05:02.564 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateNumInstancesFilter. It already exists in the database.",
        "2025-12-10 14:05:02.565 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::HostCapabilities. It already exists in the database.",
        "2025-12-10 14:05:02.566 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::AggregateDiskFilter. It already exists in the database.",
        "2025-12-10 14:05:02.568 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::TPM. It already exists in the database.",
        "2025-12-10 14:05:02.569 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::VirtualSystemSettingData. It already exists in the database.",
        "2025-12-10 14:05:02.570 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::GuestMemoryBacking. It already exists in the database.",
        "2025-12-10 14:05:02.572 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace CIM::ResourceAllocationSettingData. It already exists in the database.",
        "2025-12-10 14:05:02.573 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Software::Runtimes. It already exists in the database.",
        "2025-12-10 14:05:02.574 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::Libvirt. It already exists in the database.",
        "2025-12-10 14:05:02.576 20 INFO glance.db.sqlalchemy.metadata [-] Skipping namespace OS::Compute::VMwareFlavor. It already exists in the database.",
        "2025-12-10 14:05:02.576 20 INFO glance.db.sqlalchemy.metadata [-] Metadata loading finished",
        "+++ exit 0"
    ],
    "stdout": "Database is up to date. No migrations needed.\n",
    "stdout_lines": [
        "Database is up to date. No migrations needed."
    ]
}

TASK [glance : Disable log_bin_trust_function_creators function] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/bootstrap_service.yml:40
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686 `" && echo ansible-tmp-1765371903.3681378-259299-100990725327686="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi68lnpwi TO /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686/ /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jhrkcjvlyjmbhykabbdfuhsgdbazyyre ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371903.3681378-259299-100990725327686/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "action": "mysql_variables",
    "changed": true,
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "mode": "global",
            "value": "0",
            "variable": "log_bin_trust_function_creators"
        }
    },
    "msg": "Variable change succeeded prev_value=ON",
    "queries": [
        "SET GLOBAL `log_bin_trust_function_creators` = 0"
    ]
}

TASK [glance : Flush handlers] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/glance/tasks/deploy.yml:14
META: triggered running handlers for localhost

PLAY [Apply role ironic] *******************************************************
skipping: no hosts matched

PLAY [Apply role cinder] *******************************************************
skipping: no hosts matched

PLAY [Apply role placement] ****************************************************

TASK [placement : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/register.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/bootstrap_service.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/deploy.yml for localhost

TASK [service-ks-register : placement | Creating/deleting services] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758 `" && echo ansible-tmp-1765371906.245167-259414-87383628926758="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpg0fkdfbq TO /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758/ /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vikhgmvqqsgkofybrteyfnisttljylih ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371906.245167-259414-87383628926758/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=placement (placement)) => {
    "action": "openstack.cloud.catalog_service",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": "Placement Service",
            "interface": "internal",
            "is_enabled": null,
            "name": "placement",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service_type": "placement",
            "state": "present",
            "timeout": 180,
            "type": "placement",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "description": "Placement Service",
        "endpoints": [
            {
                "interface": "internal",
                "url": "http://192.168.0.201:8780"
            },
            {
                "interface": "public",
                "url": "http://192.168.0.201:8780"
            }
        ],
        "name": "placement",
        "type": "placement"
    },
    "service": {
        "description": "Placement Service",
        "id": "78428a714afc40ee827309b627d1a39f",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/services/78428a714afc40ee827309b627d1a39f"
        },
        "name": "placement",
        "type": "placement"
    }
}

TASK [service-ks-register : placement | Creating/deleting endpoints] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:25
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757 `" && echo ansible-tmp-1765371909.8345892-259758-115973060502757="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpljmhemto TO /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757/ /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nwzaxhjytfztfvjgmerxoqzvyudkkixi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371909.8345892-259758-115973060502757/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=placement -> http://192.168.0.201:8780 -> internal) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "9ec5b27eda3240a1a447c7d4a80138b2",
        "interface": "internal",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/9ec5b27eda3240a1a447c7d4a80138b2"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "78428a714afc40ee827309b627d1a39f",
        "url": "http://192.168.0.201:8780"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "internal",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "placement",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:8780",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Placement Service",
            "name": "placement",
            "type": "placement"
        },
        {
            "interface": "internal",
            "url": "http://192.168.0.201:8780"
        }
    ]
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320 `" && echo ansible-tmp-1765371913.1682632-259758-198048865731320="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8_d7fpom TO /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320/ /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-oeqbvbgpngakledjmvonlgfmsggtkpnp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371913.1682632-259758-198048865731320/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=placement -> http://192.168.0.201:8780 -> public) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "4f0326f0b7ab46a5a6f3f7ee9a92c0e5",
        "interface": "public",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/4f0326f0b7ab46a5a6f3f7ee9a92c0e5"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "78428a714afc40ee827309b627d1a39f",
        "url": "http://192.168.0.201:8780"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "public",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "placement",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:8780",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "Placement Service",
            "name": "placement",
            "type": "placement"
        },
        {
            "interface": "public",
            "url": "http://192.168.0.201:8780"
        }
    ]
}

TASK [service-ks-register : placement | Creating projects] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:50
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010 `" && echo ansible-tmp-1765371916.3787847-260329-269063766115010="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpmqppiqva TO /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010/ /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-chvmmbddokuvizdapovgpjazjbldpcpp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371916.3787847-260329-269063766115010/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=service) => {
    "action": "openstack.cloud.project",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain": "default",
            "extra_specs": null,
            "interface": "internal",
            "is_enabled": null,
            "name": "service",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "service",
    "project": {
        "description": "",
        "domain_id": "default",
        "id": "3e1d884058424621b0335f6a041c2d4a",
        "is_domain": false,
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/projects/3e1d884058424621b0335f6a041c2d4a"
        },
        "name": "service",
        "options": {},
        "parent_id": "default",
        "tags": []
    }
}

TASK [service-ks-register : placement | Creating/deleting users] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:67
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246 `" && echo ansible-tmp-1765371919.6404974-260527-75755477932246="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7kl7kpx6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246/ /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fjucirjvkkltnxpvcrgxdzyszhtymbgo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371919.6404974-260527-75755477932246/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => (item=placement -> service) => {
    "action": "openstack.cloud.identity_user",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": true,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "default_project": "service",
            "description": null,
            "domain": "default",
            "email": null,
            "interface": "internal",
            "is_enabled": true,
            "name": "placement",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "update_password": "always",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "7CtOOKEDfgTlbXYGc47kgLSsrxNPuGabnyrL8fTz",
        "project": "service",
        "role": "admin",
        "user": "placement"
    },
    "user": {
        "default_project_id": "3e1d884058424621b0335f6a041c2d4a",
        "description": null,
        "domain_id": "default",
        "email": null,
        "id": "8734201d20124ff2a5095d25c2f94be3",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/users/8734201d20124ff2a5095d25c2f94be3"
        },
        "name": "placement",
        "options": {},
        "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
        "password_expires_at": null
    },
    "warnings": [
        "Module did not set no_log for update_password"
    ]
}

TASK [service-ks-register : placement | Creating roles] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:93
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757 `" && echo ansible-tmp-1765371923.8802657-260792-94006182552757="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpddrgu2yq TO /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757/ /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ghfrtgbhrbkqwtfmjjjeofytiwoivvfu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371923.8802657-260792-94006182552757/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=admin) => {
    "action": "openstack.cloud.identity_role",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain_id": null,
            "interface": "internal",
            "name": "admin",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "admin",
    "role": {
        "description": null,
        "domain_id": null,
        "id": "5c609e9185ea4b52b7299d27240aebd9",
        "links": {
            "self": "http://192.168.0.201:5000/v3/roles/5c609e9185ea4b52b7299d27240aebd9"
        },
        "name": "admin",
        "options": {
            "immutable": true
        }
    }
}

TASK [service-ks-register : placement | Granting/revoking user roles] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:109
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407 `" && echo ansible-tmp-1765371927.2138286-260924-28376117372407="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpszxtqh7z TO /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407/ /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hmlokzxzvzeszvgclfbvlvyvoesoisty ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371927.2138286-260924-28376117372407/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=placement -> service -> admin) => {
    "action": "openstack.cloud.role_assignment",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "domain": null,
            "group": null,
            "group_domain": null,
            "interface": "internal",
            "project": "service",
            "project_domain": null,
            "region_name": "RegionOne",
            "role": "admin",
            "role_domain": null,
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "system": null,
            "timeout": 180,
            "user": "placement",
            "user_domain": null,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "7CtOOKEDfgTlbXYGc47kgLSsrxNPuGabnyrL8fTz",
        "project": "service",
        "role": "admin",
        "user": "placement"
    }
}

TASK [placement : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/deploy.yml:4
skipping: [localhost] => {
    "changed": false,
    "false_condition": "placement_dev_mode | bool",
    "skip_reason": "Conditional result was False"
}

TASK [placement : Ensuring config directories exist] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408 `" && echo ansible-tmp-1765371930.9271605-261107-281077751313408="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpyjddmxkq TO /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408/ /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lelkaqzwltsfumwqzprkexxhysmdrnpg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371930.9271605-261107-281077751313408/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/placement-api"
        },
        "before": {
            "path": "/etc/kolla/placement-api"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/placement-api",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/placement-api",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [placement : Check if policies shall be overwritten] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [placement : Set placement policy file] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:24
skipping: [localhost] => {
    "changed": false,
    "false_condition": "placement_policy.results | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [placement : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:31
skipping: [localhost] => {
    "changed": false,
    "false_condition": "placement_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [placement : Copying over config.json files for services] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:35
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480 `" && echo ansible-tmp-1765371931.7257156-261162-253625366973480="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpcpt8onsv TO /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/ /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rwaipigwqvdsqahhvgqyfmuchqnrxsjy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8vq8chwt TO /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/ /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mjrbliqtrvlxoyedpgjkwbszkhjhwsos ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371931.7257156-261162-253625366973480/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "6adfbd3ed558b0b2fee45e08ef6fb604627cf9c5",
    "dest": "/etc/kolla/placement-api/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/placement-api/config.json"
        },
        "before": {
            "path": "/etc/kolla/placement-api/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "placement-api.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/placement-api/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/placement-api/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/placement-api/config.json",
    "size": 1012,
    "state": "file",
    "uid": 1000
}

TASK [placement : Copying over placement.conf] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:43
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780 `" && echo ansible-tmp-1765371932.657735-261249-159338928732780="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6h_ez74g TO /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/ /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qzeqzlzygydfkmfbruyhipjluhpmxztj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpk2bra90d TO /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/ /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mqeyukhdgpesgiwjrnxaeecqeworkmvo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371932.657735-261249-159338928732780/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "54c3e6c6c06c72ebcff3a9941f5fccb3ec40a9da",
    "dest": "/etc/kolla/placement-api/placement.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/placement-api/placement.conf"
        },
        "before": {
            "path": "/etc/kolla/placement-api/placement.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/placement-api/placement.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/placement-api/placement.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/templates/placement.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/placement.conf",
                "/etc/kolla/config/placement/placement-api.conf",
                "/etc/kolla/config/placement/localhost/placement.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv1h0oo0t/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/placement-api/placement.conf",
    "size": 1010,
    "state": "file",
    "uid": 1000
}

TASK [placement : Copying over placement-api wsgi configuration] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:58
skipping: [localhost] => (item=/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/templates/placement-api-wsgi.conf.j2)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "placement_wsgi_provider == \"apache\"",
    "item": "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/templates/placement-api-wsgi.conf.j2",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [Configure uWSGI for Placement] *******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:76
included: service-uwsgi-config for localhost

TASK [service-uwsgi-config : Copying over placement-api uWSGI config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-uwsgi-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038 `" && echo ansible-tmp-1765371933.994893-261308-167500380415038="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpghnid2pm TO /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/ /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uqwbdbjphfzmcuvluvemokjwdqzubquw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp44adl9zv TO /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/ /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kfsiaayhitbxwejyulhptivumhbcjpjt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371933.994893-261308-167500380415038/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "69ba5d2a4a187a5e68be05d84d432b1aeab1c79b",
    "dest": "/etc/kolla/placement-api/placement-api-uwsgi.ini",
    "diff": {
        "after": {
            "path": "/etc/kolla/placement-api/placement-api-uwsgi.ini"
        },
        "before": {
            "path": "/etc/kolla/placement-api/placement-api-uwsgi.ini"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "uwsgi.ini.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/placement-api/placement-api-uwsgi.ini",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/placement-api/placement-api-uwsgi.ini",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/placement-api/placement-api-uwsgi.ini",
    "size": 634,
    "state": "file",
    "uid": 1000
}

TASK [placement : Copying over migrate-db.rc.j2 configuration] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:93
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854 `" && echo ansible-tmp-1765371935.170658-261359-202273305712854="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9wkvorof TO /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/ /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zgrcatinxjphpnhxcwauogkmzowogdtr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjk0y2ghi TO /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/ /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zphekyyrjtrbxeqtlsnofxkbnvppefei ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371935.170658-261359-202273305712854/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "b3564f6896a002bade7ac58f0e3250679ccb2d0d",
    "dest": "/etc/kolla/placement-api/migrate-db.rc",
    "diff": {
        "after": {
            "path": "/etc/kolla/placement-api/migrate-db.rc"
        },
        "before": {
            "path": "/etc/kolla/placement-api/migrate-db.rc"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "migrate-db.rc.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/placement-api/migrate-db.rc",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/placement-api/migrate-db.rc",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/placement-api/migrate-db.rc",
    "size": 266,
    "state": "file",
    "uid": 1000
}

TASK [placement : Copying over existing policy file] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/config.yml:103
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "placement_policy_file is defined",
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-check-containers : placement | Check containers] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715 `" && echo ansible-tmp-1765371936.3418696-261424-13028360109715="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3e3e8y_6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715/ /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-aecaokgspamkcejyagpjcnrssjogirhk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371936.3418696-261424-13028360109715/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "labels": {},
            "name": "placement_api",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ]
        }
    },
    "item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "result": false
}

TASK [service-check-containers : placement | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'placement-api', 'value': {'container_name': 'placement_api', 'group': 'placement-api', 'image': 'quay.io/openstack.kolla/placement-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8780'], 'timeout': '30'}, 'wsgi': 'placement.wsgi.api:application', 'haproxy': {'placement_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}, 'placement_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8780', 'listen_port': '8780', 'tls_backend': False, 'backend_http_extra': ['option httpchk GET /']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "placement-api",
        "value": {
            "container_name": "placement_api",
            "dimensions": {},
            "enabled": true,
            "group": "placement-api",
            "haproxy": {
                "placement_api": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                },
                "placement_api_external": {
                    "backend_http_extra": [
                        "option httpchk GET /"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8780",
                    "mode": "http",
                    "port": "8780",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8780"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "placement.wsgi.api:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [placement : Creating placement databases] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827 `" && echo ansible-tmp-1765371937.9154253-261523-262095356560827="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpdk1te49z TO /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827/ /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-yyurpbkcodpjgvtaaengsiacvcflvelb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371937.9154253-261523-262095356560827/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_db",
    "changed": false,
    "db": "placement",
    "db_list": [
        "placement"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "placement"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    }
}

TASK [placement : Creating placement databases user and setting permissions] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/bootstrap.yml:19
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649 `" && echo ansible-tmp-1765371940.3376875-261707-164850936121649="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwy9qgfl3 TO /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649/ /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-slhvcdvdlycgqhbiyaevuwesihixjcys ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371940.3376875-261707-164850936121649/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_user",
    "changed": false,
    "invocation": {
        "module_args": {
            "append_privs": true,
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "config_file": "/var/lib/ansible/.my.cnf",
            "connect_timeout": 30,
            "encrypted": false,
            "host": "%",
            "host_all": false,
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "name": "placement",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "plugin": null,
            "plugin_auth_string": null,
            "plugin_hash_string": null,
            "priv": "placement.*:ALL",
            "resource_limits": null,
            "sql_log_bin": true,
            "state": "present",
            "tls_requires": null,
            "update_password": "always",
            "user": "placement"
        }
    },
    "msg": "User unchanged",
    "user": "placement"
}

TASK [placement : Running placement bootstrap container] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/bootstrap_service.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990 `" && echo ansible-tmp-1765371943.1633756-261888-237621261491990="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmph95punk6 TO /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990/ /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fdxalvtcrqlquieydtuebwpgxpospzxl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371943.1633756-261888-237621261491990/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_BOOTSTRAP": null,
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "bootstrap-placement"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/placement-api:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "bootstrap_placement",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/placement-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "+ sudo -E kolla_set_configs\n2025-12-10 14:05:44.561 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:05:44.561 INFO Validating config file\n2025-12-10 14:05:44.561 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:05:44.564 INFO Copying service configuration files\n2025-12-10 14:05:44.564 INFO Copying /var/lib/kolla/config_files/placement.conf to /etc/placement/placement.conf\n2025-12-10 14:05:44.566 INFO Setting permission for /etc/placement/placement.conf\n2025-12-10 14:05:44.566 INFO Copying /var/lib/kolla/config_files/placement-api-uwsgi.ini to /etc/placement/placement-api-uwsgi.ini\n2025-12-10 14:05:44.566 INFO Setting permission for /etc/placement/placement-api-uwsgi.ini\n2025-12-10 14:05:44.567 INFO Copying /var/lib/kolla/config_files/migrate-db.rc to /etc/placement/migrate-db.rc\n2025-12-10 14:05:44.567 INFO Setting permission for /etc/placement/migrate-db.rc\n2025-12-10 14:05:44.567 INFO Writing out command to execute\n2025-12-10 14:05:44.567 INFO Setting permission for /var/log/kolla/placement\n2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api-uwsgi.log\n2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api.log\n2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api.log\n++ cat /run_command\n+ CMD='uwsgi /etc/placement/placement-api-uwsgi.ini'\n+ ARGS=\n+ sudo kolla_copy_cacerts\n+ sudo kolla_install_projects\n+ [[ ! -n '' ]]\n+ . kolla_extend_start\n++ [[ ! -d /var/log/kolla/placement ]]\n+++ stat -c %U:%G /var/log/kolla/placement\n++ [[ placement:kolla != \\p\\l\\a\\c\\e\\m\\e\\n\\t\\:\\k\\o\\l\\l\\a ]]\n+++ stat -c %a /var/log/kolla/placement\n++ [[ 2755 != \\7\\5\\5 ]]\n++ chmod 755 /var/log/kolla/placement\n++ chmod 644 /var/log/kolla/placement/placement-api.log\n++ . /usr/local/bin/kolla_placement_extend_start\n+++ [[ -n 0 ]]\n+++ placement-manage db sync\n+++ placement-manage db online_data_migrations\n+++ exit 0\n",
    "stderr_lines": [
        "+ sudo -E kolla_set_configs",
        "2025-12-10 14:05:44.561 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:05:44.561 INFO Validating config file",
        "2025-12-10 14:05:44.561 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:05:44.564 INFO Copying service configuration files",
        "2025-12-10 14:05:44.564 INFO Copying /var/lib/kolla/config_files/placement.conf to /etc/placement/placement.conf",
        "2025-12-10 14:05:44.566 INFO Setting permission for /etc/placement/placement.conf",
        "2025-12-10 14:05:44.566 INFO Copying /var/lib/kolla/config_files/placement-api-uwsgi.ini to /etc/placement/placement-api-uwsgi.ini",
        "2025-12-10 14:05:44.566 INFO Setting permission for /etc/placement/placement-api-uwsgi.ini",
        "2025-12-10 14:05:44.567 INFO Copying /var/lib/kolla/config_files/migrate-db.rc to /etc/placement/migrate-db.rc",
        "2025-12-10 14:05:44.567 INFO Setting permission for /etc/placement/migrate-db.rc",
        "2025-12-10 14:05:44.567 INFO Writing out command to execute",
        "2025-12-10 14:05:44.567 INFO Setting permission for /var/log/kolla/placement",
        "2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api-uwsgi.log",
        "2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api.log",
        "2025-12-10 14:05:44.568 INFO Setting permission for /var/log/kolla/placement/placement-api.log",
        "++ cat /run_command",
        "+ CMD='uwsgi /etc/placement/placement-api-uwsgi.ini'",
        "+ ARGS=",
        "+ sudo kolla_copy_cacerts",
        "+ sudo kolla_install_projects",
        "+ [[ ! -n '' ]]",
        "+ . kolla_extend_start",
        "++ [[ ! -d /var/log/kolla/placement ]]",
        "+++ stat -c %U:%G /var/log/kolla/placement",
        "++ [[ placement:kolla != \\p\\l\\a\\c\\e\\m\\e\\n\\t\\:\\k\\o\\l\\l\\a ]]",
        "+++ stat -c %a /var/log/kolla/placement",
        "++ [[ 2755 != \\7\\5\\5 ]]",
        "++ chmod 755 /var/log/kolla/placement",
        "++ chmod 644 /var/log/kolla/placement/placement-api.log",
        "++ . /usr/local/bin/kolla_placement_extend_start",
        "+++ [[ -n 0 ]]",
        "+++ placement-manage db sync",
        "+++ placement-manage db online_data_migrations",
        "+++ exit 0"
    ],
    "stdout": "Running batches of 50 until complete\n+-----------------------------+-------------+-----------+\n|          Migration          | Total Found | Completed |\n+-----------------------------+-------------+-----------+\n|    set_root_provider_ids    |      0      |     0     |\n| create_incomplete_consumers |      0      |     0     |\n+-----------------------------+-------------+-----------+\n",
    "stdout_lines": [
        "Running batches of 50 until complete",
        "+-----------------------------+-------------+-----------+",
        "|          Migration          | Total Found | Completed |",
        "+-----------------------------+-------------+-----------+",
        "|    set_root_provider_ids    |      0      |     0     |",
        "| create_incomplete_consumers |      0      |     0     |",
        "+-----------------------------+-------------+-----------+"
    ]
}

TASK [placement : Flush handlers] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/placement/tasks/deploy.yml:13
META: triggered running handlers for localhost

PLAY [Apply role openvswitch] **************************************************

TASK [openvswitch : include_tasks] *********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config-host.yml
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/post-config.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/deploy.yml for localhost

TASK [module-load : Load modules] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:8
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867 `" && echo ansible-tmp-1765371948.7797441-262547-61772609868867="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
Using module file /home/nics/.ansible/collections/ansible_collections/community/general/plugins/modules/modprobe.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpo0e1meh8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867/AnsiballZ_modprobe.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867/ /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867/AnsiballZ_modprobe.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gojoqfvtvwdvhomtjqrjnrvpkqlzvpgm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867/AnsiballZ_modprobe.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371948.7797441-262547-61772609868867/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=openvswitch) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "name": "openvswitch",
            "params": "",
            "persistent": "disabled",
            "state": "present"
        }
    },
    "item": {
        "name": "openvswitch"
    },
    "name": "openvswitch",
    "params": "",
    "state": "present"
}

TASK [module-load : Persist modules via modules-load.d] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:18
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072 `" && echo ansible-tmp-1765371949.2475696-262576-241275591842072="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_fy_czn7 TO /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/ /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hcgtititeblbztgrgfqdepbffpupzphp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8c53pykj TO /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/ /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cqxompslxtpbluyjhgluvhetlsqkctfl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371949.2475696-262576-241275591842072/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=openvswitch) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "aca7c8bb7013e03e6cf531689fb6220d9e469d63",
    "dest": "/etc/modules-load.d/openvswitch.conf",
    "diff": {
        "after": {
            "path": "/etc/modules-load.d/openvswitch.conf"
        },
        "before": {
            "path": "/etc/modules-load.d/openvswitch.conf"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "module-load.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/modules-load.d/openvswitch.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/modules-load.d/openvswitch.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "name": "openvswitch"
    },
    "mode": "0644",
    "owner": "root",
    "path": "/etc/modules-load.d/openvswitch.conf",
    "size": 31,
    "state": "file",
    "uid": 0
}

TASK [module-load : Drop module persistence] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:29
skipping: [localhost] => (item=openvswitch)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "(item.state | default('present')) == 'absent'",
    "item": {
        "name": "openvswitch"
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [openvswitch : Create /run/openvswitch directory on host] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config-host.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_container_engine == 'podman'",
    "skip_reason": "Conditional result was False"
}

TASK [openvswitch : Ensuring config directories exist] *************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599 `" && echo ansible-tmp-1765371950.345724-262627-116941928774599="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpp3m6g6j3 TO /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599/ /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bosklxajwuwlzbxvdykvqqbwgpxorpsz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371950.345724-262627-116941928774599/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/openvswitch-db-server"
        },
        "before": {
            "path": "/etc/kolla/openvswitch-db-server"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/openvswitch-db-server",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "openvswitch-db-server",
        "value": {
            "container_name": "openvswitch_db",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovsdb-client list-dbs"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "openvswitch_db:/var/lib/openvswitch/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/openvswitch-db-server",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707 `" && echo ansible-tmp-1765371950.7280705-262627-36329793437707="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1t6fu_xh TO /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707/ /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mqffnwmtwulxofvcxdraamxchrvjjtde ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371950.7280705-262627-36329793437707/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/openvswitch-vswitchd"
        },
        "before": {
            "path": "/etc/kolla/openvswitch-vswitchd"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/openvswitch-vswitchd",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "openvswitch-vswitchd",
        "value": {
            "container_name": "openvswitch_vswitchd",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovs-appctl version"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/openvswitch-vswitchd",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [openvswitch : Copying over config.json files for services] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config.yml:12
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015 `" && echo ansible-tmp-1765371951.253151-262715-96001174376015="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpooms9bms TO /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/ /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ffdexyvmthzsjrijjyqcdgckqyuwsqqx ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpk_9kecqq TO /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/ /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-spzrvdbuqwgytbxduufqiyycjstxmtob ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371951.253151-262715-96001174376015/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "3142c13c144753e69bda3a13bad0e001006c990a",
    "dest": "/etc/kolla/openvswitch-db-server/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/openvswitch-db-server/config.json"
        },
        "before": {
            "path": "/etc/kolla/openvswitch-db-server/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "openvswitch-db-server.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/openvswitch-db-server/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/openvswitch-db-server/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "openvswitch-db-server",
        "value": {
            "container_name": "openvswitch_db",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovsdb-client list-dbs"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "openvswitch_db:/var/lib/openvswitch/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/openvswitch-db-server/config.json",
    "size": 327,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905 `" && echo ansible-tmp-1765371952.0200043-262715-256004881068905="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7_3u7ske TO /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/ /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iwdthoavqoxspprnagubkelszamtfpvd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpb_k2j2_u TO /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/ /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kvevgfqcbqalbngixltxxftdxtzgttwp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371952.0200043-262715-256004881068905/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "ab5edd20984ec68ab028cf8973286b9ed2d9d5c6",
    "dest": "/etc/kolla/openvswitch-vswitchd/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/openvswitch-vswitchd/config.json"
        },
        "before": {
            "path": "/etc/kolla/openvswitch-vswitchd/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "openvswitch-vswitchd.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/openvswitch-vswitchd/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/openvswitch-vswitchd/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "openvswitch-vswitchd",
        "value": {
            "container_name": "openvswitch_vswitchd",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovs-appctl version"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/openvswitch-vswitchd/config.json",
    "size": 216,
    "state": "file",
    "uid": 1000
}

TASK [openvswitch : Copying over ovs-vsctl wrapper] ****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/config.yml:20
skipping: [localhost] => {
    "changed": false,
    "false_condition": "openvswitch_ovs_vsctl_wrapper_enabled | bool",
    "skip_reason": "Conditional result was False"
}

TASK [service-check-containers : openvswitch | Check containers] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399 `" && echo ansible-tmp-1765371953.0695555-262843-165247223502399="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpj3gea31_ TO /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399/ /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gkbkbtggdxjyccqstzpguiwkymfwzedj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371953.0695555-262843-165247223502399/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovsdb-client list-dbs"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble",
            "labels": {},
            "name": "openvswitch_db",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "openvswitch_db:/var/lib/openvswitch/"
            ]
        }
    },
    "item": {
        "key": "openvswitch-db-server",
        "value": {
            "container_name": "openvswitch_db",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovsdb-client list-dbs"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "openvswitch_db:/var/lib/openvswitch/"
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281 `" && echo ansible-tmp-1765371954.119474-262843-25531128538281="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4ed5oi9o TO /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281/ /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-suhkdigfktmljbejxkdiehlsvjqjwclc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371954.119474-262843-25531128538281/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovs-appctl version"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble",
            "labels": {},
            "name": "openvswitch_vswitchd",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "item": {
        "key": "openvswitch-vswitchd",
        "value": {
            "container_name": "openvswitch_vswitchd",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovs-appctl version"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : openvswitch | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'openvswitch-db-server', 'value': {'container_name': 'openvswitch_db', 'image': 'quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'volumes': ['/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/', 'openvswitch_db:/var/lib/openvswitch/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovsdb-client list-dbs'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "openvswitch-db-server",
        "value": {
            "container_name": "openvswitch_db",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovsdb-client list-dbs"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-db-server:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/openvswitch-db-server/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/",
                "openvswitch_db:/var/lib/openvswitch/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'openvswitch-vswitchd', 'value': {'container_name': 'openvswitch_vswitchd', 'image': 'quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble', 'enabled': True, 'group': 'openvswitch', 'host_in_groups': True, 'privileged': True, 'volumes': ['/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run/openvswitch:/run/openvswitch:shared', 'kolla_logs:/var/log/kolla/'], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'ovs-appctl version'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "openvswitch-vswitchd",
        "value": {
            "container_name": "openvswitch_vswitchd",
            "dimensions": {},
            "enabled": true,
            "group": "openvswitch",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "ovs-appctl version"
                ],
                "timeout": "30"
            },
            "host_in_groups": true,
            "image": "quay.io/openstack.kolla/openvswitch-vswitchd:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/openvswitch-vswitchd/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run/openvswitch:/run/openvswitch:shared",
                "kolla_logs:/var/log/kolla/"
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [openvswitch : Flush Handlers] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/deploy.yml:8
META: triggered running handlers for localhost

TASK [openvswitch : Set system-id, hostname and hw-offload] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/post-config.yml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510 `" && echo ansible-tmp-1765371955.489808-263053-9157076206510="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp52bdfwqx TO /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510/ /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hhduujngjkyiewytijfrbscvjcawbzvf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371955.489808-263053-9157076206510/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'col': 'external_ids', 'name': 'system-id', 'value': 'nics-VMware20-1'}) => {
    "action": "openvswitch_db",
    "ansible_loop_var": "item",
    "changed": false,
    "commands": [],
    "invocation": {
        "module_args": {
            "col": "external_ids",
            "database_socket": null,
            "key": "system-id",
            "ovs-vsctl": "/usr/bin/ovs-vsctl",
            "record": ".",
            "state": "present",
            "table": "Open_vSwitch",
            "timeout": 5,
            "value": "nics-VMware20-1"
        }
    },
    "item": {
        "col": "external_ids",
        "name": "system-id",
        "value": "nics-VMware20-1"
    }
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857 `" && echo ansible-tmp-1765371957.8035724-263053-4449940563857="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpq9zjpzne TO /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857/ /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xalgydyqoqoseximjfhihvladggcyqav ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371957.8035724-263053-4449940563857/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'col': 'external_ids', 'name': 'hostname', 'value': 'nics-VMware20-1'}) => {
    "action": "openvswitch_db",
    "ansible_loop_var": "item",
    "changed": false,
    "commands": [],
    "invocation": {
        "module_args": {
            "col": "external_ids",
            "database_socket": null,
            "key": "hostname",
            "ovs-vsctl": "/usr/bin/ovs-vsctl",
            "record": ".",
            "state": "present",
            "table": "Open_vSwitch",
            "timeout": 5,
            "value": "nics-VMware20-1"
        }
    },
    "item": {
        "col": "external_ids",
        "name": "hostname",
        "value": "nics-VMware20-1"
    }
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446 `" && echo ansible-tmp-1765371959.997689-263053-219955556494446="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjjq5aign TO /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446/ /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-szyeanlvnxvwnqelrcvafqqvrjwcsnuh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371959.997689-263053-219955556494446/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'col': 'other_config', 'name': 'hw-offload', 'value': True, 'state': 'absent'}) => {
    "action": "openvswitch_db",
    "ansible_loop_var": "item",
    "changed": false,
    "commands": [],
    "invocation": {
        "module_args": {
            "col": "other_config",
            "database_socket": null,
            "key": "hw-offload",
            "ovs-vsctl": "/usr/bin/ovs-vsctl",
            "record": ".",
            "state": "absent",
            "table": "Open_vSwitch",
            "timeout": 5,
            "value": "true"
        }
    },
    "item": {
        "col": "other_config",
        "name": "hw-offload",
        "state": "absent",
        "value": true
    }
}

TASK [openvswitch : Ensuring OVS bridge is properly setup] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/post-config.yml:25
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416 `" && echo ansible-tmp-1765371962.2737956-263431-32794735011416="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2a_dmses TO /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416/ /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iyqeeqdogmsoajqebebhrbrqpfazvstd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371962.2737956-263431-32794735011416/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=br-ex) => {
    "action": "openvswitch_bridge",
    "ansible_loop_var": "item",
    "changed": false,
    "commands": [],
    "invocation": {
        "module_args": {
            "bridge": "br-ex",
            "database_socket": null,
            "external_ids": null,
            "fail_mode": "standalone",
            "ovs-vsctl": "/usr/bin/ovs-vsctl",
            "parent": null,
            "set": null,
            "state": "present",
            "timeout": 5,
            "vlan": null
        }
    },
    "item": "br-ex"
}

TASK [openvswitch : Ensuring OVS ports are properly setup] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/openvswitch/tasks/post-config.yml:39
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265 `" && echo ansible-tmp-1765371964.6724687-263580-56967374803265="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0n_nyh4n TO /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265/ /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rpbceckdqaizkeddywzxrkhticewdder ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371964.6724687-263580-56967374803265/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=['br-ex', 'veth1']) => {
    "action": "openvswitch_port",
    "ansible_loop_var": "item",
    "changed": false,
    "commands": [],
    "invocation": {
        "module_args": {
            "bridge": "br-ex",
            "database_socket": null,
            "external_ids": {},
            "ovs-vsctl": "/usr/bin/ovs-vsctl",
            "port": "veth1",
            "set": null,
            "state": "present",
            "tag": null,
            "timeout": 5
        }
    },
    "item": [
        "br-ex",
        "veth1"
    ]
}

PLAY [Apply role ovs-dpdk] *****************************************************
skipping: no hosts matched

PLAY [Apply role ovn-controller] ***********************************************
skipping: no hosts matched

PLAY [Apply role ovn-db] *******************************************************
skipping: no hosts matched

PLAY [Bootstrap nova API databases] ********************************************

TASK [Bootstrap deploy] ********************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/nova.yml:49
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config_bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap_service.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/map_cell0.yml
included: nova for localhost

TASK [nova : Creating Nova databases] ******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568 `" && echo ansible-tmp-1765371967.3300977-263698-155652778987568="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpoi6jy1fd TO /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568/ /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wvyuwkhzgvjrtvcmstwkykmorypbidjb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371967.3300977-263698-155652778987568/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova_cell0) => {
    "action": "mysql_db",
    "ansible_loop_var": "item",
    "changed": false,
    "db": "nova_cell0",
    "db_list": [
        "nova_cell0"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "nova_cell0"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    },
    "item": "nova_cell0"
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874 `" && echo ansible-tmp-1765371969.7720609-263698-179312788918874="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkhw67f0h TO /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874/ /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kungeffjwhidrarxsahfckrbetgqycww ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371969.7720609-263698-179312788918874/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova_api) => {
    "action": "mysql_db",
    "ansible_loop_var": "item",
    "changed": false,
    "db": "nova_api",
    "db_list": [
        "nova_api"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "nova_api"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    },
    "item": "nova_api"
}

TASK [nova : Creating Nova databases user and setting permissions] *************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap.yml:21
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348 `" && echo ansible-tmp-1765371972.04421-264031-6614525240348="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpen0svwg0 TO /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348/ /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lodxedfiyhocxvneudvkchppofhtemdk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371972.04421-264031-6614525240348/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=None) => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787 `" && echo ansible-tmp-1765371974.3534753-264031-11058558521787="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7_kjohkx TO /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787/ /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qscoperlvlfigzgbjffsjnrfetaqtzvj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371974.3534753-264031-11058558521787/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=None) => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}
ok: [localhost] => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}

TASK [nova : Ensuring config directories exist] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config_bootstrap.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561 `" && echo ansible-tmp-1765371976.6181445-264339-107256401971561="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7bttu8s8 TO /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561/ /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gcblvspszdxfyxldkhhhtuylivootapp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371976.6181445-264339-107256401971561/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api-bootstrap"
        },
        "before": {
            "path": "/etc/kolla/nova-api-bootstrap"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-api-bootstrap",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-api-bootstrap",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:2
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_copy_certs | bool",
    "item": {
        "key": "nova-api-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-api"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:12
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_copy_certs | bool",
    "item": {
        "key": "nova-api-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-api"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:30
skipping: [localhost] => (item={'key': 'nova-api-bootstrap', 'value': {'group': 'nova-api', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_copy_certs | bool",
    "item": {
        "key": "nova-api-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-api"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova : Copying over config.json files for nova-api-bootstrap] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config_bootstrap.yml:26
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002 `" && echo ansible-tmp-1765371977.3850515-264373-225982142750002="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2svjopch TO /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/ /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zubfbouynrctyedncdsarvjlwczmmnmh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpo54621r5 TO /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/ /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rtbdmzogqobupvhttykjbzjwngsstupw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371977.3850515-264373-225982142750002/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "e0c84ccf022bc5d6578034a1c639179d3d1c57aa",
    "dest": "/etc/kolla/nova-api-bootstrap/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api-bootstrap/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-api-bootstrap/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-api-bootstrap.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-api-bootstrap/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-api-bootstrap/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-api-bootstrap/config.json",
    "size": 390,
    "state": "file",
    "uid": 1000
}

TASK [nova : Copying over nova.conf for nova-api-bootstrap] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config_bootstrap.yml:34
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678 `" && echo ansible-tmp-1765371978.199833-264435-235003315506678="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd71e4j3v TO /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/ /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bayopatyemozcqfsqlqktcsutviblvpv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8rsmav_h TO /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/ /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jpdlnhxngabirmfgyxdjrhnlfgofbbvj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371978.199833-264435-235003315506678/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "cdfc64ea4032b5d05a993814c7553e6a431182e9",
    "dest": "/etc/kolla/nova-api-bootstrap/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api-bootstrap/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-api-bootstrap/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-api-bootstrap/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-api-bootstrap/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-api.conf",
                "/etc/kolla/config/nova/localhost/nova.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv17bz40w/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-api-bootstrap/nova.conf",
    "size": 3086,
    "state": "file",
    "uid": 1000
}

TASK [nova : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap.yml:53
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_dev_mode | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova : Running Nova API bootstrap container] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/bootstrap_service.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675 `" && echo ansible-tmp-1765371979.7091446-264501-200104552851675="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptk9adwvo TO /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675/ /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nfgtwqnnygyooslyeupvklqldgqgpbfh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371979.7091446-264501-200104552851675/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "nova-api-bootstrap",
                "KOLLA_UPGRADE": null
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "nova_api_bootstrap",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-api-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "+ sudo -E kolla_set_configs\n2025-12-10 14:06:20.918 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:06:20.918 INFO Validating config file\n2025-12-10 14:06:20.918 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:06:20.921 INFO Copying service configuration files\n2025-12-10 14:06:20.921 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:06:20.923 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:06:20.923 INFO Writing out command to execute\n2025-12-10 14:06:20.923 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n++ cat /run_command\n+ CMD=false\n+ ARGS=\n+ sudo kolla_copy_cacerts\n+ sudo kolla_install_projects\n+ [[ ! -n '' ]]\n+ . kolla_extend_start\n++ [[ ! -d /var/log/kolla/nova ]]\n+++ stat -c %a /var/log/kolla/nova\n++ [[ 2755 != \\7\\5\\5 ]]\n++ chmod 755 /var/log/kolla/nova\n++ . /usr/local/bin/kolla_nova_extend_start\n+++ [[ -n '' ]]\n+++ [[ -n 0 ]]\n+++ nova-manage api_db sync\n+++ nova-manage db sync --local_cell\n+++ exit 0\n",
    "stderr_lines": [
        "+ sudo -E kolla_set_configs",
        "2025-12-10 14:06:20.918 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:06:20.918 INFO Validating config file",
        "2025-12-10 14:06:20.918 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:06:20.921 INFO Copying service configuration files",
        "2025-12-10 14:06:20.921 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:06:20.923 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:06:20.923 INFO Writing out command to execute",
        "2025-12-10 14:06:20.923 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:06:20.924 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log",
        "++ cat /run_command",
        "+ CMD=false",
        "+ ARGS=",
        "+ sudo kolla_copy_cacerts",
        "+ sudo kolla_install_projects",
        "+ [[ ! -n '' ]]",
        "+ . kolla_extend_start",
        "++ [[ ! -d /var/log/kolla/nova ]]",
        "+++ stat -c %a /var/log/kolla/nova",
        "++ [[ 2755 != \\7\\5\\5 ]]",
        "++ chmod 755 /var/log/kolla/nova",
        "++ . /usr/local/bin/kolla_nova_extend_start",
        "+++ [[ -n '' ]]",
        "+++ [[ -n 0 ]]",
        "+++ nova-manage api_db sync",
        "+++ nova-manage db sync --local_cell",
        "+++ exit 0"
    ],
    "stdout": "",
    "stdout_lines": []
}

TASK [nova : Create cell0 mappings] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/map_cell0.yml:5
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169 `" && echo ansible-tmp-1765371989.337821-265223-273465988003169="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpktztrpui TO /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169/ /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-nqgfhpeydqbioawxukydduhhwzayxvzd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371989.337821-265223-273465988003169/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "bash -c 'sudo -E kolla_set_configs && sudo -E kolla_copy_cacerts && nova-manage cell_v2 map_cell0 --database_connection mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.201:3306/nova_cell0'",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "nova-api-map-cell0"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "nova_api_map_cell0",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-api-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "2025-12-10 14:06:30.619 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:06:30.620 INFO Validating config file\n2025-12-10 14:06:30.620 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:06:30.622 INFO Copying service configuration files\n2025-12-10 14:06:30.623 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:06:30.624 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:06:30.625 INFO Writing out command to execute\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:06:30.626 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n",
    "stderr_lines": [
        "2025-12-10 14:06:30.619 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:06:30.620 INFO Validating config file",
        "2025-12-10 14:06:30.620 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:06:30.622 INFO Copying service configuration files",
        "2025-12-10 14:06:30.623 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:06:30.624 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:06:30.625 INFO Writing out command to execute",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:06:30.625 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:06:30.626 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log"
    ],
    "stdout": "Cell0 is already setup\n",
    "stdout_lines": [
        "Cell0 is already setup"
    ]
}

TASK [nova-cell : Get a list of existing cells] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/get_cell_settings.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747 `" && echo ansible-tmp-1765371995.266787-265455-186918929010747="` echo /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprkzw2mzn TO /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747/ /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ctnkozoxklypnzshmwrzicconasimnma ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765371995.266787-265455-186918929010747/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "bash -c 'sudo -E kolla_set_configs && sudo -E kolla_copy_cacerts && nova-manage cell_v2 list_cells --verbose'",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "nova-list-cells"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "nova_list_cells",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-api-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "2025-12-10 14:06:36.324 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:06:36.325 INFO Validating config file\n2025-12-10 14:06:36.325 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:06:36.327 INFO Copying service configuration files\n2025-12-10 14:06:36.327 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:06:36.329 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:06:36.329 INFO Writing out command to execute\n2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n",
    "stderr_lines": [
        "2025-12-10 14:06:36.324 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:06:36.325 INFO Validating config file",
        "2025-12-10 14:06:36.325 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:06:36.327 INFO Copying service configuration files",
        "2025-12-10 14:06:36.327 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:06:36.329 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:06:36.329 INFO Writing out command to execute",
        "2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:06:36.329 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:06:36.330 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log"
    ],
    "stdout": "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n|  Name |                 UUID                 |                                  Transport URL                                   |                                     Database Connection                                     | Disabled |\n+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n|       | 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee | rabbit://openstack:RXdStyDdvVIjACW4bAcjFiQ9rKWBA6kJCDU3ZNbw@192.168.0.195:5672// |    mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova    |  False   |\n| cell0 | 00000000-0000-0000-0000-000000000000 |                                     none:///                                     | mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova_cell0 |  False   |\n+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n",
    "stdout_lines": [
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+",
        "|  Name |                 UUID                 |                                  Transport URL                                   |                                     Database Connection                                     | Disabled |",
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+",
        "|       | 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee | rabbit://openstack:RXdStyDdvVIjACW4bAcjFiQ9rKWBA6kJCDU3ZNbw@192.168.0.195:5672// |    mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova    |  False   |",
        "| cell0 | 00000000-0000-0000-0000-000000000000 |                                     none:///                                     | mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova_cell0 |  False   |",
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+"
    ]
}

TASK [nova-cell : Extract current cell settings from list] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/get_cell_settings.yml:23
ok: [localhost] => {
    "ansible_facts": {
        "nova_cell_settings": {
            "cell_database": "mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova_cell0",
            "cell_disabled": "False",
            "cell_message_queue": "none:///",
            "cell_name": "cell0",
            "cell_uuid": "00000000-0000-0000-0000-000000000000"
        }
    },
    "changed": false
}

TASK [nova : Update cell0 mappings] ********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/map_cell0.yml:34
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_cell_settings | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/map_cell0.yml:67
skipping: [localhost] => {
    "changed": false,
    "false_condition": "map_cell0.changed",
    "skip_reason": "Conditional result was False"
}

TASK [Bootstrap upgrade] *******************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/nova.yml:59
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_action == 'upgrade'",
    "skip_reason": "Conditional result was False"
}

PLAY [Bootstrap nova cell databases] *******************************************

TASK [Bootstrap deploy] ********************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/nova.yml:85
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/rabbitmq.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config_bootstrap.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/bootstrap_service.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/create_cells.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/get_cell_settings.yml
included: nova-cell for localhost

TASK [nova-cell : Creating Nova cell database] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/bootstrap.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590 `" && echo ansible-tmp-1765372001.4284291-265820-10733014020590="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpotcb2xvp TO /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590/ /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wckrupmuodzaojblaeecajgadnfxtwlb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372001.4284291-265820-10733014020590/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "action": "mysql_db",
    "changed": false,
    "db": "nova",
    "db_list": [
        "nova"
    ],
    "executed_commands": [],
    "invocation": {
        "module_args": {
            "ca_cert": null,
            "check_hostname": null,
            "check_implicit_admin": false,
            "client_cert": null,
            "client_key": null,
            "collation": "",
            "config_file": "/var/lib/ansible/.my.cnf",
            "config_overrides_defaults": false,
            "connect_timeout": 30,
            "dump_extra_args": null,
            "encoding": "",
            "force": false,
            "hex_blob": false,
            "ignore_tables": [],
            "login_host": "192.168.0.201",
            "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "login_port": 3306,
            "login_unix_socket": null,
            "login_user": "root_shard_0",
            "master_data": 0,
            "name": [
                "nova"
            ],
            "quick": true,
            "restrict_config_file": false,
            "single_transaction": false,
            "skip_lock_tables": false,
            "state": "present",
            "target": null,
            "unsafe_login_password": false,
            "use_shell": false
        }
    }
}

TASK [nova-cell : Creating Nova cell database user and setting permissions] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/bootstrap.yml:18
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215 `" && echo ansible-tmp-1765372003.8389502-265952-75471008358215="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqmot41vn TO /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215/ /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-welwvomvrmdpkslnrhfuleglqbnuxdhz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372003.8389502-265952-75471008358215/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-rabbitmq/tasks/main.yml:9
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-rabbitmq/tasks/main.yml:22
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789 `" && echo ansible-tmp-1765372006.3942592-266109-274507109466789="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_9as_jrh TO /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789/ /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-muzkktwnkedjphxisojlbwdokcemuyyh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372006.3942592-266109-274507109466789/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=None) => {
    "attempts": 1,
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}
ok: [localhost -> {{ service_rabbitmq_delegate_host }}] => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}

TASK [service-rabbitmq : Ensure RabbitMQ vhosts exist for nova] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-rabbitmq/tasks/main.yml:9
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [service-rabbitmq : Ensure RabbitMQ users exist for nova] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-rabbitmq/tasks/main.yml:22
skipping: [localhost] => (item=None)  => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}
skipping: [localhost] => {
    "censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result",
    "changed": false
}

TASK [nova-cell : Ensuring config directories exist] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config_bootstrap.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073 `" && echo ansible-tmp-1765372013.7529945-266646-256744544848073="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpvd8vz8rf TO /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073/ /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ivgljshtpwucclphqvthuvbbcqxsjqcl ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372013.7529945-266646-256744544848073/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-cell-bootstrap"
        },
        "before": {
            "path": "/etc/kolla/nova-cell-bootstrap"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-cell-bootstrap",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-cell-bootstrap",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [nova-cell : Copying over config.json files for nova-cell-bootstrap] ******
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config_bootstrap.yml:14
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284 `" && echo ansible-tmp-1765372014.193645-266675-53888701403284="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpr_4plxeb TO /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/ /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-czjujqvpmpcvgubdaptidbvvdkceiafe ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpuonuii2k TO /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/ /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ufuiijzpmstuctdcztodguqieasmkkik ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372014.193645-266675-53888701403284/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "e0c84ccf022bc5d6578034a1c639179d3d1c57aa",
    "dest": "/etc/kolla/nova-cell-bootstrap/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-cell-bootstrap/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-cell-bootstrap/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-cell-bootstrap.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-cell-bootstrap/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-cell-bootstrap/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-cell-bootstrap/config.json",
    "size": 390,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying over nova.conf for nova-cell-bootstrap] **************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config_bootstrap.yml:22
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777 `" && echo ansible-tmp-1765372015.005534-266759-83099171055777="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp96vyhneg TO /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/ /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-peblozcgvrstoiufgpdyklffezmowlbg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzyk9qrw7 TO /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/ /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iflpcizggdfugmkshcashjdhbutpbyeo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372015.005534-266759-83099171055777/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "803f3d31d89e29df3577211d08a350adb31d2b97",
    "dest": "/etc/kolla/nova-cell-bootstrap/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-cell-bootstrap/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-cell-bootstrap/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-cell-bootstrap/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-cell-bootstrap/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-conductor.conf",
                "/etc/kolla/config/nova/localhost/nova.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpuvhtrwbf/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-cell-bootstrap/nova.conf",
    "size": 2542,
    "state": "file",
    "uid": 1000
}

TASK [service-cert-copy : nova | Copying over extra CA certificates] ***********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:2
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_cell_copy_certs | bool",
    "item": {
        "key": "nova-cell-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-conductor"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-cert-copy : nova | Copying over backend internal TLS certificate] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:12
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_cell_copy_certs | bool",
    "item": {
        "key": "nova-cell-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-conductor"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-cert-copy : nova | Copying over backend internal TLS key] ********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-cert-copy/tasks/main.yml:30
skipping: [localhost] => (item={'key': 'nova-cell-bootstrap', 'value': {'group': 'nova-conductor', 'enabled': True}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_cell_copy_certs | bool",
    "item": {
        "key": "nova-cell-bootstrap",
        "value": {
            "enabled": true,
            "group": "nova-conductor"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova-cell : Running Nova cell bootstrap container] ***********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/bootstrap_service.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822 `" && echo ansible-tmp-1765372016.9325325-266885-216779143406822="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfegoz9iu TO /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822/ /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iqdehxdbebdurhrmtteyfqjpxuoqkzfm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372016.9325325-266885-216779143406822/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "nova-cell-bootstrap",
                "KOLLA_UPGRADE": null
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "nova_cell_bootstrap",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-cell-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "",
                ""
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "+ sudo -E kolla_set_configs\n2025-12-10 14:06:58.187 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:06:58.188 INFO Validating config file\n2025-12-10 14:06:58.188 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:06:58.191 INFO Copying service configuration files\n2025-12-10 14:06:58.191 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:06:58.193 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:06:58.193 INFO Writing out command to execute\n2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:06:58.196 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n++ cat /run_command\n+ CMD=false\n+ ARGS=\n+ sudo kolla_copy_cacerts\n+ sudo kolla_install_projects\n+ [[ ! -n '' ]]\n+ . kolla_extend_start\n++ [[ ! -d /var/log/kolla/nova ]]\n+++ stat -c %a /var/log/kolla/nova\n++ [[ 2755 != \\7\\5\\5 ]]\n++ chmod 755 /var/log/kolla/nova\n++ . /usr/local/bin/kolla_nova_extend_start\n+++ [[ -n '' ]]\n+++ [[ -n 0 ]]\n+++ nova-manage db sync --local_cell\n+++ exit 0\n",
    "stderr_lines": [
        "+ sudo -E kolla_set_configs",
        "2025-12-10 14:06:58.187 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:06:58.188 INFO Validating config file",
        "2025-12-10 14:06:58.188 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:06:58.191 INFO Copying service configuration files",
        "2025-12-10 14:06:58.191 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:06:58.193 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:06:58.193 INFO Writing out command to execute",
        "2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:06:58.194 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:06:58.195 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:06:58.196 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log",
        "++ cat /run_command",
        "+ CMD=false",
        "+ ARGS=",
        "+ sudo kolla_copy_cacerts",
        "+ sudo kolla_install_projects",
        "+ [[ ! -n '' ]]",
        "+ . kolla_extend_start",
        "++ [[ ! -d /var/log/kolla/nova ]]",
        "+++ stat -c %a /var/log/kolla/nova",
        "++ [[ 2755 != \\7\\5\\5 ]]",
        "++ chmod 755 /var/log/kolla/nova",
        "++ . /usr/local/bin/kolla_nova_extend_start",
        "+++ [[ -n '' ]]",
        "+++ [[ -n 0 ]]",
        "+++ nova-manage db sync --local_cell",
        "+++ exit 0"
    ],
    "stdout": "",
    "stdout_lines": []
}

TASK [nova-cell : Get a list of existing cells] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/get_cell_settings.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530 `" && echo ansible-tmp-1765372023.1566393-267448-22239546553530="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpfpsno7z1 TO /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530/ /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-okljjvquuhrpguehmutzyylugahiiggt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372023.1566393-267448-22239546553530/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "bash -c 'sudo -E kolla_set_configs && sudo -E kolla_copy_cacerts && nova-manage cell_v2 list_cells --verbose'",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "nova-list-cells"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "nova_list_cells",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-cell-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "",
                ""
            ]
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "2025-12-10 14:07:04.224 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:07:04.225 INFO Validating config file\n2025-12-10 14:07:04.225 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:07:04.229 INFO Copying service configuration files\n2025-12-10 14:07:04.229 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:07:04.230 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:07:04.230 INFO Writing out command to execute\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n",
    "stderr_lines": [
        "2025-12-10 14:07:04.224 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:07:04.225 INFO Validating config file",
        "2025-12-10 14:07:04.225 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:07:04.229 INFO Copying service configuration files",
        "2025-12-10 14:07:04.229 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:07:04.230 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:07:04.230 INFO Writing out command to execute",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:07:04.231 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log"
    ],
    "stdout": "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n|  Name |                 UUID                 |                                  Transport URL                                   |                                     Database Connection                                     | Disabled |\n+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n|       | 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee | rabbit://openstack:RXdStyDdvVIjACW4bAcjFiQ9rKWBA6kJCDU3ZNbw@192.168.0.195:5672// |    mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova    |  False   |\n| cell0 | 00000000-0000-0000-0000-000000000000 |                                     none:///                                     | mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova_cell0 |  False   |\n+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+\n",
    "stdout_lines": [
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+",
        "|  Name |                 UUID                 |                                  Transport URL                                   |                                     Database Connection                                     | Disabled |",
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+",
        "|       | 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee | rabbit://openstack:RXdStyDdvVIjACW4bAcjFiQ9rKWBA6kJCDU3ZNbw@192.168.0.195:5672// |    mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova    |  False   |",
        "| cell0 | 00000000-0000-0000-0000-000000000000 |                                     none:///                                     | mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova_cell0 |  False   |",
        "+-------+--------------------------------------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+----------+"
    ]
}

TASK [nova-cell : Extract current cell settings from list] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/get_cell_settings.yml:23
ok: [localhost] => {
    "ansible_facts": {
        "nova_cell_settings": {
            "cell_database": "mysql+pymysql://nova:Is46W72QW2jjHoSMcpunstQfITfH1cLci26xFQ73@192.168.0.200:3306/nova",
            "cell_disabled": "False",
            "cell_message_queue": "rabbit://openstack:RXdStyDdvVIjACW4bAcjFiQ9rKWBA6kJCDU3ZNbw@192.168.0.195:5672//",
            "cell_name": null,
            "cell_uuid": "24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee"
        }
    },
    "changed": false
}

TASK [nova-cell : Create cell] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/create_cells.yml:6
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467 `" && echo ansible-tmp-1765372029.6659427-267682-244361786018467="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxyhd_h03 TO /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467/ /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cfpmelivafqrslalgmwhomjpunzugoku ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372029.6659427-267682-244361786018467/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "bash -c 'sudo -E kolla_set_configs && sudo kolla_copy_cacerts && nova-manage cell_v2 create_cell'",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "create-cell-nova"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "labels": {
                "BOOTSTRAP": null
            },
            "name": "create_cell_nova",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-cell-bootstrap/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "",
                ""
            ]
        }
    },
    "msg": "Container exited with non-zero return code 2",
    "rc": 2,
    "stderr": "2025-12-10 14:07:10.874 INFO Loading config file at /var/lib/kolla/config_files/config.json\n2025-12-10 14:07:10.875 INFO Validating config file\n2025-12-10 14:07:10.875 INFO Kolla config strategy set to: COPY_ALWAYS\n2025-12-10 14:07:10.877 INFO Copying service configuration files\n2025-12-10 14:07:10.877 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf\n2025-12-10 14:07:10.879 INFO Setting permission for /etc/nova/nova.conf\n2025-12-10 14:07:10.879 INFO Writing out command to execute\n2025-12-10 14:07:10.879 INFO Setting permission for /var/log/kolla/nova\n2025-12-10 14:07:10.879 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-manage.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-api.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-compute.log\n2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log\n",
    "stderr_lines": [
        "2025-12-10 14:07:10.874 INFO Loading config file at /var/lib/kolla/config_files/config.json",
        "2025-12-10 14:07:10.875 INFO Validating config file",
        "2025-12-10 14:07:10.875 INFO Kolla config strategy set to: COPY_ALWAYS",
        "2025-12-10 14:07:10.877 INFO Copying service configuration files",
        "2025-12-10 14:07:10.877 INFO Copying /var/lib/kolla/config_files/nova.conf to /etc/nova/nova.conf",
        "2025-12-10 14:07:10.879 INFO Setting permission for /etc/nova/nova.conf",
        "2025-12-10 14:07:10.879 INFO Writing out command to execute",
        "2025-12-10 14:07:10.879 INFO Setting permission for /var/log/kolla/nova",
        "2025-12-10 14:07:10.879 INFO Setting permission for /var/log/kolla/nova/nova-metadata.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-conductor.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-scheduler.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-novncproxy.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-manage.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-metadata-uwsgi.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-api.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-compute.log",
        "2025-12-10 14:07:10.880 INFO Setting permission for /var/log/kolla/nova/nova-api-uwsgi.log"
    ],
    "stdout": "--transport-url not provided in the command line, using the value [DEFAULT]/transport_url from the configuration file\n--database_connection not provided in the command line, using the value [database]/connection from the configuration file\nThe specified transport_url and/or database_connection combination already exists for another cell with uuid 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee.\n",
    "stdout_lines": [
        "--transport-url not provided in the command line, using the value [DEFAULT]/transport_url from the configuration file",
        "--database_connection not provided in the command line, using the value [database]/connection from the configuration file",
        "The specified transport_url and/or database_connection combination already exists for another cell with uuid 24cc35ec-f505-4da8-a61a-6e1ce8d9f5ee."
    ]
}

TASK [nova-cell : Update cell] *************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/create_cells.yml:31
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_cell_settings | bool",
    "skip_reason": "Conditional result was False"
}

TASK [Bootstrap upgrade] *******************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/nova.yml:94
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_action == 'upgrade'",
    "skip_reason": "Conditional result was False"
}

PLAY [Apply role nova] *********************************************************

TASK [nova : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/register.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/check-containers.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/deploy.yml for localhost

TASK [service-ks-register : nova | Creating/deleting services] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:3
skipping: [localhost] => (item=nova_legacy (compute_legacy))  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.enabled | default(True) | bool",
    "item": {
        "description": "OpenStack Compute Service (Legacy 2.0)",
        "enabled": false,
        "endpoints": [
            {
                "interface": "internal",
                "url": "http://192.168.0.201:8774/v2/%(tenant_id)s"
            },
            {
                "interface": "public",
                "url": "http://192.168.0.201:8774/v2/%(tenant_id)s"
            }
        ],
        "name": "nova_legacy",
        "type": "compute_legacy"
    },
    "skip_reason": "Conditional result was False"
}
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927 `" && echo ansible-tmp-1765372035.8177261-268061-248617895887927="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmppx30dpkw TO /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927/ /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lidfjrctmzexbdsxkxlsownrswzwrdzp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372035.8177261-268061-248617895887927/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova (compute)) => {
    "action": "openstack.cloud.catalog_service",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": "OpenStack Compute Service",
            "interface": "internal",
            "is_enabled": null,
            "name": "nova",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service_type": "compute",
            "state": "present",
            "timeout": 180,
            "type": "compute",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "description": "OpenStack Compute Service",
        "endpoints": [
            {
                "interface": "internal",
                "url": "http://192.168.0.201:8774/v2.1"
            },
            {
                "interface": "public",
                "url": "http://192.168.0.201:8774/v2.1"
            }
        ],
        "name": "nova",
        "type": "compute"
    },
    "service": {
        "description": "OpenStack Compute Service",
        "id": "949428a9bfd34ad783fa60aacd19a998",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/services/949428a9bfd34ad783fa60aacd19a998"
        },
        "name": "nova",
        "type": "compute"
    }
}

TASK [service-ks-register : nova | Creating/deleting endpoints] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:25
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.201:8774/v2/%(tenant_id)s -> internal)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.0.enabled | default(True) | bool",
    "item": [
        {
            "description": "OpenStack Compute Service (Legacy 2.0)",
            "enabled": false,
            "name": "nova_legacy",
            "type": "compute_legacy"
        },
        {
            "interface": "internal",
            "url": "http://192.168.0.201:8774/v2/%(tenant_id)s"
        }
    ],
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item=nova_legacy -> http://192.168.0.201:8774/v2/%(tenant_id)s -> public)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.0.enabled | default(True) | bool",
    "item": [
        {
            "description": "OpenStack Compute Service (Legacy 2.0)",
            "enabled": false,
            "name": "nova_legacy",
            "type": "compute_legacy"
        },
        {
            "interface": "public",
            "url": "http://192.168.0.201:8774/v2/%(tenant_id)s"
        }
    ],
    "skip_reason": "Conditional result was False"
}
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797 `" && echo ansible-tmp-1765372039.2650433-268216-92194017084797="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4agbj1gg TO /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797/ /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ffvbnfmettnhswnccqwnlryloczezlwk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372039.2650433-268216-92194017084797/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova -> http://192.168.0.201:8774/v2.1 -> internal) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "65300f45b863409583133674bea60de5",
        "interface": "internal",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/65300f45b863409583133674bea60de5"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "949428a9bfd34ad783fa60aacd19a998",
        "url": "http://192.168.0.201:8774/v2.1"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "internal",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "nova",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:8774/v2.1",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "OpenStack Compute Service",
            "name": "nova",
            "type": "compute"
        },
        {
            "interface": "internal",
            "url": "http://192.168.0.201:8774/v2.1"
        }
    ]
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303 `" && echo ansible-tmp-1765372042.4748087-268216-264764607010303="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6hhqx8xq TO /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303/ /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-buaiifwypcyvwktlicprwwrandwpgdht ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372042.4748087-268216-264764607010303/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova -> http://192.168.0.201:8774/v2.1 -> public) => {
    "action": "openstack.cloud.endpoint",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "endpoint": {
        "id": "10fb99ecdd4b41f8966f5c2ea57a8b71",
        "interface": "public",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/endpoints/10fb99ecdd4b41f8966f5c2ea57a8b71"
        },
        "name": null,
        "region_id": "RegionOne",
        "service_id": "949428a9bfd34ad783fa60aacd19a998",
        "url": "http://192.168.0.201:8774/v2.1"
    },
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "enabled": true,
            "endpoint_interface": "public",
            "interface": "internal",
            "region": "RegionOne",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "service": "nova",
            "state": "present",
            "timeout": 180,
            "url": "http://192.168.0.201:8774/v2.1",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": [
        {
            "description": "OpenStack Compute Service",
            "name": "nova",
            "type": "compute"
        },
        {
            "interface": "public",
            "url": "http://192.168.0.201:8774/v2.1"
        }
    ]
}

TASK [service-ks-register : nova | Creating projects] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:50
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195 `" && echo ansible-tmp-1765372045.7599792-268577-261352252219195="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp96go4xla TO /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195/ /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wfbniirworgdgujkqmrthbcsgxikarzu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372045.7599792-268577-261352252219195/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=service) => {
    "action": "openstack.cloud.project",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain": "default",
            "extra_specs": null,
            "interface": "internal",
            "is_enabled": null,
            "name": "service",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "service",
    "project": {
        "description": "",
        "domain_id": "default",
        "id": "3e1d884058424621b0335f6a041c2d4a",
        "is_domain": false,
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/projects/3e1d884058424621b0335f6a041c2d4a"
        },
        "name": "service",
        "options": {},
        "parent_id": "default",
        "tags": []
    }
}

TASK [service-ks-register : nova | Creating/deleting users] ********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:67
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346 `" && echo ansible-tmp-1765372049.07885-268763-240246475357346="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpf74e6mv_ TO /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346/ /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ntfamhbxlaxvkyfiyklwmtoexfsndcji ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372049.07885-268763-240246475357346/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => (item=nova -> service) => {
    "action": "openstack.cloud.identity_user",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": true,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "default_project": "service",
            "description": null,
            "domain": "default",
            "email": null,
            "interface": "internal",
            "is_enabled": true,
            "name": "nova",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "update_password": "always",
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "Yd402SIrfcdJIAJQcEKmGQyojvuaJFWAUeLt0JaY",
        "project": "service",
        "role": "admin",
        "user": "nova"
    },
    "user": {
        "default_project_id": "3e1d884058424621b0335f6a041c2d4a",
        "description": null,
        "domain_id": "default",
        "email": null,
        "id": "081f65737bcf45f88e0a5f710967e74d",
        "is_enabled": true,
        "links": {
            "self": "http://192.168.0.201:5000/v3/users/081f65737bcf45f88e0a5f710967e74d"
        },
        "name": "nova",
        "options": {},
        "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
        "password_expires_at": null
    },
    "warnings": [
        "Module did not set no_log for update_password"
    ]
}

TASK [service-ks-register : nova | Creating roles] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:93
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266 `" && echo ansible-tmp-1765372053.555696-269039-77365292156266="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpx6bje49y TO /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266/ /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-untjhnmdgllpewhitizpvzuhhhbeoeqi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372053.555696-269039-77365292156266/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=admin) => {
    "action": "openstack.cloud.identity_role",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "description": null,
            "domain_id": null,
            "interface": "internal",
            "name": "admin",
            "region_name": "RegionOne",
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "timeout": 180,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": "admin",
    "role": {
        "description": null,
        "domain_id": null,
        "id": "5c609e9185ea4b52b7299d27240aebd9",
        "links": {
            "self": "http://192.168.0.201:5000/v3/roles/5c609e9185ea4b52b7299d27240aebd9"
        },
        "name": "admin",
        "options": {
            "immutable": true
        }
    }
}

TASK [service-ks-register : nova | Granting/revoking user roles] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-ks-register/tasks/main.yml:109
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195 `" && echo ansible-tmp-1765372057.0319571-269379-92133409134195="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpa4roi568 TO /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195/ /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ydrzmgxekorpbdxwyqquptfkmdncegnd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372057.0319571-269379-92133409134195/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova -> service -> admin) => {
    "action": "openstack.cloud.role_assignment",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "domain": null,
            "group": null,
            "group_domain": null,
            "interface": "internal",
            "project": "service",
            "project_domain": null,
            "region_name": "RegionOne",
            "role": "admin",
            "role_domain": null,
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "system": null,
            "timeout": 180,
            "user": "nova",
            "user_domain": null,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "password": "Yd402SIrfcdJIAJQcEKmGQyojvuaJFWAUeLt0JaY",
        "project": "service",
        "role": "admin",
        "user": "nova"
    }
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898 `" && echo ansible-tmp-1765372060.4672143-269379-14701743583898="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_toolbox.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6h3oinw0 TO /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898/AnsiballZ_kolla_toolbox.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898/ /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898/AnsiballZ_kolla_toolbox.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-akqgnlfpvpjjntdstkviovndcogwxzqu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898/AnsiballZ_kolla_toolbox.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372060.4672143-269379-14701743583898/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=nova -> service -> service) => {
    "action": "openstack.cloud.role_assignment",
    "ansible_loop_var": "item",
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_timeout": null,
            "auth": {
                "auth_url": "http://192.168.0.201:5000",
                "domain_name": "default",
                "password": "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
                "project_name": "admin",
                "user_domain_name": "default",
                "username": "admin"
            },
            "auth_type": null,
            "ca_cert": "",
            "cacert": "",
            "client_cert": null,
            "client_key": null,
            "domain": null,
            "group": null,
            "group_domain": null,
            "interface": "internal",
            "project": "service",
            "project_domain": null,
            "region_name": "RegionOne",
            "role": "service",
            "role_domain": null,
            "sdk_log_level": "INFO",
            "sdk_log_path": null,
            "state": "present",
            "system": null,
            "timeout": 180,
            "user": "nova",
            "user_domain": null,
            "validate_certs": null,
            "wait": true
        }
    },
    "item": {
        "project": "service",
        "role": "service",
        "user": "nova"
    }
}

TASK [nova : Ensuring config directories exist] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690 `" && echo ansible-tmp-1765372064.0768933-269933-155340448867690="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpeuw3t6z9 TO /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690/ /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-atfehpuvunaexqljgjzjzrypnxwyahqi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372064.0768933-269933-155340448867690/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api"
        },
        "before": {
            "path": "/etc/kolla/nova-api"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-api",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-api",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635 `" && echo ansible-tmp-1765372064.4495273-269933-72271138956635="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpil8_wcxf TO /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635/ /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qjmouikyszegsqsihsrlrlqbibacapad ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372064.4495273-269933-72271138956635/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-metadata"
        },
        "before": {
            "path": "/etc/kolla/nova-metadata"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-metadata",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-metadata",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683 `" && echo ansible-tmp-1765372064.82994-269933-186659427747683="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxjdbq474 TO /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683/ /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cmaynboibbmhaxphhaqcamlyckmymhms ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372064.82994-269933-186659427747683/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-scheduler"
        },
        "before": {
            "path": "/etc/kolla/nova-scheduler"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-scheduler",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-scheduler",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [nova : Check if policies shall be overwritten] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [nova : Set nova policy file] *********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:24
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_policy.results | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [nova : Check for vendordata file] ****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:31
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330 `" && echo ansible-tmp-1765372065.5242836-270060-109456932898330="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0parwe15 TO /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330/ /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372065.5242836-270060-109456932898330/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_mime": true,
            "path": "/etc/kolla/config/nova/vendordata.json"
        }
    },
    "stat": {
        "exists": false
    }
}

TASK [nova : Set vendordata file path] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:38
skipping: [localhost] => {
    "changed": false,
    "false_condition": "vendordata_file.stat.exists",
    "skip_reason": "Conditional result was False"
}

TASK [nova : include_tasks] ****************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:44
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova : Copying over config.json files for services] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:48
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167 `" && echo ansible-tmp-1765372066.3434927-270101-168014219011167="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi2bxrjgk TO /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/ /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qtguochurmfwnencpzgeruqislsyrhge ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp73sj4a1j TO /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/ /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bajsqieikoerkkikdqbardymvoeybllq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372066.3434927-270101-168014219011167/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "b6fe671433c150ffaf9c5cfb5c48de200c89b31c",
    "dest": "/etc/kolla/nova-api/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-api/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-api.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-api/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-api/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-api/config.json",
    "size": 620,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189 `" && echo ansible-tmp-1765372067.0619817-270101-95904831012189="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp3f98o8a4 TO /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/ /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zgsonmzzhurjflzyohechxecfewhjjsq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpgjuke_7j TO /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/ /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-erseuhzzdwodhrnpmkuttgxlqqeubyla ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372067.0619817-270101-95904831012189/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "93fbd5512209473d8ab52a0db99c3b529d11f3c9",
    "dest": "/etc/kolla/nova-metadata/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-metadata/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-metadata/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-metadata.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-metadata/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-metadata/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-metadata/config.json",
    "size": 635,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257 `" && echo ansible-tmp-1765372067.790924-270101-177186852248257="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkw24lr7d TO /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/ /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-twgycocrjuivycknmjidjulygllipsbm ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpigc0j25t TO /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/ /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-djclmrsstaziswifbqyvajabndmqfogi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372067.790924-270101-177186852248257/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "7d0fa55a55ce5ae9e65deedf7592925b1b470e2f",
    "dest": "/etc/kolla/nova-scheduler/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-scheduler/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-scheduler/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-scheduler.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-scheduler/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-scheduler/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-scheduler/config.json",
    "size": 399,
    "state": "file",
    "uid": 1000
}

TASK [nova : Copying over nova.conf] *******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:56
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378 `" && echo ansible-tmp-1765372068.8385484-270289-15590425274378="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp94v1ylk0 TO /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/ /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tffyjranbjcjrfgzsbdwxghqiugxxjxj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpvrqiok2c TO /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/ /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-yyxtpwnbcoppfragyaqsuwvnudvoggvv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372068.8385484-270289-15590425274378/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "757dc82c1121341f3fb0791545820111228ee59d",
    "dest": "/etc/kolla/nova-api/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-api/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-api/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-api/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-api.conf",
                "/etc/kolla/config/nova/localhost/nova.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptsk135i7/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-api/nova.conf",
    "size": 3122,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125 `" && echo ansible-tmp-1765372069.7674716-270289-249792313178125="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpiq5ymh0c TO /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/ /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-waitxwbfpzzvphcxysinjydxpwihorff ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd5a09drm TO /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/ /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lolvflgrjwtcfjjcjvxuhlilsotskmbe ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372069.7674716-270289-249792313178125/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "5f4e252036027a8ab313e15ac3b7649b1af47314",
    "dest": "/etc/kolla/nova-metadata/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-metadata/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-metadata/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-metadata/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-metadata/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-metadata.conf",
                "/etc/kolla/config/nova/localhost/nova.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmppx8h2jfe/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-metadata/nova.conf",
    "size": 3133,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156 `" && echo ansible-tmp-1765372070.6909578-270289-231221669021156="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptcw5p2jr TO /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/ /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-neyemlzlnuvovbupyxfczzjnhrzksjiu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp92zlm5wp TO /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/ /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-easnmhctzdhpaamwquipnbwthdgagpou ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372070.6909578-270289-231221669021156/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "cdfc64ea4032b5d05a993814c7553e6a431182e9",
    "dest": "/etc/kolla/nova-scheduler/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-scheduler/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-scheduler/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-scheduler/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-scheduler/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-scheduler.conf",
                "/etc/kolla/config/nova/localhost/nova.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpi0r7hizt/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-scheduler/nova.conf",
    "size": 3086,
    "state": "file",
    "uid": 1000
}

TASK [nova : Copying over existing policy file] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:71
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova : Copying over nova-api-wsgi.conf] **********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:82
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_wsgi_provider == \"apache\"",
    "skip_reason": "Conditional result was False"
}

TASK [nova : Copying over nova-metadata-wsgi.conf] *****************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:94
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_wsgi_provider == \"apache\"",
    "skip_reason": "Conditional result was False"
}

TASK [nova : Copying over vendordata file for nova services] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:106
skipping: [localhost] => (item=nova-metadata)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "vendordata_file_path is defined",
    "item": "nova-metadata",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item=nova-api)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "vendordata_file_path is defined",
    "item": "nova-api",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [Configure uWSGI for Nova] ************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/config.yml:121
included: service-uwsgi-config for localhost => (item={'name': 'nova-api', 'port': '8774'})
included: service-uwsgi-config for localhost => (item={'name': 'nova-metadata', 'port': '8775'})

TASK [service-uwsgi-config : Copying over nova-api uWSGI config] ***************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-uwsgi-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046 `" && echo ansible-tmp-1765372073.4256213-270530-239715537674046="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpdr8rez1q TO /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/ /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-soonpmlzshpqfxyaieinzqieammglxjp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpe7tk6gjj TO /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/ /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qxwjpvmtdmvzfhiywkyrrjrnlsfwqbdw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372073.4256213-270530-239715537674046/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "3fe60434cc21d0ff6b78373b4fd895e213e30e53",
    "dest": "/etc/kolla/nova-api/nova-api-uwsgi.ini",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-api/nova-api-uwsgi.ini"
        },
        "before": {
            "path": "/etc/kolla/nova-api/nova-api-uwsgi.ini"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "uwsgi.ini.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-api/nova-api-uwsgi.ini",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-api/nova-api-uwsgi.ini",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-api/nova-api-uwsgi.ini",
    "size": 644,
    "state": "file",
    "uid": 1000
}

TASK [service-uwsgi-config : Copying over nova-metadata uWSGI config] **********
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-uwsgi-config/tasks/main.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139 `" && echo ansible-tmp-1765372074.56924-270601-5030985709139="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkgn1hz47 TO /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/ /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-naqlgpjxggyzsmomfrfkuzvfuctudfuw ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmptwbb6846 TO /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/ /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dqjnircoigpcmttujnchxdeghlalkemg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372074.56924-270601-5030985709139/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "7d0c31c4bd8c3c9f7fce96142e54282a62c8bcf3",
    "dest": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini"
        },
        "before": {
            "path": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "uwsgi.ini.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-metadata/nova-metadata-uwsgi.ini",
    "size": 644,
    "state": "file",
    "uid": 1000
}

TASK [service-check-containers : nova | Check containers] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252 `" && echo ansible-tmp-1765372076.0299275-270659-234167337563252="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9xnp0wo0 TO /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252/ /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gbpwouhzwkbeauclbpdcyyujulejrxjk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372076.0299275-270659-234167337563252/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "labels": {},
            "name": "nova_api",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424 `" && echo ansible-tmp-1765372077.0756147-270659-113078989441424="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqgdr9kwd TO /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424/ /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mfcmetaskkhdkhdpzyajhmfcsvtpiqtp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372077.0756147-270659-113078989441424/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "labels": {},
            "name": "nova_metadata",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812 `" && echo ansible-tmp-1765372078.0373394-270659-171594941051812="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpcvw2th43 TO /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812/ /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gqwutibcodkxyinjehnoofkritalzncf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372078.0373394-270659-171594941051812/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "labels": {},
            "name": "nova_scheduler",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : nova | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'nova-api', 'value': {'container_name': 'nova_api', 'group': 'nova-api', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'privileged': True, 'volumes': ['/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8774 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.osapi_compute:application', 'haproxy': {'nova_api': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_api_external': {'enabled': True, 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8774', 'listen_port': '8774', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-api",
        "value": {
            "container_name": "nova_api",
            "dimensions": {},
            "enabled": true,
            "group": "nova-api",
            "haproxy": {
                "nova_api": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                },
                "nova_api_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8774",
                    "mode": "http",
                    "port": "8774",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8774 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-api/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ],
            "wsgi": "nova.wsgi.osapi_compute:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-metadata', 'value': {'container_name': 'nova_metadata', 'group': 'nova-metadata', 'image': 'quay.io/openstack.kolla/nova-api:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:8775 '], 'timeout': '30'}, 'wsgi': 'nova.wsgi.metadata:application', 'haproxy': {'nova_metadata': {'enabled': True, 'mode': 'http', 'external': False, 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}, 'nova_metadata_external': {'enabled': 'no', 'mode': 'http', 'external': True, 'external_fqdn': '192.168.0.201', 'port': '8775', 'listen_port': '8775', 'tls_backend': False, 'backend_http_extra': ['option httpchk']}}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-metadata",
        "value": {
            "container_name": "nova_metadata",
            "dimensions": {},
            "enabled": true,
            "group": "nova-metadata",
            "haproxy": {
                "nova_metadata": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": true,
                    "external": false,
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                },
                "nova_metadata_external": {
                    "backend_http_extra": [
                        "option httpchk"
                    ],
                    "enabled": "no",
                    "external": true,
                    "external_fqdn": "192.168.0.201",
                    "listen_port": "8775",
                    "mode": "http",
                    "port": "8775",
                    "tls_backend": false
                }
            },
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:8775 "
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-api:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-metadata/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                ""
            ],
            "wsgi": "nova.wsgi.metadata:application"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-scheduler', 'value': {'container_name': 'nova_scheduler', 'group': 'nova-scheduler', 'image': 'quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-scheduler 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-scheduler",
        "value": {
            "container_name": "nova_scheduler",
            "dimensions": {},
            "enabled": true,
            "group": "nova-scheduler",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-scheduler 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-scheduler:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-scheduler/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova : Flush handlers] ***************************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova/tasks/deploy.yml:8
META: triggered running handlers for localhost

PLAY [Apply role nova-cell] ****************************************************

TASK [nova-cell : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/main.yml:2
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config-host.yml
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/check-containers.yml
statically imported: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/wait_discover_computes.yml
included: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml for localhost

TASK [nova-cell : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml:2
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_dev_mode | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Get new Libvirt version] *************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857 `" && echo ansible-tmp-1765372080.794893-270918-74602212046857="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpahgyj6se TO /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857/ /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xnnhvpyvrbdexwwhzxyjiydobdyjgevj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372080.794893-270918-74602212046857/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "action": "start_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "command": "libvirtd --version",
            "container_engine": "docker",
            "detach": false,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "KOLLA_SERVICE_NAME": "libvirt-version-check"
            },
            "graceful_timeout": 60,
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "labels": {},
            "name": "libvirt_version_check",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "oneshot",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false
        }
    },
    "rc": 0,
    "result": false,
    "stderr": "",
    "stderr_lines": [],
    "stdout": "libvirtd (libvirt) 10.0.0\n",
    "stdout_lines": [
        "libvirtd (libvirt) 10.0.0"
    ]
}

TASK [nova-cell : Cache new Libvirt version] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:28
ok: [localhost] => {
    "ansible_facts": {
        "libvirt_new_version": "10.0.0"
    },
    "changed": false
}

TASK [Get nova_libvirt image info] *********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:35
included: service-image-info for localhost

TASK [service-image-info : community.docker.docker_image_info] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-image-info/tasks/main.yml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126 `" && echo ansible-tmp-1765372084.176276-271106-137916925562126="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126 `" ) && sleep 0'
Using module file /home/nics/.ansible/collections/ansible_collections/community/docker/plugins/modules/docker_image_info.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp0790u879 TO /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126/AnsiballZ_docker_image_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126/ /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126/AnsiballZ_docker_image_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iwfujvopzyferjhfcdcbutuwupofcjht ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126/AnsiballZ_docker_image_info.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372084.176276-271106-137916925562126/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "images": [
        {
            "Architecture": "amd64",
            "Config": {
                "Cmd": [
                    "kolla_start"
                ],
                "Entrypoint": [
                    "dumb-init",
                    "--single-child",
                    "--"
                ],
                "Env": [
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL="
                ],
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "nova-libvirt",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                }
            },
            "Created": "2025-12-10T02:29:48.186105019Z",
            "GraphDriver": {
                "Data": {
                    "LowerDir": "/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/merged",
                    "UpperDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff",
                    "WorkDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/work"
                },
                "Name": "overlay2"
            },
            "Id": "sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a",
            "Metadata": {
                "LastTagTime": "0001-01-01T00:00:00Z"
            },
            "Os": "linux",
            "RepoDigests": [
                "quay.io/openstack.kolla/nova-libvirt@sha256:26391ae573e49f80ad0f0b32d809e50c6e69d2fd0f83ed554bdfc80721f44ad0"
            ],
            "RepoTags": [
                "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble"
            ],
            "RootFS": {
                "Layers": [
                    "sha256:e8bce0aabd687e9ee90e0bada33884f40b277196f72aac9934357472863a80ae",
                    "sha256:8f41f6765ebe060b39deb1e1d56d90432f2063a56662f5a5c0c064b71e451ebc",
                    "sha256:4346edd815f46042315cf909705bd21fc3b6f3300643e4715fdf6cef2a64de6a",
                    "sha256:b7c32d5bbf53bf4060fcb3435158f439a34f2b71abc5fda0d47196d4de6938f4",
                    "sha256:1d8e88838a24bdc9f9c893e42dd95684d299eba0055255eccf8e13c19bcc8b23",
                    "sha256:82f7e563cc48f0b9a516ff3a07afbb758dd076f599f69bc36a8e566eed6337bf",
                    "sha256:0983dde2790ce6af6d19f074095cf97f88294f1b266ddd15fce4f41a38cf338d",
                    "sha256:ff61d4a7aed8cfd5e3e3c1352ed1643f5143153c661a8b03bac30f1294065a0b",
                    "sha256:5233682378b4a00d4061bdafbb108f670a7d7c4aaccee879b858e5dc004613bf",
                    "sha256:a849aac569ec2d9d58a8a4b766d233f542c864a78f3fcda83bb338741f9c6e2e",
                    "sha256:a075095d2965783b7b2a17ef551b607e0b8d72ac7e0cb18b96a7393e3e3f0dd0",
                    "sha256:96477a8d22ee529bf27ed3dff8d7e431047612dfd43f02e83fbf056a68f73937",
                    "sha256:6464a479ca14f32b05869fff4568086647ac12a4bb47bb8975296efb566be3de",
                    "sha256:2ed39ff45ddbdf8e6df0a21fe0f4a405a8726dac9df283dde18f1493f7759b36",
                    "sha256:90c9977fd3e2a2f70017fd342ad64f734a54f7bfe28926f0914386b3b9ffe164",
                    "sha256:548e7a669ded67347ce52f0c2d97b293e376fb892e51c3618138d6b57379c68c",
                    "sha256:f9d727ca2aca0be0108d81943646392ecced70bd1c64c40512ac59489dde2644",
                    "sha256:0cad01fc5984672835507408316256caf8fa45c32ac9b00630bdb3e30cd3c54d",
                    "sha256:0f0e0a6e7f52ccb6e13a63b11a57741885be84fe9a39a5c60e6412970e9e8ece",
                    "sha256:d8f8f1e0c3410066b84e2f9559e0c566cf72e5128ba013dd5c8145eb88044680",
                    "sha256:0e0e8da32b62c79d7c3c96df9060b29c7682c0a3802733d1185c5e0c51bb8bb3",
                    "sha256:02b8e5bbde37e0eb0f959ce6b5cc8782342d44a171cec9a97a1502606ded89ed",
                    "sha256:e2b0d84309c02351aa53a2f4f53bc0b4994c093343a50f55d0558906f534aac9",
                    "sha256:a746cc05625019d823dbb1566131dca46426af320b4cad02a47bdeb3867deceb",
                    "sha256:199b3ae922bea4d9c4cfa57c021ee60c7d1ee576e6121bd4713ae8c3c080ed41",
                    "sha256:a4131b88194ee0a538dda73a412c26a5fec4e6f7301037ee444e5221acbe647f",
                    "sha256:1f507a51a4dac42792e25c84802013fecac9f3855b2ec6835a7a1d52c4cc9f88",
                    "sha256:9e7ad0ff4c637574a4a31764d3b8f236cbdeb516cab01d344340b431424b7d11",
                    "sha256:01f455f237468959d74206278dd8c03e3868efee1aaedfd053691546579522ed",
                    "sha256:ac2c7eb9bb835dd6f401d79954702145938ad14fab25807400d74e7f4220d628",
                    "sha256:8b50eb8abafe32fc7055b73a1f921cd7c136867d1136d10238627cad6ad7b8fd",
                    "sha256:98ec892a4fc201641e2086da4f3f91d502751ffa47de65876ce9a7c1d627d6fd",
                    "sha256:a49fd5b37840c8f53f83bcb64e1e706cb6588c9d879097ad93de39a5c0d94745",
                    "sha256:57c4b1705ffdf80d2e94bbeab05ce79ac355673c42876251695f7d085562f7f6",
                    "sha256:4fc1433acb89713859b2106d7a299c293dcd15355f9092a33276b8b9b3823730"
                ],
                "Type": "layers"
            },
            "Size": 1065830817
        }
    ],
    "invocation": {
        "module_args": {
            "api_version": "auto",
            "ca_path": null,
            "client_cert": null,
            "client_key": null,
            "debug": false,
            "docker_host": "unix:///var/run/docker.sock",
            "name": [
                "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble"
            ],
            "timeout": 60,
            "tls": false,
            "tls_hostname": null,
            "use_ssh_client": false,
            "validate_certs": false
        }
    }
}

TASK [service-image-info : set_fact] *******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-image-info/tasks/main.yml:11
ok: [localhost] => {
    "ansible_facts": {
        "service_image_info": {
            "changed": false,
            "failed": false,
            "images": [
                {
                    "Architecture": "amd64",
                    "Config": {
                        "Cmd": [
                            "kolla_start"
                        ],
                        "Entrypoint": [
                            "dumb-init",
                            "--single-child",
                            "--"
                        ],
                        "Env": [
                            "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                            "LANG=en_US.UTF-8",
                            "KOLLA_BASE_DISTRO=ubuntu",
                            "KOLLA_BASE_ARCH=x86_64",
                            "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                            "DEBIAN_FRONTEND=noninteractive",
                            "PIP_INDEX_URL=",
                            "PIP_TRUSTED_HOST=",
                            "PIP_EXTRA_INDEX_URL="
                        ],
                        "Labels": {
                            "build-date": "20251210",
                            "kolla_version": "21.1.0",
                            "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                            "name": "nova-libvirt",
                            "org.opencontainers.image.ref.name": "ubuntu",
                            "org.opencontainers.image.version": "24.04"
                        }
                    },
                    "Created": "2025-12-10T02:29:48.186105019Z",
                    "GraphDriver": {
                        "Data": {
                            "LowerDir": "/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                            "MergedDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/merged",
                            "UpperDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff",
                            "WorkDir": "/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/work"
                        },
                        "Name": "overlay2"
                    },
                    "Id": "sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a",
                    "Metadata": {
                        "LastTagTime": "0001-01-01T00:00:00Z"
                    },
                    "Os": "linux",
                    "RepoDigests": [
                        "quay.io/openstack.kolla/nova-libvirt@sha256:26391ae573e49f80ad0f0b32d809e50c6e69d2fd0f83ed554bdfc80721f44ad0"
                    ],
                    "RepoTags": [
                        "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble"
                    ],
                    "RootFS": {
                        "Layers": [
                            "sha256:e8bce0aabd687e9ee90e0bada33884f40b277196f72aac9934357472863a80ae",
                            "sha256:8f41f6765ebe060b39deb1e1d56d90432f2063a56662f5a5c0c064b71e451ebc",
                            "sha256:4346edd815f46042315cf909705bd21fc3b6f3300643e4715fdf6cef2a64de6a",
                            "sha256:b7c32d5bbf53bf4060fcb3435158f439a34f2b71abc5fda0d47196d4de6938f4",
                            "sha256:1d8e88838a24bdc9f9c893e42dd95684d299eba0055255eccf8e13c19bcc8b23",
                            "sha256:82f7e563cc48f0b9a516ff3a07afbb758dd076f599f69bc36a8e566eed6337bf",
                            "sha256:0983dde2790ce6af6d19f074095cf97f88294f1b266ddd15fce4f41a38cf338d",
                            "sha256:ff61d4a7aed8cfd5e3e3c1352ed1643f5143153c661a8b03bac30f1294065a0b",
                            "sha256:5233682378b4a00d4061bdafbb108f670a7d7c4aaccee879b858e5dc004613bf",
                            "sha256:a849aac569ec2d9d58a8a4b766d233f542c864a78f3fcda83bb338741f9c6e2e",
                            "sha256:a075095d2965783b7b2a17ef551b607e0b8d72ac7e0cb18b96a7393e3e3f0dd0",
                            "sha256:96477a8d22ee529bf27ed3dff8d7e431047612dfd43f02e83fbf056a68f73937",
                            "sha256:6464a479ca14f32b05869fff4568086647ac12a4bb47bb8975296efb566be3de",
                            "sha256:2ed39ff45ddbdf8e6df0a21fe0f4a405a8726dac9df283dde18f1493f7759b36",
                            "sha256:90c9977fd3e2a2f70017fd342ad64f734a54f7bfe28926f0914386b3b9ffe164",
                            "sha256:548e7a669ded67347ce52f0c2d97b293e376fb892e51c3618138d6b57379c68c",
                            "sha256:f9d727ca2aca0be0108d81943646392ecced70bd1c64c40512ac59489dde2644",
                            "sha256:0cad01fc5984672835507408316256caf8fa45c32ac9b00630bdb3e30cd3c54d",
                            "sha256:0f0e0a6e7f52ccb6e13a63b11a57741885be84fe9a39a5c60e6412970e9e8ece",
                            "sha256:d8f8f1e0c3410066b84e2f9559e0c566cf72e5128ba013dd5c8145eb88044680",
                            "sha256:0e0e8da32b62c79d7c3c96df9060b29c7682c0a3802733d1185c5e0c51bb8bb3",
                            "sha256:02b8e5bbde37e0eb0f959ce6b5cc8782342d44a171cec9a97a1502606ded89ed",
                            "sha256:e2b0d84309c02351aa53a2f4f53bc0b4994c093343a50f55d0558906f534aac9",
                            "sha256:a746cc05625019d823dbb1566131dca46426af320b4cad02a47bdeb3867deceb",
                            "sha256:199b3ae922bea4d9c4cfa57c021ee60c7d1ee576e6121bd4713ae8c3c080ed41",
                            "sha256:a4131b88194ee0a538dda73a412c26a5fec4e6f7301037ee444e5221acbe647f",
                            "sha256:1f507a51a4dac42792e25c84802013fecac9f3855b2ec6835a7a1d52c4cc9f88",
                            "sha256:9e7ad0ff4c637574a4a31764d3b8f236cbdeb516cab01d344340b431424b7d11",
                            "sha256:01f455f237468959d74206278dd8c03e3868efee1aaedfd053691546579522ed",
                            "sha256:ac2c7eb9bb835dd6f401d79954702145938ad14fab25807400d74e7f4220d628",
                            "sha256:8b50eb8abafe32fc7055b73a1f921cd7c136867d1136d10238627cad6ad7b8fd",
                            "sha256:98ec892a4fc201641e2086da4f3f91d502751ffa47de65876ce9a7c1d627d6fd",
                            "sha256:a49fd5b37840c8f53f83bcb64e1e706cb6588c9d879097ad93de39a5c0d94745",
                            "sha256:57c4b1705ffdf80d2e94bbeab05ce79ac355673c42876251695f7d085562f7f6",
                            "sha256:4fc1433acb89713859b2106d7a299c293dcd15355f9092a33276b8b9b3823730"
                        ],
                        "Type": "layers"
                    },
                    "Size": 1065830817
                }
            ]
        }
    },
    "changed": false
}

TASK [service-image-info : containers.podman.podman_image_info] ****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-image-info/tasks/main.yml:20
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_container_engine == 'podman'",
    "skip_reason": "Conditional result was False"
}

TASK [service-image-info : set_fact] *******************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-image-info/tasks/main.yml:24
skipping: [localhost] => {
    "changed": false,
    "false_condition": "kolla_container_engine == 'podman'",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Get container facts] *****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:40
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902 `" && echo ansible-tmp-1765372088.7598953-271227-208977225811902="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container_facts.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv0qf80ly TO /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902/AnsiballZ_kolla_container_facts.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902/ /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902/AnsiballZ_kolla_container_facts.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-rvwpzuygfjwdjidkwuwrtisfwlputdwp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902/AnsiballZ_kolla_container_facts.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372088.7598953-271227-208977225811902/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=localhost) => {
    "ansible_loop_var": "item",
    "changed": false,
    "containers": {
        "nova_libvirt": {
            "AppArmorProfile": "unconfined",
            "Args": [
                "--single-child",
                "--",
                "kolla_start"
            ],
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "kolla_start"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "dumb-init",
                    "--single-child",
                    "--"
                ],
                "Env": [
                    "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                    "KOLLA_SERVICE_NAME=nova-libvirt",
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "LANG=en_US.UTF-8",
                    "KOLLA_BASE_DISTRO=ubuntu",
                    "KOLLA_BASE_ARCH=x86_64",
                    "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                    "DEBIAN_FRONTEND=noninteractive",
                    "PIP_INDEX_URL=",
                    "PIP_TRUSTED_HOST=",
                    "PIP_EXTRA_INDEX_URL="
                ],
                "Healthcheck": {
                    "Interval": 30000000000,
                    "Retries": 3,
                    "StartPeriod": 5000000000,
                    "Test": [
                        "CMD-SHELL",
                        "virsh version --daemon"
                    ],
                    "Timeout": 30000000000
                },
                "Hostname": "nics-VMware20-1",
                "Image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
                "Labels": {
                    "build-date": "20251210",
                    "kolla_version": "21.1.0",
                    "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                    "name": "nova-libvirt",
                    "org.opencontainers.image.ref.name": "ubuntu",
                    "org.opencontainers.image.version": "24.04"
                },
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "",
                "Volumes": {
                    "/dev": {},
                    "/etc/libvirt/qemu": {},
                    "/etc/localtime": {},
                    "/etc/timezone": {},
                    "/lib/modules": {},
                    "/run": {},
                    "/sys/fs/cgroup": {},
                    "/var/lib/kolla/config_files/": {},
                    "/var/lib/libvirt": {},
                    "/var/lib/nova/": {},
                    "/var/log/kolla/": {}
                },
                "WorkingDir": ""
            },
            "Created": "2025-12-10T12:06:47.964413255Z",
            "Driver": "overlay2",
            "ExecIDs": null,
            "GraphDriver": {
                "Data": {
                    "ID": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
                    "LowerDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc-init/diff:/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff:/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                    "MergedDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/merged",
                    "UpperDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/diff",
                    "WorkDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/work"
                },
                "Name": "overlay2"
            },
            "HostConfig": {
                "AutoRemove": false,
                "Binds": [
                    "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                    "/etc/localtime:/etc/localtime:ro",
                    "/etc/timezone:/etc/timezone:ro",
                    "/lib/modules:/lib/modules:ro",
                    "/run:/run:shared",
                    "/dev:/dev:rw",
                    "/sys/fs/cgroup:/sys/fs/cgroup:rw",
                    "kolla_logs:/var/log/kolla/:rw",
                    "libvirtd:/var/lib/libvirt:rw",
                    "nova_compute:/var/lib/nova/:rw",
                    "nova_libvirt_qemu:/etc/libvirt/qemu:rw"
                ],
                "BlkioDeviceReadBps": null,
                "BlkioDeviceReadIOps": null,
                "BlkioDeviceWriteBps": null,
                "BlkioDeviceWriteIOps": null,
                "BlkioWeight": 0,
                "BlkioWeightDevice": null,
                "CapAdd": null,
                "CapDrop": null,
                "Cgroup": "",
                "CgroupParent": "",
                "CgroupnsMode": "host",
                "ConsoleSize": [
                    0,
                    0
                ],
                "ContainerIDFile": "",
                "CpuCount": 0,
                "CpuPercent": 0,
                "CpuPeriod": 0,
                "CpuQuota": 0,
                "CpuRealtimePeriod": 0,
                "CpuRealtimeRuntime": 0,
                "CpuShares": 0,
                "CpusetCpus": "",
                "CpusetMems": "",
                "DeviceCgroupRules": null,
                "DeviceRequests": null,
                "Devices": null,
                "Dns": null,
                "DnsOptions": null,
                "DnsSearch": null,
                "ExtraHosts": null,
                "GroupAdd": null,
                "IOMaximumBandwidth": 0,
                "IOMaximumIOps": 0,
                "IpcMode": "private",
                "Isolation": "",
                "Links": null,
                "LogConfig": {
                    "Config": {
                        "max-file": "5",
                        "max-size": "50m"
                    },
                    "Type": "json-file"
                },
                "MaskedPaths": null,
                "Memory": 0,
                "MemoryReservation": 0,
                "MemorySwap": 0,
                "MemorySwappiness": null,
                "NanoCpus": 0,
                "NetworkMode": "host",
                "OomKillDisable": null,
                "OomScoreAdj": 0,
                "PidMode": "host",
                "PidsLimit": null,
                "PortBindings": {},
                "Privileged": true,
                "PublishAllPorts": false,
                "ReadonlyPaths": null,
                "ReadonlyRootfs": false,
                "RestartPolicy": {
                    "MaximumRetryCount": 0,
                    "Name": "no"
                },
                "Runtime": "runc",
                "SecurityOpt": [
                    "label=disable"
                ],
                "ShmSize": 67108864,
                "UTSMode": "",
                "Ulimits": [
                    {
                        "Hard": 67108864,
                        "Name": "memlock",
                        "Soft": 67108864
                    }
                ],
                "UsernsMode": "",
                "VolumeDriver": "",
                "VolumesFrom": null
            },
            "HostnamePath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hostname",
            "HostsPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hosts",
            "Id": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
            "Image": "sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a",
            "LogPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e-json.log",
            "MountLabel": "",
            "Mounts": [
                {
                    "Destination": "/var/log/kolla",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "kolla_logs",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/etc/libvirt/qemu",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "nova_libvirt_qemu",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/nova_libvirt_qemu/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/lib/kolla/config_files",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/kolla/nova-libvirt",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/localtime",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/localtime",
                    "Type": "bind"
                },
                {
                    "Destination": "/etc/timezone",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/etc/timezone",
                    "Type": "bind"
                },
                {
                    "Destination": "/dev",
                    "Mode": "rw",
                    "Propagation": "rprivate",
                    "RW": true,
                    "Source": "/dev",
                    "Type": "bind"
                },
                {
                    "Destination": "/var/lib/libvirt",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "libvirtd",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/libvirtd/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/var/lib/nova",
                    "Driver": "local",
                    "Mode": "rw",
                    "Name": "nova_compute",
                    "Propagation": "",
                    "RW": true,
                    "Source": "/var/lib/docker/volumes/nova_compute/_data",
                    "Type": "volume"
                },
                {
                    "Destination": "/lib/modules",
                    "Mode": "ro",
                    "Propagation": "rprivate",
                    "RW": false,
                    "Source": "/lib/modules",
                    "Type": "bind"
                },
                {
                    "Destination": "/run",
                    "Mode": "shared",
                    "Propagation": "shared",
                    "RW": true,
                    "Source": "/run",
                    "Type": "bind"
                },
                {
                    "Destination": "/sys/fs/cgroup",
                    "Mode": "rw",
                    "Propagation": "rprivate",
                    "RW": true,
                    "Source": "/sys/fs/cgroup",
                    "Type": "bind"
                }
            ],
            "Name": "/nova_libvirt",
            "NetworkSettings": {
                "Networks": {
                    "host": {
                        "Aliases": null,
                        "DNSNames": null,
                        "DriverOpts": null,
                        "EndpointID": "06fe5587e1b667d8396bd7bfdfe3fb624b6420c8ae2909dcc177255b6ef96bb7",
                        "Gateway": "",
                        "GlobalIPv6Address": "",
                        "GlobalIPv6PrefixLen": 0,
                        "GwPriority": 0,
                        "IPAMConfig": null,
                        "IPAddress": "",
                        "IPPrefixLen": 0,
                        "IPv6Gateway": "",
                        "Links": null,
                        "MacAddress": "",
                        "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                    }
                },
                "Ports": {},
                "SandboxID": "8b09258d0c3762b1a641de2f52676f3d8d8d69295d507b9e758bb50a6519c934",
                "SandboxKey": "/var/run/docker/netns/default"
            },
            "Path": "dumb-init",
            "Platform": "linux",
            "ProcessLabel": "",
            "ResolvConfPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/resolv.conf",
            "RestartCount": 0,
            "State": {
                "Dead": false,
                "Error": "",
                "ExitCode": 0,
                "FinishedAt": "0001-01-01T00:00:00Z",
                "Health": {
                    "FailingStreak": 0,
                    "Status": "healthy"
                },
                "OOMKilled": false,
                "Paused": false,
                "Pid": 92321,
                "Restarting": false,
                "Running": true,
                "StartedAt": "2025-12-10T12:06:49.032795938Z",
                "Status": "running"
            }
        }
    },
    "invocation": {
        "module_args": {
            "action": "get_containers",
            "api_version": "auto",
            "args": {
                "get_all_containers": false
            },
            "container_engine": "docker",
            "name": [
                "nova_libvirt"
            ]
        }
    },
    "item": "localhost",
    "result": false
}

TASK [nova-cell : Get current Libvirt version] *********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:54
skipping: [localhost] => (item=localhost)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.containers[service.container_name].Image != hostvars[groups[service.group] | first].service_image_info.images[0].Id",
    "item": {
        "ansible_loop_var": "item",
        "changed": false,
        "containers": {
            "nova_libvirt": {
                "AppArmorProfile": "unconfined",
                "Args": [
                    "--single-child",
                    "--",
                    "kolla_start"
                ],
                "Config": {
                    "AttachStderr": false,
                    "AttachStdin": false,
                    "AttachStdout": false,
                    "Cmd": [
                        "kolla_start"
                    ],
                    "Domainname": "",
                    "Entrypoint": [
                        "dumb-init",
                        "--single-child",
                        "--"
                    ],
                    "Env": [
                        "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                        "KOLLA_SERVICE_NAME=nova-libvirt",
                        "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                        "LANG=en_US.UTF-8",
                        "KOLLA_BASE_DISTRO=ubuntu",
                        "KOLLA_BASE_ARCH=x86_64",
                        "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                        "DEBIAN_FRONTEND=noninteractive",
                        "PIP_INDEX_URL=",
                        "PIP_TRUSTED_HOST=",
                        "PIP_EXTRA_INDEX_URL="
                    ],
                    "Healthcheck": {
                        "Interval": 30000000000,
                        "Retries": 3,
                        "StartPeriod": 5000000000,
                        "Test": [
                            "CMD-SHELL",
                            "virsh version --daemon"
                        ],
                        "Timeout": 30000000000
                    },
                    "Hostname": "nics-VMware20-1",
                    "Image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
                    "Labels": {
                        "build-date": "20251210",
                        "kolla_version": "21.1.0",
                        "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                        "name": "nova-libvirt",
                        "org.opencontainers.image.ref.name": "ubuntu",
                        "org.opencontainers.image.version": "24.04"
                    },
                    "OpenStdin": false,
                    "StdinOnce": false,
                    "Tty": false,
                    "User": "",
                    "Volumes": {
                        "/dev": {},
                        "/etc/libvirt/qemu": {},
                        "/etc/localtime": {},
                        "/etc/timezone": {},
                        "/lib/modules": {},
                        "/run": {},
                        "/sys/fs/cgroup": {},
                        "/var/lib/kolla/config_files/": {},
                        "/var/lib/libvirt": {},
                        "/var/lib/nova/": {},
                        "/var/log/kolla/": {}
                    },
                    "WorkingDir": ""
                },
                "Created": "2025-12-10T12:06:47.964413255Z",
                "Driver": "overlay2",
                "ExecIDs": null,
                "GraphDriver": {
                    "Data": {
                        "ID": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
                        "LowerDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc-init/diff:/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff:/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                        "MergedDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/merged",
                        "UpperDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/diff",
                        "WorkDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/work"
                    },
                    "Name": "overlay2"
                },
                "HostConfig": {
                    "AutoRemove": false,
                    "Binds": [
                        "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                        "/etc/localtime:/etc/localtime:ro",
                        "/etc/timezone:/etc/timezone:ro",
                        "/lib/modules:/lib/modules:ro",
                        "/run:/run:shared",
                        "/dev:/dev:rw",
                        "/sys/fs/cgroup:/sys/fs/cgroup:rw",
                        "kolla_logs:/var/log/kolla/:rw",
                        "libvirtd:/var/lib/libvirt:rw",
                        "nova_compute:/var/lib/nova/:rw",
                        "nova_libvirt_qemu:/etc/libvirt/qemu:rw"
                    ],
                    "BlkioDeviceReadBps": null,
                    "BlkioDeviceReadIOps": null,
                    "BlkioDeviceWriteBps": null,
                    "BlkioDeviceWriteIOps": null,
                    "BlkioWeight": 0,
                    "BlkioWeightDevice": null,
                    "CapAdd": null,
                    "CapDrop": null,
                    "Cgroup": "",
                    "CgroupParent": "",
                    "CgroupnsMode": "host",
                    "ConsoleSize": [
                        0,
                        0
                    ],
                    "ContainerIDFile": "",
                    "CpuCount": 0,
                    "CpuPercent": 0,
                    "CpuPeriod": 0,
                    "CpuQuota": 0,
                    "CpuRealtimePeriod": 0,
                    "CpuRealtimeRuntime": 0,
                    "CpuShares": 0,
                    "CpusetCpus": "",
                    "CpusetMems": "",
                    "DeviceCgroupRules": null,
                    "DeviceRequests": null,
                    "Devices": null,
                    "Dns": null,
                    "DnsOptions": null,
                    "DnsSearch": null,
                    "ExtraHosts": null,
                    "GroupAdd": null,
                    "IOMaximumBandwidth": 0,
                    "IOMaximumIOps": 0,
                    "IpcMode": "private",
                    "Isolation": "",
                    "Links": null,
                    "LogConfig": {
                        "Config": {
                            "max-file": "5",
                            "max-size": "50m"
                        },
                        "Type": "json-file"
                    },
                    "MaskedPaths": null,
                    "Memory": 0,
                    "MemoryReservation": 0,
                    "MemorySwap": 0,
                    "MemorySwappiness": null,
                    "NanoCpus": 0,
                    "NetworkMode": "host",
                    "OomKillDisable": null,
                    "OomScoreAdj": 0,
                    "PidMode": "host",
                    "PidsLimit": null,
                    "PortBindings": {},
                    "Privileged": true,
                    "PublishAllPorts": false,
                    "ReadonlyPaths": null,
                    "ReadonlyRootfs": false,
                    "RestartPolicy": {
                        "MaximumRetryCount": 0,
                        "Name": "no"
                    },
                    "Runtime": "runc",
                    "SecurityOpt": [
                        "label=disable"
                    ],
                    "ShmSize": 67108864,
                    "UTSMode": "",
                    "Ulimits": [
                        {
                            "Hard": 67108864,
                            "Name": "memlock",
                            "Soft": 67108864
                        }
                    ],
                    "UsernsMode": "",
                    "VolumeDriver": "",
                    "VolumesFrom": null
                },
                "HostnamePath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hostname",
                "HostsPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hosts",
                "Id": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
                "Image": "sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a",
                "LogPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e-json.log",
                "MountLabel": "",
                "Mounts": [
                    {
                        "Destination": "/var/log/kolla",
                        "Driver": "local",
                        "Mode": "rw",
                        "Name": "kolla_logs",
                        "Propagation": "",
                        "RW": true,
                        "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                        "Type": "volume"
                    },
                    {
                        "Destination": "/etc/libvirt/qemu",
                        "Driver": "local",
                        "Mode": "rw",
                        "Name": "nova_libvirt_qemu",
                        "Propagation": "",
                        "RW": true,
                        "Source": "/var/lib/docker/volumes/nova_libvirt_qemu/_data",
                        "Type": "volume"
                    },
                    {
                        "Destination": "/var/lib/kolla/config_files",
                        "Mode": "ro",
                        "Propagation": "rprivate",
                        "RW": false,
                        "Source": "/etc/kolla/nova-libvirt",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/etc/localtime",
                        "Mode": "ro",
                        "Propagation": "rprivate",
                        "RW": false,
                        "Source": "/etc/localtime",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/etc/timezone",
                        "Mode": "ro",
                        "Propagation": "rprivate",
                        "RW": false,
                        "Source": "/etc/timezone",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/dev",
                        "Mode": "rw",
                        "Propagation": "rprivate",
                        "RW": true,
                        "Source": "/dev",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/var/lib/libvirt",
                        "Driver": "local",
                        "Mode": "rw",
                        "Name": "libvirtd",
                        "Propagation": "",
                        "RW": true,
                        "Source": "/var/lib/docker/volumes/libvirtd/_data",
                        "Type": "volume"
                    },
                    {
                        "Destination": "/var/lib/nova",
                        "Driver": "local",
                        "Mode": "rw",
                        "Name": "nova_compute",
                        "Propagation": "",
                        "RW": true,
                        "Source": "/var/lib/docker/volumes/nova_compute/_data",
                        "Type": "volume"
                    },
                    {
                        "Destination": "/lib/modules",
                        "Mode": "ro",
                        "Propagation": "rprivate",
                        "RW": false,
                        "Source": "/lib/modules",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/run",
                        "Mode": "shared",
                        "Propagation": "shared",
                        "RW": true,
                        "Source": "/run",
                        "Type": "bind"
                    },
                    {
                        "Destination": "/sys/fs/cgroup",
                        "Mode": "rw",
                        "Propagation": "rprivate",
                        "RW": true,
                        "Source": "/sys/fs/cgroup",
                        "Type": "bind"
                    }
                ],
                "Name": "/nova_libvirt",
                "NetworkSettings": {
                    "Networks": {
                        "host": {
                            "Aliases": null,
                            "DNSNames": null,
                            "DriverOpts": null,
                            "EndpointID": "06fe5587e1b667d8396bd7bfdfe3fb624b6420c8ae2909dcc177255b6ef96bb7",
                            "Gateway": "",
                            "GlobalIPv6Address": "",
                            "GlobalIPv6PrefixLen": 0,
                            "GwPriority": 0,
                            "IPAMConfig": null,
                            "IPAddress": "",
                            "IPPrefixLen": 0,
                            "IPv6Gateway": "",
                            "Links": null,
                            "MacAddress": "",
                            "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                        }
                    },
                    "Ports": {},
                    "SandboxID": "8b09258d0c3762b1a641de2f52676f3d8d8d69295d507b9e758bb50a6519c934",
                    "SandboxKey": "/var/run/docker/netns/default"
                },
                "Path": "dumb-init",
                "Platform": "linux",
                "ProcessLabel": "",
                "ResolvConfPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/resolv.conf",
                "RestartCount": 0,
                "State": {
                    "Dead": false,
                    "Error": "",
                    "ExitCode": 0,
                    "FinishedAt": "0001-01-01T00:00:00Z",
                    "Health": {
                        "FailingStreak": 0,
                        "Status": "healthy"
                    },
                    "OOMKilled": false,
                    "Paused": false,
                    "Pid": 92321,
                    "Restarting": false,
                    "Running": true,
                    "StartedAt": "2025-12-10T12:06:49.032795938Z",
                    "Status": "running"
                }
            }
        },
        "failed": false,
        "invocation": {
            "module_args": {
                "action": "get_containers",
                "api_version": "auto",
                "args": {
                    "get_all_containers": false
                },
                "container_engine": "docker",
                "name": [
                    "nova_libvirt"
                ]
            }
        },
        "item": "localhost",
        "result": false
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova-cell : Check that the new Libvirt version is >= current] ************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/version-check.yml:71
skipping: [localhost] => (item={'result': False, 'changed': False, 'containers': {'nova_libvirt': {'Id': '46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e', 'Created': '2025-12-10T12:06:47.964413255Z', 'Path': 'dumb-init', 'Args': ['--single-child', '--', 'kolla_start'], 'State': {'Status': 'running', 'Running': True, 'Paused': False, 'Restarting': False, 'OOMKilled': False, 'Dead': False, 'Pid': 92321, 'ExitCode': 0, 'Error': '', 'StartedAt': '2025-12-10T12:06:49.032795938Z', 'FinishedAt': '0001-01-01T00:00:00Z', 'Health': {'Status': 'healthy', 'FailingStreak': 0}}, 'Image': 'sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a', 'ResolvConfPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/resolv.conf', 'HostnamePath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hostname', 'HostsPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hosts', 'LogPath': '/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e-json.log', 'Name': '/nova_libvirt', 'RestartCount': 0, 'Driver': 'overlay2', 'Platform': 'linux', 'MountLabel': '', 'ProcessLabel': '', 'AppArmorProfile': 'unconfined', 'ExecIDs': None, 'HostConfig': {'Binds': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev:rw', '/sys/fs/cgroup:/sys/fs/cgroup:rw', 'kolla_logs:/var/log/kolla/:rw', 'libvirtd:/var/lib/libvirt:rw', 'nova_compute:/var/lib/nova/:rw', 'nova_libvirt_qemu:/etc/libvirt/qemu:rw'], 'ContainerIDFile': '', 'LogConfig': {'Type': 'json-file', 'Config': {'max-file': '5', 'max-size': '50m'}}, 'NetworkMode': 'host', 'PortBindings': {}, 'RestartPolicy': {'Name': 'no', 'MaximumRetryCount': 0}, 'AutoRemove': False, 'VolumeDriver': '', 'VolumesFrom': None, 'ConsoleSize': [0, 0], 'CapAdd': None, 'CapDrop': None, 'CgroupnsMode': 'host', 'Dns': None, 'DnsOptions': None, 'DnsSearch': None, 'ExtraHosts': None, 'GroupAdd': None, 'IpcMode': 'private', 'Cgroup': '', 'Links': None, 'OomScoreAdj': 0, 'PidMode': 'host', 'Privileged': True, 'PublishAllPorts': False, 'ReadonlyRootfs': False, 'SecurityOpt': ['label=disable'], 'UTSMode': '', 'UsernsMode': '', 'ShmSize': 67108864, 'Runtime': 'runc', 'Isolation': '', 'CpuShares': 0, 'Memory': 0, 'NanoCpus': 0, 'CgroupParent': '', 'BlkioWeight': 0, 'BlkioWeightDevice': None, 'BlkioDeviceReadBps': None, 'BlkioDeviceWriteBps': None, 'BlkioDeviceReadIOps': None, 'BlkioDeviceWriteIOps': None, 'CpuPeriod': 0, 'CpuQuota': 0, 'CpuRealtimePeriod': 0, 'CpuRealtimeRuntime': 0, 'CpusetCpus': '', 'CpusetMems': '', 'Devices': None, 'DeviceCgroupRules': None, 'DeviceRequests': None, 'MemoryReservation': 0, 'MemorySwap': 0, 'MemorySwappiness': None, 'OomKillDisable': None, 'PidsLimit': None, 'Ulimits': [{'Name': 'memlock', 'Hard': 67108864, 'Soft': 67108864}], 'CpuCount': 0, 'CpuPercent': 0, 'IOMaximumIOps': 0, 'IOMaximumBandwidth': 0, 'MaskedPaths': None, 'ReadonlyPaths': None}, 'GraphDriver': {'Data': {'ID': '46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e', 'LowerDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc-init/diff:/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff:/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff', 'MergedDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/merged', 'UpperDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/diff', 'WorkDir': '/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/work'}, 'Name': 'overlay2'}, 'Mounts': [{'Type': 'volume', 'Name': 'kolla_logs', 'Source': '/var/lib/docker/volumes/kolla_logs/_data', 'Destination': '/var/log/kolla', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'volume', 'Name': 'nova_libvirt_qemu', 'Source': '/var/lib/docker/volumes/nova_libvirt_qemu/_data', 'Destination': '/etc/libvirt/qemu', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'bind', 'Source': '/etc/kolla/nova-libvirt', 'Destination': '/var/lib/kolla/config_files', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/etc/localtime', 'Destination': '/etc/localtime', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/etc/timezone', 'Destination': '/etc/timezone', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/dev', 'Destination': '/dev', 'Mode': 'rw', 'RW': True, 'Propagation': 'rprivate'}, {'Type': 'volume', 'Name': 'libvirtd', 'Source': '/var/lib/docker/volumes/libvirtd/_data', 'Destination': '/var/lib/libvirt', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'volume', 'Name': 'nova_compute', 'Source': '/var/lib/docker/volumes/nova_compute/_data', 'Destination': '/var/lib/nova', 'Driver': 'local', 'Mode': 'rw', 'RW': True, 'Propagation': ''}, {'Type': 'bind', 'Source': '/lib/modules', 'Destination': '/lib/modules', 'Mode': 'ro', 'RW': False, 'Propagation': 'rprivate'}, {'Type': 'bind', 'Source': '/run', 'Destination': '/run', 'Mode': 'shared', 'RW': True, 'Propagation': 'shared'}, {'Type': 'bind', 'Source': '/sys/fs/cgroup', 'Destination': '/sys/fs/cgroup', 'Mode': 'rw', 'RW': True, 'Propagation': 'rprivate'}], 'Config': {'Hostname': 'nics-VMware20-1', 'Domainname': '', 'User': '', 'AttachStdin': False, 'AttachStdout': False, 'AttachStderr': False, 'Tty': False, 'OpenStdin': False, 'StdinOnce': False, 'Env': ['KOLLA_CONFIG_STRATEGY=COPY_ALWAYS', 'KOLLA_SERVICE_NAME=nova-libvirt', 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LANG=en_US.UTF-8', 'KOLLA_BASE_DISTRO=ubuntu', 'KOLLA_BASE_ARCH=x86_64', 'PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ', 'DEBIAN_FRONTEND=noninteractive', 'PIP_INDEX_URL=', 'PIP_TRUSTED_HOST=', 'PIP_EXTRA_INDEX_URL='], 'Cmd': ['kolla_start'], 'Healthcheck': {'Test': ['CMD-SHELL', 'virsh version --daemon'], 'Interval': 30000000000, 'Timeout': 30000000000, 'StartPeriod': 5000000000, 'Retries': 3}, 'Image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'Volumes': {'/dev': {}, '/etc/libvirt/qemu': {}, '/etc/localtime': {}, '/etc/timezone': {}, '/lib/modules': {}, '/run': {}, '/sys/fs/cgroup': {}, '/var/lib/kolla/config_files/': {}, '/var/lib/libvirt': {}, '/var/lib/nova/': {}, '/var/log/kolla/': {}}, 'WorkingDir': '', 'Entrypoint': ['dumb-init', '--single-child', '--'], 'Labels': {'build-date': '20251210', 'kolla_version': '21.1.0', 'maintainer': 'Kolla Project (https://launchpad.net/kolla)', 'name': 'nova-libvirt', 'org.opencontainers.image.ref.name': 'ubuntu', 'org.opencontainers.image.version': '24.04'}}, 'NetworkSettings': {'SandboxID': '8b09258d0c3762b1a641de2f52676f3d8d8d69295d507b9e758bb50a6519c934', 'SandboxKey': '/var/run/docker/netns/default', 'Ports': {}, 'Networks': {'host': {'IPAMConfig': None, 'Links': None, 'Aliases': None, 'DriverOpts': None, 'GwPriority': 0, 'NetworkID': '72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af', 'EndpointID': '06fe5587e1b667d8396bd7bfdfe3fb624b6420c8ae2909dcc177255b6ef96bb7', 'Gateway': '', 'IPAddress': '', 'MacAddress': '', 'IPPrefixLen': 0, 'IPv6Gateway': '', 'GlobalIPv6Address': '', 'GlobalIPv6PrefixLen': 0, 'DNSNames': None}}}}}, 'invocation': {'module_args': {'action': 'get_containers', 'container_engine': 'docker', 'name': ['nova_libvirt'], 'api_version': 'auto', 'args': {'get_all_containers': False}}}, 'failed': False, 'item': 'localhost', 'ansible_loop_var': 'item'})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.stdout is defined",
    "item": {
        "ansible_loop_var": "item",
        "changed": false,
        "false_condition": "item.containers[service.container_name].Image != hostvars[groups[service.group] | first].service_image_info.images[0].Id",
        "item": {
            "ansible_loop_var": "item",
            "changed": false,
            "containers": {
                "nova_libvirt": {
                    "AppArmorProfile": "unconfined",
                    "Args": [
                        "--single-child",
                        "--",
                        "kolla_start"
                    ],
                    "Config": {
                        "AttachStderr": false,
                        "AttachStdin": false,
                        "AttachStdout": false,
                        "Cmd": [
                            "kolla_start"
                        ],
                        "Domainname": "",
                        "Entrypoint": [
                            "dumb-init",
                            "--single-child",
                            "--"
                        ],
                        "Env": [
                            "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS",
                            "KOLLA_SERVICE_NAME=nova-libvirt",
                            "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                            "LANG=en_US.UTF-8",
                            "KOLLA_BASE_DISTRO=ubuntu",
                            "KOLLA_BASE_ARCH=x86_64",
                            "PS1=$(tput bold)($(printenv KOLLA_SERVICE_NAME))$(tput sgr0)[$(id -un)@$(hostname -s) $(pwd)]$ ",
                            "DEBIAN_FRONTEND=noninteractive",
                            "PIP_INDEX_URL=",
                            "PIP_TRUSTED_HOST=",
                            "PIP_EXTRA_INDEX_URL="
                        ],
                        "Healthcheck": {
                            "Interval": 30000000000,
                            "Retries": 3,
                            "StartPeriod": 5000000000,
                            "Test": [
                                "CMD-SHELL",
                                "virsh version --daemon"
                            ],
                            "Timeout": 30000000000
                        },
                        "Hostname": "nics-VMware20-1",
                        "Image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
                        "Labels": {
                            "build-date": "20251210",
                            "kolla_version": "21.1.0",
                            "maintainer": "Kolla Project (https://launchpad.net/kolla)",
                            "name": "nova-libvirt",
                            "org.opencontainers.image.ref.name": "ubuntu",
                            "org.opencontainers.image.version": "24.04"
                        },
                        "OpenStdin": false,
                        "StdinOnce": false,
                        "Tty": false,
                        "User": "",
                        "Volumes": {
                            "/dev": {},
                            "/etc/libvirt/qemu": {},
                            "/etc/localtime": {},
                            "/etc/timezone": {},
                            "/lib/modules": {},
                            "/run": {},
                            "/sys/fs/cgroup": {},
                            "/var/lib/kolla/config_files/": {},
                            "/var/lib/libvirt": {},
                            "/var/lib/nova/": {},
                            "/var/log/kolla/": {}
                        },
                        "WorkingDir": ""
                    },
                    "Created": "2025-12-10T12:06:47.964413255Z",
                    "Driver": "overlay2",
                    "ExecIDs": null,
                    "GraphDriver": {
                        "Data": {
                            "ID": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
                            "LowerDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc-init/diff:/var/lib/docker/overlay2/9c04a77351285a3a6c3c88b0f360f6c20432e6ceb767c49adf1c86f907e85500/diff:/var/lib/docker/overlay2/e4fde224eddb897a8b8636582c41e27a3ea91c160db07c235bb320d94ada7e5b/diff:/var/lib/docker/overlay2/84c2fb4ef6bbbd4f208679bbe1fed1974a56c1ef9817c0179002ae5e2dfdfe2d/diff:/var/lib/docker/overlay2/9c4be7cd8c4c9f6dc00adecd6758894c33e1126f39eb8d832761500bfa851a98/diff:/var/lib/docker/overlay2/feff51552a7d2889f441d5ba65bec73cb942b0c3a51bf6bb462c97872b8a79f8/diff:/var/lib/docker/overlay2/96731e1375699b7b5b607d09f4bbf44dbc14e08e63274db5255a28ee867ffc91/diff:/var/lib/docker/overlay2/7d8ef97fa24188bc54c658f712a51db1f35e646dab199a7e4d8d773060fd55df/diff:/var/lib/docker/overlay2/393883fcdb28d13a1292a5b7601c994f4037df82175dbc66a7c8aa2196f8a9fe/diff:/var/lib/docker/overlay2/85dc93b6a376c6cb49a61441f8952aa591cbedf15ec66da9b9b89e0160e06de8/diff:/var/lib/docker/overlay2/a0336dbfb4159019c1f14c48d162280fc493a7a981a9b50d6c6d605cf9b51aa5/diff:/var/lib/docker/overlay2/b758418a188d57377838973c3509400bacabe7f57fe592e3ed2997cae1ff751b/diff:/var/lib/docker/overlay2/505f82bc8ca4e3f9f34add1e15ce455fbbd6e584bd25ec08be24060dfb51410d/diff:/var/lib/docker/overlay2/8c45ce4ce1657940d0ce4751c0cbe75e0a733dae8bd0d53eee28eb2268278219/diff:/var/lib/docker/overlay2/6452149baa59d5e028e380816334f012c80484dd1317f8206252e600b1e1009e/diff:/var/lib/docker/overlay2/ec65f8fe15e7ce6c8800ee72c4b2beb55bfa8019c9e2404d7dd86a713f1177cf/diff:/var/lib/docker/overlay2/e0ad3c13bff995619d799d117c098e820234225c802d4a670fc50974bb2dfb10/diff:/var/lib/docker/overlay2/3adf4dc315f454ad3315650001629f62573eff53d3b4584200196a5826228389/diff:/var/lib/docker/overlay2/e00b7170bc685b06e6aa677936f0c23318aaa7d3b8af1bb8f38fbb78eec506d0/diff:/var/lib/docker/overlay2/ff53165a2ea15d53cf34360ff69035d386ec75eaac532f0e437eb8727673173a/diff:/var/lib/docker/overlay2/f74b450523f9c93fc77d904aea2ca093df280a71d1dd0efc227e45428d246abd/diff:/var/lib/docker/overlay2/e5e2f3dc2f03a8f7efac26cdf311c4c2785437cd6c00bbb861993c798d826836/diff:/var/lib/docker/overlay2/8931a79683b1e5e3eabf981e58b7ad4cd4238dcc341f03fe4b8e34a1f77c72ea/diff:/var/lib/docker/overlay2/a3b6943987be8c45a25813fc44f8d69cfa8bb596b2079c8b93c40397eeb43598/diff:/var/lib/docker/overlay2/16e0132561579a890cc5aaa2885e4b9e994ef98ba7c263c4dd88cc37890dcc58/diff:/var/lib/docker/overlay2/996e7619843b20aba168d24f5a769ec846f6a09e388655783812f7128dbb8008/diff:/var/lib/docker/overlay2/ec75269cbaf39ea4d9831284c726f1720c9d49c7ed40dd985c0420818a953258/diff:/var/lib/docker/overlay2/8e2fd330dbbc20eb384b7cce70c78d4a624566f494d0e8883da16201d31bafc1/diff:/var/lib/docker/overlay2/defe5106fe79b83e6bfeaf30888a8f14111356e5209d347a5abce0d6386b0be9/diff:/var/lib/docker/overlay2/12b97e5f14dc307cafa2d0ae72ffac6c5ac4c1121387d88a293803648f20d098/diff:/var/lib/docker/overlay2/5efaffe0e47d334ef805151adf8a66fe63741aac1e7649308f3e322e5be05408/diff:/var/lib/docker/overlay2/d9d8f0fe5026a67c21abd2e64210e2d555e911de17a49681bbc7bc4b01200e30/diff:/var/lib/docker/overlay2/f0afdae98216f63ebd95b52fea5560f91dcd7bdc111ea71dcbaf9864e9666625/diff:/var/lib/docker/overlay2/6ef540ee8ee6c64a025b7ab25a474514993c84229a80c5affc83180cfc045b26/diff:/var/lib/docker/overlay2/5205d1fcc356773406b762878a4bdfd1e1f98b0a6cc4b24540d8278257cb9e89/diff:/var/lib/docker/overlay2/29beb614574446732a847b9255d9885ee26e6cf10e28a1db07b66d014f857d1a/diff",
                            "MergedDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/merged",
                            "UpperDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/diff",
                            "WorkDir": "/var/lib/docker/overlay2/85e266db6fb4c02fe678d668066b90c119cbc53b929f4a72e6506351bc8607bc/work"
                        },
                        "Name": "overlay2"
                    },
                    "HostConfig": {
                        "AutoRemove": false,
                        "Binds": [
                            "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                            "/etc/localtime:/etc/localtime:ro",
                            "/etc/timezone:/etc/timezone:ro",
                            "/lib/modules:/lib/modules:ro",
                            "/run:/run:shared",
                            "/dev:/dev:rw",
                            "/sys/fs/cgroup:/sys/fs/cgroup:rw",
                            "kolla_logs:/var/log/kolla/:rw",
                            "libvirtd:/var/lib/libvirt:rw",
                            "nova_compute:/var/lib/nova/:rw",
                            "nova_libvirt_qemu:/etc/libvirt/qemu:rw"
                        ],
                        "BlkioDeviceReadBps": null,
                        "BlkioDeviceReadIOps": null,
                        "BlkioDeviceWriteBps": null,
                        "BlkioDeviceWriteIOps": null,
                        "BlkioWeight": 0,
                        "BlkioWeightDevice": null,
                        "CapAdd": null,
                        "CapDrop": null,
                        "Cgroup": "",
                        "CgroupParent": "",
                        "CgroupnsMode": "host",
                        "ConsoleSize": [
                            0,
                            0
                        ],
                        "ContainerIDFile": "",
                        "CpuCount": 0,
                        "CpuPercent": 0,
                        "CpuPeriod": 0,
                        "CpuQuota": 0,
                        "CpuRealtimePeriod": 0,
                        "CpuRealtimeRuntime": 0,
                        "CpuShares": 0,
                        "CpusetCpus": "",
                        "CpusetMems": "",
                        "DeviceCgroupRules": null,
                        "DeviceRequests": null,
                        "Devices": null,
                        "Dns": null,
                        "DnsOptions": null,
                        "DnsSearch": null,
                        "ExtraHosts": null,
                        "GroupAdd": null,
                        "IOMaximumBandwidth": 0,
                        "IOMaximumIOps": 0,
                        "IpcMode": "private",
                        "Isolation": "",
                        "Links": null,
                        "LogConfig": {
                            "Config": {
                                "max-file": "5",
                                "max-size": "50m"
                            },
                            "Type": "json-file"
                        },
                        "MaskedPaths": null,
                        "Memory": 0,
                        "MemoryReservation": 0,
                        "MemorySwap": 0,
                        "MemorySwappiness": null,
                        "NanoCpus": 0,
                        "NetworkMode": "host",
                        "OomKillDisable": null,
                        "OomScoreAdj": 0,
                        "PidMode": "host",
                        "PidsLimit": null,
                        "PortBindings": {},
                        "Privileged": true,
                        "PublishAllPorts": false,
                        "ReadonlyPaths": null,
                        "ReadonlyRootfs": false,
                        "RestartPolicy": {
                            "MaximumRetryCount": 0,
                            "Name": "no"
                        },
                        "Runtime": "runc",
                        "SecurityOpt": [
                            "label=disable"
                        ],
                        "ShmSize": 67108864,
                        "UTSMode": "",
                        "Ulimits": [
                            {
                                "Hard": 67108864,
                                "Name": "memlock",
                                "Soft": 67108864
                            }
                        ],
                        "UsernsMode": "",
                        "VolumeDriver": "",
                        "VolumesFrom": null
                    },
                    "HostnamePath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hostname",
                    "HostsPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/hosts",
                    "Id": "46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e",
                    "Image": "sha256:8b3ef8928eef519a76d1b2f3fbae768bb2552549f2ee1b846bda4fa560519c8a",
                    "LogPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e-json.log",
                    "MountLabel": "",
                    "Mounts": [
                        {
                            "Destination": "/var/log/kolla",
                            "Driver": "local",
                            "Mode": "rw",
                            "Name": "kolla_logs",
                            "Propagation": "",
                            "RW": true,
                            "Source": "/var/lib/docker/volumes/kolla_logs/_data",
                            "Type": "volume"
                        },
                        {
                            "Destination": "/etc/libvirt/qemu",
                            "Driver": "local",
                            "Mode": "rw",
                            "Name": "nova_libvirt_qemu",
                            "Propagation": "",
                            "RW": true,
                            "Source": "/var/lib/docker/volumes/nova_libvirt_qemu/_data",
                            "Type": "volume"
                        },
                        {
                            "Destination": "/var/lib/kolla/config_files",
                            "Mode": "ro",
                            "Propagation": "rprivate",
                            "RW": false,
                            "Source": "/etc/kolla/nova-libvirt",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/etc/localtime",
                            "Mode": "ro",
                            "Propagation": "rprivate",
                            "RW": false,
                            "Source": "/etc/localtime",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/etc/timezone",
                            "Mode": "ro",
                            "Propagation": "rprivate",
                            "RW": false,
                            "Source": "/etc/timezone",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/dev",
                            "Mode": "rw",
                            "Propagation": "rprivate",
                            "RW": true,
                            "Source": "/dev",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/var/lib/libvirt",
                            "Driver": "local",
                            "Mode": "rw",
                            "Name": "libvirtd",
                            "Propagation": "",
                            "RW": true,
                            "Source": "/var/lib/docker/volumes/libvirtd/_data",
                            "Type": "volume"
                        },
                        {
                            "Destination": "/var/lib/nova",
                            "Driver": "local",
                            "Mode": "rw",
                            "Name": "nova_compute",
                            "Propagation": "",
                            "RW": true,
                            "Source": "/var/lib/docker/volumes/nova_compute/_data",
                            "Type": "volume"
                        },
                        {
                            "Destination": "/lib/modules",
                            "Mode": "ro",
                            "Propagation": "rprivate",
                            "RW": false,
                            "Source": "/lib/modules",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/run",
                            "Mode": "shared",
                            "Propagation": "shared",
                            "RW": true,
                            "Source": "/run",
                            "Type": "bind"
                        },
                        {
                            "Destination": "/sys/fs/cgroup",
                            "Mode": "rw",
                            "Propagation": "rprivate",
                            "RW": true,
                            "Source": "/sys/fs/cgroup",
                            "Type": "bind"
                        }
                    ],
                    "Name": "/nova_libvirt",
                    "NetworkSettings": {
                        "Networks": {
                            "host": {
                                "Aliases": null,
                                "DNSNames": null,
                                "DriverOpts": null,
                                "EndpointID": "06fe5587e1b667d8396bd7bfdfe3fb624b6420c8ae2909dcc177255b6ef96bb7",
                                "Gateway": "",
                                "GlobalIPv6Address": "",
                                "GlobalIPv6PrefixLen": 0,
                                "GwPriority": 0,
                                "IPAMConfig": null,
                                "IPAddress": "",
                                "IPPrefixLen": 0,
                                "IPv6Gateway": "",
                                "Links": null,
                                "MacAddress": "",
                                "NetworkID": "72f43f12bcfa60a060ee17c98e79bf195c0edd2d4cc0dad8d390458745d955af"
                            }
                        },
                        "Ports": {},
                        "SandboxID": "8b09258d0c3762b1a641de2f52676f3d8d8d69295d507b9e758bb50a6519c934",
                        "SandboxKey": "/var/run/docker/netns/default"
                    },
                    "Path": "dumb-init",
                    "Platform": "linux",
                    "ProcessLabel": "",
                    "ResolvConfPath": "/var/lib/docker/containers/46dcf6694df2015238acb1af128c82fce9f7bd15c237248e9ea281dba2a4697e/resolv.conf",
                    "RestartCount": 0,
                    "State": {
                        "Dead": false,
                        "Error": "",
                        "ExitCode": 0,
                        "FinishedAt": "0001-01-01T00:00:00Z",
                        "Health": {
                            "FailingStreak": 0,
                            "Status": "healthy"
                        },
                        "OOMKilled": false,
                        "Paused": false,
                        "Pid": 92321,
                        "Restarting": false,
                        "Running": true,
                        "StartedAt": "2025-12-10T12:06:49.032795938Z",
                        "Status": "running"
                    }
                }
            },
            "failed": false,
            "invocation": {
                "module_args": {
                    "action": "get_containers",
                    "api_version": "auto",
                    "args": {
                        "get_all_containers": false
                    },
                    "container_engine": "docker",
                    "name": [
                        "nova_libvirt"
                    ]
                }
            },
            "item": "localhost",
            "result": false
        },
        "skip_reason": "Conditional result was False",
        "skipped": true
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [Load and persist br_netfilter module] ************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config-host.yml:2
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
included: module-load for localhost

TASK [module-load : Load modules] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:8
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741 `" && echo ansible-tmp-1765372092.516406-271603-245352672742741="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.modprobe to community.general.modprobe
Using module file /home/nics/.ansible/collections/ansible_collections/community/general/plugins/modules/modprobe.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmph2z8sq7y TO /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741/AnsiballZ_modprobe.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741/ /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741/AnsiballZ_modprobe.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-brkcvaffqmbywjvfkfmrcatdkyeevota ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741/AnsiballZ_modprobe.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372092.516406-271603-245352672742741/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=br_netfilter) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "name": "br_netfilter",
            "params": "",
            "persistent": "disabled",
            "state": "present"
        }
    },
    "item": {
        "name": "br_netfilter"
    },
    "name": "br_netfilter",
    "params": "",
    "state": "present"
}

TASK [module-load : Persist modules via modules-load.d] ************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:18
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839 `" && echo ansible-tmp-1765372093.113808-271635-190910524745839="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpc9b0s7s7 TO /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/ /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-epsehabsqptlxjmasibeecflberireft ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpz7aqeowq TO /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/ /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tmfqmktnhpivtcpktzwmmycpjafdcnmg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372093.113808-271635-190910524745839/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=br_netfilter) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "95f40cda62dc4d1f4975ef2d651fbe20f9c57607",
    "dest": "/etc/modules-load.d/br_netfilter.conf",
    "diff": {
        "after": {
            "path": "/etc/modules-load.d/br_netfilter.conf"
        },
        "before": {
            "path": "/etc/modules-load.d/br_netfilter.conf"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "module-load.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/modules-load.d/br_netfilter.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/modules-load.d/br_netfilter.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "name": "br_netfilter"
    },
    "mode": "0644",
    "owner": "root",
    "path": "/etc/modules-load.d/br_netfilter.conf",
    "size": 32,
    "state": "file",
    "uid": 0
}

TASK [module-load : Drop module persistence] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/module-load/tasks/main.yml:29
skipping: [localhost] => (item=br_netfilter)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "(item.state | default('present')) == 'absent'",
    "item": {
        "name": "br_netfilter"
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova-cell : Enable bridge-nf-call sysctl variables] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config-host.yml:11
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257 `" && echo ansible-tmp-1765372094.0627394-271769-272910517303257="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmplsco850q TO /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257/ /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-bjeghqclpdjoptekelaeofocqscwjqii ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372094.0627394-271769-272910517303257/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=net.bridge.bridge-nf-call-iptables) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.bridge.bridge-nf-call-iptables",
            "reload": true,
            "state": "present",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": true,
            "value": "1"
        }
    },
    "item": "net.bridge.bridge-nf-call-iptables"
}
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469 `" && echo ansible-tmp-1765372094.5648248-271769-234502944522469="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.sysctl to ansible.posix.sysctl
Using module file /home/nics/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/sysctl.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9l32kjky TO /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469/AnsiballZ_sysctl.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469/ /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469/AnsiballZ_sysctl.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fhcnbylsgewxzxnpuprqtezrapfejnpy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469/AnsiballZ_sysctl.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372094.5648248-271769-234502944522469/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item=net.bridge.bridge-nf-call-ip6tables) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "ignoreerrors": false,
            "name": "net.bridge.bridge-nf-call-ip6tables",
            "reload": true,
            "state": "present",
            "sysctl_file": "/etc/sysctl.conf",
            "sysctl_set": true,
            "value": "1"
        }
    },
    "item": "net.bridge.bridge-nf-call-ip6tables"
}

TASK [nova-cell : Install udev kolla kvm rules] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config-host.yml:30
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_compute_virt_type == 'kvm'",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Mask qemu-kvm service] ***************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config-host.yml:44
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_compute_virt_type == 'kvm'",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Ensuring config directories exist] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396 `" && echo ansible-tmp-1765372095.6863425-271903-148677527404396="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpcqfhcx74 TO /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396/ /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pgvobvtjnnkrdnowumulfghhpkmebqga ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372095.6863425-271903-148677527404396/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-libvirt",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-libvirt",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992 `" && echo ansible-tmp-1765372096.0562668-271903-36484363102992="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwbe34_o5 TO /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992/ /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-djptmfpnljiifubztgaqmrntsojibxfy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372096.0562668-271903-36484363102992/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-ssh",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-ssh",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044 `" && echo ansible-tmp-1765372096.460921-271903-30322316331044="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmps4gasy4p TO /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044/ /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sutjlupfzvnmqhvhtudovtotjedmmygt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372096.460921-271903-30322316331044/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-novncproxy"
        },
        "before": {
            "path": "/etc/kolla/nova-novncproxy"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-novncproxy",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-novncproxy",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803 `" && echo ansible-tmp-1765372096.9256759-271903-217635569698803="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4dlhzpeo TO /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803/ /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zeuqlbaqulporeqplfsezrmqttvmymkn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372096.9256759-271903-217635569698803/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-conductor"
        },
        "before": {
            "path": "/etc/kolla/nova-conductor"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-conductor",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-conductor",
    "size": 4096,
    "state": "directory",
    "uid": 0
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719 `" && echo ansible-tmp-1765372097.2895565-271903-124649335016719="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpobq9t9ju TO /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719/ /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fclazjmzahaywuvqfacbykpusljkzsqq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372097.2895565-271903-124649335016719/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-compute"
        },
        "before": {
            "path": "/etc/kolla/nova-compute"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": "root",
            "mode": "0770",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": "root",
            "path": "/etc/kolla/nova-compute",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "mode": "0770",
    "owner": "root",
    "path": "/etc/kolla/nova-compute",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [nova-cell : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:12
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_cell_copy_certs | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:16
skipping: [localhost] => {
    "changed": false,
    "false_condition": "(nova_backend == \"rbd\" or cinder_backend_ceph | bool)",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Check if policies shall be overwritten] **********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:21
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [nova-cell : Set nova policy file] ****************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:33
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_policy.results | length > 0",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Check for vendordata file] ***********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:40
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839 `" && echo ansible-tmp-1765372098.0484953-272167-275026286021839="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_p96u6ya TO /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839/ /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372098.0484953-272167-275026286021839/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_mime": true,
            "path": "/etc/kolla/config/nova/vendordata.json"
        }
    },
    "stat": {
        "exists": false
    }
}

TASK [nova-cell : Set vendordata file path] ************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:47
skipping: [localhost] => {
    "changed": false,
    "false_condition": "vendordata_file.stat.exists",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Copying over config.json files for services] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:53
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119 `" && echo ansible-tmp-1765372098.8107045-272223-10401325678119="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv604w_6n TO /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/ /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pyofixfazgoyvcdegnjjexfseyjxviwj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp9xkd3uht TO /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/ /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qykebtvaglkbbuatxzofvjuchbzdzhqp ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372098.8107045-272223-10401325678119/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "6388d581a0c52b0c4b68c8c44a02d704c8a44033",
    "dest": "/etc/kolla/nova-libvirt/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-libvirt.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-libvirt/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-libvirt/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-libvirt/config.json",
    "size": 838,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622 `" && echo ansible-tmp-1765372099.4888308-272223-151088023153622="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6s3_9ii9 TO /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/ /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-idcjjgemmwhtehyiohksycvpqbdrzyvd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp05y4adk2 TO /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/ /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dduksrdznvljrchxtaedantjyzjyqkeh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372099.4888308-272223-151088023153622/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "d564cd8272865d05891aaf46dcb022b068e8cbd3",
    "dest": "/etc/kolla/nova-ssh/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-ssh.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-ssh/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-ssh/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-ssh/config.json",
    "size": 827,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909 `" && echo ansible-tmp-1765372100.1818082-272223-55626952304909="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprkjgogsx TO /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/ /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ecpvginwdbnztnvtrrfexpldgttzwlra ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpd6_j8z1a TO /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/ /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-fufvunpnfajzoigxeodgtlpeixvfekcg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372100.1818082-272223-55626952304909/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "8c96033e8fac6f4e479e401e523113631abb849d",
    "dest": "/etc/kolla/nova-novncproxy/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-novncproxy/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-novncproxy/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-novncproxy.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-novncproxy/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-novncproxy/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-novncproxy/config.json",
    "size": 400,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588 `" && echo ansible-tmp-1765372100.8647275-272223-95521297771588="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp05t55rwx TO /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/ /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-urvcxkifdheisxxjggevrblwijkyybht ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp31g1gdup TO /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/ /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vsivctfuqwpndvvgvdypjlxlpdnvxzeb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372100.8647275-272223-95521297771588/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "59f3ddc08a271182533b337ef0b073597d558358",
    "dest": "/etc/kolla/nova-conductor/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-conductor/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-conductor/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-conductor.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-conductor/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-conductor/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-conductor/config.json",
    "size": 399,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687 `" && echo ansible-tmp-1765372101.5633934-272223-4551737076687="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpl74xk80c TO /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/ /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zdrmqihokkemqjraqjeibgxofnqjgtou ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkchncnkk TO /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/ /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jlfpmmsfhoxtrqmjkhduapnpkbrgxztj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372101.5633934-272223-4551737076687/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "799c493fab9f2736ea61f0c73da99f39657c0b7b",
    "dest": "/etc/kolla/nova-compute/config.json",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-compute/config.json"
        },
        "before": {
            "path": "/etc/kolla/nova-compute/config.json"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "nova-compute.json.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-compute/config.json",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-compute/config.json",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-compute/config.json",
    "size": 1108,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying over nova.conf] **************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:61
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key in nova_cell_services_require_nova_conf",
    "item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "item.key in nova_cell_services_require_nova_conf",
    "item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195 `" && echo ansible-tmp-1765372102.7425997-272487-43790770570195="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmppaesl405 TO /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/ /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ztayfxmdntmdtzoicgyycttilrszhocy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprxq9t48s TO /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/ /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mjbhozuksevikfxkplawzxoqjxagkgub ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372102.7425997-272487-43790770570195/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "e48b652702021ba677c3bb9bf81937e399124c99",
    "dest": "/etc/kolla/nova-novncproxy/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-novncproxy/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-novncproxy/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-novncproxy/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-novncproxy/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-novncproxy.conf",
                "/etc/kolla/config/nova/localhost/nova.conf",
                "/etc/kolla/config/nova/localhost/nova-novncproxy.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7cj5o1r0/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-novncproxy/nova.conf",
    "size": 2355,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547 `" && echo ansible-tmp-1765372103.7415907-272487-152926922041547="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpxuttcb0f TO /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/ /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-eunaxmdbprofujdswqiicfgwlslxtfik ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwa69o1ce TO /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/ /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mftuiyodaojersnpseziqdsdcjursztf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372103.7415907-272487-152926922041547/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "122bb1350d9199568778b6f0852ab0695c58ac05",
    "dest": "/etc/kolla/nova-conductor/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-conductor/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-conductor/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-conductor/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-conductor/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-conductor.conf",
                "/etc/kolla/config/nova/localhost/nova.conf",
                "/etc/kolla/config/nova/localhost/nova-conductor.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpb3hwur_c/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-conductor/nova.conf",
    "size": 2573,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856 `" && echo ansible-tmp-1765372104.7362397-272487-84916682100856="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp4nl2yoqa TO /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/ /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mpbvoxvysxcieqmgoocmxdbsmpghptzj ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp1d26z3tq TO /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/ /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-gazpopzjqeosmmanqqugmunhkpafugfd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372104.7362397-272487-84916682100856/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "b020e3b350b3bbb6f7e2e5e9ee20aa2081afc05f",
    "dest": "/etc/kolla/nova-compute/nova.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-compute/nova.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-compute/nova.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "source",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-compute/nova.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-compute/nova.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "sources": [
                "/home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/templates/nova.conf.j2",
                "/etc/kolla/config/global.conf",
                "/etc/kolla/config/nova.conf",
                "/etc/kolla/config/nova/nova-compute.conf",
                "/etc/kolla/config/nova/localhost/nova.conf",
                "/etc/kolla/config/nova/localhost/nova-compute.conf"
            ],
            "src": "/home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp06q6vmso/source",
            "state": "file",
            "unsafe_writes": false,
            "whitespace": true
        }
    },
    "item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-compute/nova.conf",
    "size": 2348,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying over Nova compute provider config] *******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:79
skipping: [localhost] => {
    "changed": false,
    "false_condition": "nova_cell_compute_provider_config is defined",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Copying over libvirt configuration] **************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:91
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608 `" && echo ansible-tmp-1765372106.7416642-272721-208755665195608="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqy10zw5a TO /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/ /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-vullqigmlgildndjkouvrdiqknvktwiv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8panka53 TO /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/ /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-trkdklbpzdignlshcwzqjajlqtnmherq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372106.7416642-272721-208755665195608/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'qemu.conf.j2', 'dest': 'qemu.conf'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "a086958af1f7d38df9703282ac15cc9f1c11d259",
    "dest": "/etc/kolla/nova-libvirt/qemu.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt/qemu.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt/qemu.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "qemu.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-libvirt/qemu.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-libvirt/qemu.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "qemu.conf",
        "src": "qemu.conf.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-libvirt/qemu.conf",
    "size": 97,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836 `" && echo ansible-tmp-1765372107.7412882-272721-263631522196836="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7ebnw7n8 TO /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/ /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-phxmwutrwqoixugbopufxryajdrxcwva ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpikd25m1l TO /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/ /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pktoqxglqprmmgssspekglakippbmeeh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372107.7412882-272721-263631522196836/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'libvirtd.conf.j2', 'dest': 'libvirtd.conf'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "ceea9341665f054e7f13ae5d8c8d8ef279267891",
    "dest": "/etc/kolla/nova-libvirt/libvirtd.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt/libvirtd.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt/libvirtd.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "libvirtd.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-libvirt/libvirtd.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-libvirt/libvirtd.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "libvirtd.conf",
        "src": "libvirtd.conf.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-libvirt/libvirtd.conf",
    "size": 183,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying over libvirt TLS keys] *******************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:104
skipping: [localhost] => {
    "changed": false,
    "false_condition": "libvirt_tls | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Copying over libvirt SASL configuration] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:111
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137 `" && echo ansible-tmp-1765372108.9573596-272859-123897923976137="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp8j6t8ggo TO /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/ /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-kkwjnxtharpfjuaowuinyaphycdkskuu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp_0pjxroa TO /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/ /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ahlkefomidujgqbkbylonbyacegjczwb ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372108.9573596-272859-123897923976137/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-compute'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "53d9a915c7adf27524c8a8373d51e30c915dc043",
    "dest": "/etc/kolla/nova-compute/auth.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-compute/auth.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-compute/auth.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "auth.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-compute/auth.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-compute/auth.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "auth.conf",
        "service": "nova-compute",
        "src": "auth.conf.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-compute/auth.conf",
    "size": 130,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172 `" && echo ansible-tmp-1765372110.0105479-272859-240224387246172="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjqdbiovr TO /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/ /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lckupifhqsndwgcjleurkbtkznuvxqpf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2vtxr10h TO /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/ /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ydpinufdsmelnjidrnvxblgppbajgkvi ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372110.0105479-272859-240224387246172/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'auth.conf.j2', 'dest': 'auth.conf', 'service': 'nova-libvirt'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "53d9a915c7adf27524c8a8373d51e30c915dc043",
    "dest": "/etc/kolla/nova-libvirt/auth.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt/auth.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt/auth.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "auth.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-libvirt/auth.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-libvirt/auth.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "auth.conf",
        "service": "nova-libvirt",
        "src": "auth.conf.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-libvirt/auth.conf",
    "size": 130,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037 `" && echo ansible-tmp-1765372110.9495022-272859-123419684888037="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7xk_irvx TO /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/ /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sevxqdckappjxltgbeipnqyvgirefmcs ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpc5b30955 TO /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/ /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-mvqtqexgmbbegjzbhswrhgsdqousygmf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372110.9495022-272859-123419684888037/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'sasl.conf.j2', 'dest': 'sasl.conf', 'service': 'nova-libvirt'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "5543f978398d201d60824d884663b01eb70dd714",
    "dest": "/etc/kolla/nova-libvirt/sasl.conf",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-libvirt/sasl.conf"
        },
        "before": {
            "path": "/etc/kolla/nova-libvirt/sasl.conf"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "sasl.conf.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-libvirt/sasl.conf",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-libvirt/sasl.conf",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "sasl.conf",
        "service": "nova-libvirt",
        "src": "sasl.conf.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-libvirt/sasl.conf",
    "size": 58,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying files for nova-ssh] **********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:128
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241 `" && echo ansible-tmp-1765372112.0091858-273042-109866338654241="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwy_tfvql TO /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/ /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-orjixtacjpqxeobfxyrujbyqyxxxaiuk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5ha2vjax TO /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/ /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tryctbolptchimgbupuhimgxlxdzngqv ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372112.0091858-273042-109866338654241/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'sshd_config.j2', 'dest': 'sshd_config'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "05549555bf69a959ccbd634188cd7dbc1683abe9",
    "dest": "/etc/kolla/nova-ssh/sshd_config",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh/sshd_config"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh/sshd_config"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "sshd_config.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-ssh/sshd_config",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-ssh/sshd_config",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "sshd_config",
        "src": "sshd_config.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-ssh/sshd_config",
    "size": 127,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149 `" && echo ansible-tmp-1765372113.0257547-273042-62198239038149="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwk92xy9q TO /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/ /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-erdmhqknoisogfanvfffuneyoswvzcdz ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp5p24q93t TO /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/ /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jgrpivfggbekbhxmvojeqlwxlhbztrvn ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372113.0257547-273042-62198239038149/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'id_rsa', 'dest': 'id_rsa'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "7b443872b92026bbdc13f4ef4600c7d2e5b857a9",
    "dest": "/etc/kolla/nova-ssh/id_rsa",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh/id_rsa"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh/id_rsa"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "id_rsa",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-ssh/id_rsa",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-ssh/id_rsa",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "id_rsa",
        "src": "id_rsa"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-ssh/id_rsa",
    "size": 3272,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121 `" && echo ansible-tmp-1765372113.9785862-273042-189956876226121="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpv68l3_04 TO /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/ /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-iuolzbgvbhxgimhgpiuopupebbwxdzod ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmprvkaw5c0 TO /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/ /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-cwxeomxshiljtateeiswxroqfqtkpnxo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372113.9785862-273042-189956876226121/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'id_rsa.pub', 'dest': 'id_rsa.pub'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "8d931ce436b4e2ca87e33d98d712f89e6775387b",
    "dest": "/etc/kolla/nova-ssh/id_rsa.pub",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh/id_rsa.pub"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh/id_rsa.pub"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "id_rsa.pub",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-ssh/id_rsa.pub",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-ssh/id_rsa.pub",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "id_rsa.pub",
        "src": "id_rsa.pub"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-ssh/id_rsa.pub",
    "size": 725,
    "state": "file",
    "uid": 1000
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583 `" && echo ansible-tmp-1765372114.9116912-273042-249012745847583="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpnp1hhozh TO /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/ /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-pzsgdmlytnnfeljwsszmjostzgztjbvu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpofhcrpeo TO /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/ /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-elykmcskginaowohoyecuvyngtxfethu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372114.9116912-273042-249012745847583/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'src': 'ssh_config.j2', 'dest': 'ssh_config'}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "checksum": "72df3ebacdceba019a7dfedffae0ed4faa0e3feb",
    "dest": "/etc/kolla/nova-ssh/ssh_config",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-ssh/ssh_config"
        },
        "before": {
            "path": "/etc/kolla/nova-ssh/ssh_config"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "ssh_config.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-ssh/ssh_config",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-ssh/ssh_config",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "item": {
        "dest": "ssh_config",
        "src": "ssh_config.j2"
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-ssh/ssh_config",
    "size": 77,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying 'release' file for nova_compute] *********************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:143
skipping: [localhost] => {
    "changed": false,
    "skipped_reason": "No items in the list"
}

TASK [nova-cell : Generating 'hostnqn' file for nova_compute] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:158
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879 `" && echo ansible-tmp-1765372116.0110826-273306-46063670391879="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/stat.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmps64fp_e5 TO /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/ /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wybhpxyuyupnpkctqijvxjswylvzrvik ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_stat.py'"'"' && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/file.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpy8ni91ng TO /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/ /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hkmhvnbkdebysxqpqjxbxihyaqdpwfih ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/AnsiballZ_file.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372116.0110826-273306-46063670391879/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "checksum": "70a5c93e4435d9f319ccec1879d7cf7af11eb11a",
    "dest": "/etc/kolla/nova-compute/hostnqn",
    "diff": {
        "after": {
            "path": "/etc/kolla/nova-compute/hostnqn"
        },
        "before": {
            "path": "/etc/kolla/nova-compute/hostnqn"
        }
    },
    "gid": 1000,
    "group": "nics",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": "hostnqn.j2",
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "dest": "/etc/kolla/nova-compute/hostnqn",
            "follow": true,
            "force": false,
            "group": null,
            "mode": "0660",
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/etc/kolla/nova-compute/hostnqn",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "file",
            "unsafe_writes": false
        }
    },
    "mode": "0660",
    "owner": "nics",
    "path": "/etc/kolla/nova-compute/hostnqn",
    "size": 69,
    "state": "file",
    "uid": 1000
}

TASK [nova-cell : Copying over existing policy file] ***************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:169
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "nova_policy_file is defined",
    "item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova-cell : Copying over vendordata file to containers] ******************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/config.yml:180
skipping: [localhost] => (item=nova-compute)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "vendordata_file_path is defined",
    "item": "nova-compute",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item=nova-compute-ironic)  => {
    "ansible_loop_var": "item",
    "changed": false,
    "false_condition": "vendordata_file_path is defined",
    "item": "nova-compute-ironic",
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [service-check-containers : nova_cell | Check containers] *****************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:4
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737 `" && echo ansible-tmp-1765372117.7180703-273371-110857935412737="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpz06w5t_x TO /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737/ /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-ygtdjbnyvmrhyhpasyssuvqrfuynqvwc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372117.7180703-273371-110857935412737/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "cgroupns_mode": "host",
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "labels": {},
            "name": "nova_libvirt",
            "pid_mode": "host",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494 `" && echo ansible-tmp-1765372118.7528133-273371-187983061787494="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzpeuv2tq TO /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494/ /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wporktkslgqcebkbsfxeqjwaxrfifmuc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372118.7528133-273371-187983061787494/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "labels": {},
            "name": "nova_ssh",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699 `" && echo ansible-tmp-1765372119.772315-273371-238673520023699="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpm76m36vk TO /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699/ /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sxszwiiopuplcegmxegqkmpbkswfivqh ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372119.772315-273371-238673520023699/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "labels": {},
            "name": "nova_novncproxy",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111 `" && echo ansible-tmp-1765372120.962738-273371-128428222264111="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjpb2pl99 TO /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111/ /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-djvjaukytodbloabjdgboajgmrbfgcqt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372120.962738-273371-128428222264111/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "labels": {},
            "name": "nova_conductor",
            "privileged": false,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "result": false
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558 `" && echo ansible-tmp-1765372122.2671702-273371-187052127852558="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/share/kolla-ansible/ansible/library/kolla_container.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmphuxexlne TO /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558/AnsiballZ_kolla_container.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558/ /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558/AnsiballZ_kolla_container.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-wdepjvoufiijslmfbkgvdroxewahiiae ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558/AnsiballZ_kolla_container.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372122.2671702-273371-187052127852558/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}}) => {
    "ansible_loop_var": "item",
    "changed": false,
    "invocation": {
        "module_args": {
            "action": "compare_container",
            "api_version": "auto",
            "auth_email": null,
            "auth_password": null,
            "auth_registry": "quay.io",
            "auth_username": null,
            "cap_add": [],
            "client_timeout": 120,
            "container_engine": "docker",
            "detach": true,
            "dimensions": {},
            "environment": {
                "KOLLA_CONFIG_STRATEGY": "COPY_ALWAYS",
                "LIBGUESTFS_BACKEND": "direct"
            },
            "graceful_timeout": 60,
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "ignore_missing": false,
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "labels": {},
            "name": "nova_compute",
            "privileged": true,
            "remove_on_exit": true,
            "restart_policy": "unless-stopped",
            "restart_retries": 10,
            "security_opt": [],
            "state": "running",
            "tls_verify": false,
            "tty": false,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "result": false
}

TASK [service-check-containers : nova_cell | Notify handlers to restart containers] ***
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:34
ok: [localhost] => {
    "msg": "Notifying handlers"
}

TASK [service-check-containers : Include tasks] ********************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/service-check-containers/tasks/main.yml:43
skipping: [localhost] => (item={'key': 'nova-libvirt', 'value': {'container_name': 'nova_libvirt', 'group': 'compute', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble', 'pid_mode': 'host', 'cgroupns_mode': 'host', 'privileged': True, 'volumes': ['/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', '', '/sys/fs/cgroup:/sys/fs/cgroup', 'kolla_logs:/var/log/kolla/', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', 'nova_libvirt_qemu:/etc/libvirt/qemu', ''], 'dimensions': {'ulimits': {'memlock': {'soft': 67108864, 'hard': 67108864}}}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'virsh version --daemon'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-libvirt",
        "value": {
            "cgroupns_mode": "host",
            "container_name": "nova_libvirt",
            "dimensions": {
                "ulimits": {
                    "memlock": {
                        "hard": 67108864,
                        "soft": 67108864
                    }
                }
            },
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "virsh version --daemon"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-libvirt:master-ubuntu-noble",
            "pid_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-libvirt/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "",
                "/sys/fs/cgroup:/sys/fs/cgroup",
                "kolla_logs:/var/log/kolla/",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                "nova_libvirt_qemu:/etc/libvirt/qemu",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-ssh', 'value': {'container_name': 'nova_ssh', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla', 'nova_compute:/var/lib/nova', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_listen sshd 8022'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-ssh",
        "value": {
            "container_name": "nova_ssh",
            "dimensions": {},
            "enabled": true,
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_listen sshd 8022"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-ssh:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-ssh/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla",
                "nova_compute:/var/lib/nova",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-novncproxy', 'value': {'container_name': 'nova_novncproxy', 'group': 'nova-novncproxy', 'image': 'quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble', 'enabled': True, 'volumes': ['/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_curl http://192.168.0.195:6080/vnc_lite.html'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-novncproxy",
        "value": {
            "container_name": "nova_novncproxy",
            "dimensions": {},
            "enabled": true,
            "group": "nova-novncproxy",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_curl http://192.168.0.195:6080/vnc_lite.html"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-novncproxy:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-novncproxy/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-conductor', 'value': {'container_name': 'nova_conductor', 'group': 'nova-conductor', 'enabled': True, 'image': 'quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble', 'volumes': ['/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', 'kolla_logs:/var/log/kolla/', '/dev/shm:/dev/shm', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-conductor 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-conductor",
        "value": {
            "container_name": "nova_conductor",
            "dimensions": {},
            "enabled": true,
            "group": "nova-conductor",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-conductor 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-conductor:master-ubuntu-noble",
            "volumes": [
                "/etc/kolla/nova-conductor/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "kolla_logs:/var/log/kolla/",
                "/dev/shm:/dev/shm",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'key': 'nova-compute', 'value': {'container_name': 'nova_compute', 'group': 'compute', 'image': 'quay.io/openstack.kolla/nova-compute:master-ubuntu-noble', 'environment': {'LIBGUESTFS_BACKEND': 'direct'}, 'privileged': True, 'enabled': True, 'ipc_mode': 'host', 'volumes': ['/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro', '/etc/localtime:/etc/localtime:ro', '/etc/timezone:/etc/timezone:ro', '/lib/modules:/lib/modules:ro', '/run:/run:shared', '/dev:/dev', 'kolla_logs:/var/log/kolla/', '', 'libvirtd:/var/lib/libvirt', 'nova_compute:/var/lib/nova/', '', ''], 'dimensions': {}, 'healthcheck': {'interval': '30', 'retries': '3', 'start_period': '5', 'test': ['CMD-SHELL', 'healthcheck_port nova-compute 5672'], 'timeout': '30'}}})  => {
    "ansible_loop_var": "outer_item",
    "changed": false,
    "false_condition": "(service.iterate | default(False)) | bool",
    "outer_item": {
        "key": "nova-compute",
        "value": {
            "container_name": "nova_compute",
            "dimensions": {},
            "enabled": true,
            "environment": {
                "LIBGUESTFS_BACKEND": "direct"
            },
            "group": "compute",
            "healthcheck": {
                "interval": "30",
                "retries": "3",
                "start_period": "5",
                "test": [
                    "CMD-SHELL",
                    "healthcheck_port nova-compute 5672"
                ],
                "timeout": "30"
            },
            "image": "quay.io/openstack.kolla/nova-compute:master-ubuntu-noble",
            "ipc_mode": "host",
            "privileged": true,
            "volumes": [
                "/etc/kolla/nova-compute/:/var/lib/kolla/config_files/:ro",
                "/etc/localtime:/etc/localtime:ro",
                "/etc/timezone:/etc/timezone:ro",
                "/lib/modules:/lib/modules:ro",
                "/run:/run:shared",
                "/dev:/dev",
                "kolla_logs:/var/log/kolla/",
                "",
                "libvirtd:/var/lib/libvirt",
                "nova_compute:/var/lib/nova/",
                "",
                ""
            ]
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => {
    "changed": false,
    "msg": "All items skipped"
}

TASK [nova-cell : include_tasks] ***********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml:13
skipping: [localhost] => {
    "changed": false,
    "false_condition": "enable_nova_fake | bool",
    "skip_reason": "Conditional result was False"
}

TASK [nova-cell : Flush handlers] **********************************************
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/deploy.yml:18
META: triggered running handlers for localhost

TASK [nova-cell : Waiting for nova-compute services to register themselves] ****
task path: /home/nics/openstack_venv/share/kolla-ansible/ansible/roles/nova-cell/tasks/wait_discover_computes.yml:24
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: nics
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696 `" && echo ansible-tmp-1765372124.6631024-273887-138082213138696="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpo9beatbi TO /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696/ /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-jyjtfpkfnhmhgjylszctlnhyczoxtfuu ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372124.6631024-273887-138082213138696/ > /dev/null 2>&1 && sleep 0'
redirecting (type: filter) ansible.builtin.json_query to community.general.json_query
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (20 retries left).Result was: {
    "attempts": 1,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.252077",
    "end": "2025-12-10 14:09:46.233889",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:08:44.981812",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734 `" && echo ansible-tmp-1765372196.6836033-273887-20526696579734="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqd3ugcz0 TO /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734/ /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-utegieticdhyzfxieopkaqriigvnxzjg ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372196.6836033-273887-20526696579734/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (19 retries left).Result was: {
    "attempts": 2,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.676271",
    "end": "2025-12-10 14:10:58.648266",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:09:56.971995",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559 `" && echo ansible-tmp-1765372269.0353658-273887-225482615598559="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpgl4w1cwt TO /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559/ /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-dpazomtrcgfngjfhzspneubizctakmtf ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372269.0353658-273887-225482615598559/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (18 retries left).Result was: {
    "attempts": 3,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:02.003543",
    "end": "2025-12-10 14:12:11.355747",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:11:09.352204",
    "stderr": "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time.",
    "stderr_lines": [
        "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455 `" && echo ansible-tmp-1765372341.7558563-273887-103966449853455="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp2q89kzq8 TO /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455/ /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tapkqwlwbybkewykbrlamdjkzuvzriwo ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372341.7558563-273887-103966449853455/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (17 retries left).Result was: {
    "attempts": 4,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.274013",
    "end": "2025-12-10 14:13:23.305841",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:12:22.031828",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193 `" && echo ansible-tmp-1765372413.6988559-273887-4056104874193="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpkwwd6sz9 TO /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193/ /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-qfmyvjxmtiwbobtdhnyywcfcsgekkasc ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372413.6988559-273887-4056104874193/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (16 retries left).Result was: {
    "attempts": 5,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.580185",
    "end": "2025-12-10 14:14:35.544836",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:13:33.964651",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666 `" && echo ansible-tmp-1765372486.0090353-273887-192361363367666="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp7x12t7y_ TO /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666/ /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-xtoweoaytxjimigrljlqmzaaizvwqgij ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372486.0090353-273887-192361363367666/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (15 retries left).Result was: {
    "attempts": 6,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.998618",
    "end": "2025-12-10 14:15:48.281982",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:14:46.283364",
    "stderr": "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time.",
    "stderr_lines": [
        "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209 `" && echo ansible-tmp-1765372558.6603026-273887-45331398360209="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpqzrhp2_6 TO /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209/ /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-zbqbebcktubuohrdipckasrxfjaiyifd ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372558.6603026-273887-45331398360209/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (14 retries left).Result was: {
    "attempts": 7,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.901716",
    "end": "2025-12-10 14:17:00.852429",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:15:58.950713",
    "stderr": "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time.",
    "stderr_lines": [
        "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354 `" && echo ansible-tmp-1765372631.2263434-273887-108806271370354="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpg8wj32ba TO /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354/ /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-tdreumnkecewwmesnyyijbvjhpeocxzr ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372631.2263434-273887-108806271370354/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (13 retries left).Result was: {
    "attempts": 8,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.817318",
    "end": "2025-12-10 14:18:13.347937",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:17:11.530619",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687 `" && echo ansible-tmp-1765372703.7426288-273887-234707092640687="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpwd6ccbwe TO /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687/ /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-sihdbglpuyhvylcakepmhkolzkjhzlgq ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372703.7426288-273887-234707092640687/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (12 retries left).Result was: {
    "attempts": 9,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.652955",
    "end": "2025-12-10 14:19:25.691584",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:18:24.038629",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810 `" && echo ansible-tmp-1765372776.1090589-273887-227632253454810="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmp6kkdi8t_ TO /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810/ /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-lvekbhakgzbplykylkqlfkmwkwjmbmgk ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372776.1090589-273887-227632253454810/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (11 retries left).Result was: {
    "attempts": 10,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.949019",
    "end": "2025-12-10 14:20:38.334341",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:19:36.385322",
    "stderr": "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time.",
    "stderr_lines": [
        "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531 `" && echo ansible-tmp-1765372848.715491-273887-42995187488531="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpzxxais1w TO /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531/ /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-uuwalmplxfklfslgfigzdueopbsvybez ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372848.715491-273887-42995187488531/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (10 retries left).Result was: {
    "attempts": 11,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.946216",
    "end": "2025-12-10 14:21:50.938816",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:20:48.992600",
    "stderr": "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time.",
    "stderr_lines": [
        "HttpException: 504: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 504 Gateway Time-out: The server didn't respond in time."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683 `" && echo ansible-tmp-1765372921.3872108-273887-34454178111683="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpjy_ujh27 TO /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683/ /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-poyzlmhcrfbeqosomvrcoedrtbqluzmy ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372921.3872108-273887-34454178111683/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: [localhost]: Waiting for nova-compute services to register themselves (9 retries left).Result was: {
    "attempts": 12,
    "changed": false,
    "cmd": [
        "docker",
        "exec",
        "kolla_toolbox",
        "openstack",
        "--os-interface",
        "internal",
        "--os-auth-url",
        "http://192.168.0.201:5000",
        "--os-project-domain-name",
        "default",
        "--os-project-name",
        "admin",
        "--os-username",
        "admin",
        "--os-password",
        "M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A",
        "--os-identity-api-version",
        "3",
        "--os-user-domain-name",
        "default",
        "--os-region-name",
        "RegionOne",
        "compute",
        "service",
        "list",
        "--format",
        "json",
        "--column",
        "Host",
        "--service",
        "nova-compute"
    ],
    "delta": "0:01:01.743565",
    "end": "2025-12-10 14:23:03.445567",
    "failed_when_result": false,
    "invocation": {
        "module_args": {
            "_raw_params": "docker exec kolla_toolbox openstack --os-interface internal --os-auth-url http://192.168.0.201:5000 --os-project-domain-name default --os-project-name admin --os-username admin --os-password M6RIJ7CY2pWiVs5sKIE6M2aEhJGE0LCRpQza1L7A --os-identity-api-version 3 --os-user-domain-name default --os-region-name RegionOne  compute service list --format json --column Host --service nova-compute\n",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "expand_argument_vars": true,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "retries": 21,
    "start": "2025-12-10 14:22:01.702002",
    "stderr": "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response.",
    "stderr_lines": [
        "HttpException: 502: Server Error for url: http://192.168.0.201:8774/v2.1/os-services?binary=nova-compute, 502 Bad Gateway: The server returned an invalid or incomplete response."
    ],
    "stdout": "",
    "stdout_lines": []
}
<localhost> EXEC /bin/sh -c 'echo ~nics && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /home/nics/.ansible/tmp `"&& mkdir "` echo /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439 `" && echo ansible-tmp-1765372993.8943655-273887-126174182619439="` echo /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439 `" ) && sleep 0'
Using module file /home/nics/openstack_venv/lib/python3.12/site-packages/ansible/modules/command.py
<localhost> PUT /home/nics/.ansible/tmp/ansible-local-242251o9jr4r3c/tmpyiosf5ws TO /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439/ /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '"'"'echo BECOME-SUCCESS-hisblacyzddsgoontvpdkczvlttudpzt ; /home/nics/openstack_venv/bin/python3.12 /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439/AnsiballZ_command.py'"'"' && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /home/nics/.ansible/tmp/ansible-tmp-1765372993.8943655-273887-126174182619439/ > /dev/null 2>&1 && sleep 0'
